{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458a57bf",
   "metadata": {},
   "source": [
    "#  PART 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c018d",
   "metadata": {},
   "source": [
    "* What are the input text parameters?\n",
    "\n",
    "* What are the labels? :\n",
    "   \n",
    "   * Gender \n",
    "   * Age \n",
    "   * Industry \n",
    "   * Astrological Sign\n",
    "   \n",
    "###### MemoryError: Unable to allocate 468. MiB for an array with shape (204386, 300) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2442e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(color_codes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b18e879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f8d44",
   "metadata": {},
   "source": [
    "##### DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e87e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('blogtext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680a7f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7318cdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can now 'capture' the URLs of popups...which means now I can show you some cool links to Korean Pop (K-Pop) audio and video without the need to relate ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                                                                                                                                                                      text  \n",
       "0                                                       Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.           \n",
       "1                               These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail            \n",
       "2             In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An ...  \n",
       "3                                                                                                                                                                         testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can now 'capture' the URLs of popups...which means now I can show you some cool links to Korean Pop (K-Pop) audio and video without the need to relate ins...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90990e18",
   "metadata": {},
   "source": [
    "Here, given the problem is typically a classification one. It shouldn't make any sense to predict date and id as it's does not describe any potentially important aspect of any text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0284f450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can now 'capture' the URLs of popups...which means now I can show you some cool links to Korean Pop (K-Pop) audio and video without the need to relate ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  age              topic      sign  \\\n",
       "0   male   15            Student       Leo   \n",
       "1   male   15            Student       Leo   \n",
       "2   male   15            Student       Leo   \n",
       "3   male   15            Student       Leo   \n",
       "4   male   33  InvestmentBanking  Aquarius   \n",
       "\n",
       "                                                                                                                                                                                                      text  \n",
       "0                                                       Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.           \n",
       "1                               These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail            \n",
       "2             In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An ...  \n",
       "3                                                                                                                                                                         testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can now 'capture' the URLs of popups...which means now I can show you some cool links to Korean Pop (K-Pop) audio and video without the need to relate ins...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns = ['id','date'], axis = 0, inplace = True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafcddb7",
   "metadata": {},
   "source": [
    "###### EXPLORING DATA STATISTICS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753a9098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['gender','age','topic','sign']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e38058f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 14, 15, 16, 17, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48] , data type:  int64\n"
     ]
    }
   ],
   "source": [
    "print(sorted(data['age'].unique()), ', data type: ',data['age'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7816c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = ['10s' if ((type(i)==int)&(i in range(0,18))) else i for i in data['age'] ]\n",
    "data['age'] = ['20s' if ((type(i)==int)&(i in range(23,28))) else i for i in data['age'] ]\n",
    "data['age'] = ['30s' if ((type(i)==int)&(i in range(33,49))) else i for i in data['age'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37816c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['age'], hue =data['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fa302c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sign', ylabel='topic'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_tab = pd.crosstab(data['topic'],data['sign'])\n",
    "sns.heatmap(cross_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db5bee",
   "metadata": {},
   "source": [
    "Here it appears as though aries and cancer people have greater interesting in writing on \"indUnk\" than people with other zodiac signs. \n",
    "\n",
    "However there's no particular pattern to learn from the above map since the two topics largely written on are Sports-Recreation and Unknown Industry by people of all signs. So all the said points makes it safe to discard Sign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0330074d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sign', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "sns.countplot(data['sign'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26da93",
   "metadata": {},
   "source": [
    "But from above it's clear that people with signs Aries and Cancer are simply greater in number than people with other signs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b01a4e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='gender'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_tab = pd.crosstab(data['gender'],data['age'])\n",
    "sns.heatmap(cross_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beabe2b",
   "metadata": {},
   "source": [
    "By and large, males and females write equally in numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc390cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gender', ylabel='topic'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_tab = pd.crosstab(data['topic'],data['gender'])\n",
    "sns.heatmap(cross_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb7eba",
   "metadata": {},
   "source": [
    "Given, the counts of male and female bloggers are equal in numbers, it can be derived that females truly write more articles on indUnk that males. Males seem to write more on Telecommunications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "361dffd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(data['gender'])\n",
    "\n",
    "for p in ax.patches:\n",
    "        ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef4326",
   "metadata": {},
   "source": [
    "###### Since the problem is typically a multilabel classification problem, it is widely advised that the labels are merged to unique collections of labels in the context of NLP problems at least. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3c6c1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10s', '30s', '20s'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06b946dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='sign'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_tab = pd.crosstab(data['sign'],data['age'])\n",
    "sns.heatmap(cross_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3151617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='topic'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_tab = pd.crosstab(data['topic'],data['age'])\n",
    "sns.heatmap(cross_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ffb51",
   "metadata": {},
   "source": [
    "So from all the plots and maps, it's easily inferable that age tends to have a pattern against other variables. Hence to make the prediction output simpler, it should be a preemptive move to eliminate all that 'Age' follows a pattern with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2e41f61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.drop(columns = ['gender','topic','sign'],axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b7d63f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10s</td>\n",
       "      <td>Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10s</td>\n",
       "      <td>These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10s</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10s</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30s</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can now 'capture' the URLs of popups...which means now I can show you some cool links to Korean Pop (K-Pop) audio and video without the need to relate ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  \\\n",
       "0  10s   \n",
       "1  10s   \n",
       "2  10s   \n",
       "3  10s   \n",
       "4  30s   \n",
       "\n",
       "                                                                                                                                                                                                      text  \n",
       "0                                                       Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.           \n",
       "1                               These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail            \n",
       "2             In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An ...  \n",
       "3                                                                                                                                                                         testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can now 'capture' the URLs of popups...which means now I can show you some cool links to Korean Pop (K-Pop) audio and video without the need to relate ins...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32a984",
   "metadata": {},
   "source": [
    "###### Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "501f1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(comp):\n",
    "    \n",
    "    words = RegexpTokenizer('\\w+').tokenize(comp)\n",
    "    words = [re.sub(r'([xx]+)|([XX]+)|(\\d+)', '', w).lower() for w in words]\n",
    "    words = list(filter(lambda a: a != '', words))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2282b9e",
   "metadata": {},
   "source": [
    "###### Preparing Word Embeddings for Potential Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b26c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.300d.txt',encoding=\"utf8\")\n",
    "embeddings_index['<unk>'] = 0\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa65336f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "word_data = list()\n",
    "for words in data['text']:\n",
    "    sentence = np.zeros(300)\n",
    "    count = 0\n",
    "    for w in tokenizer(words):\n",
    "        try:\n",
    "            sentence += embeddings_index[w]\n",
    "            count += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    word_data.append(sentence / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e63c01",
   "metadata": {},
   "source": [
    "Here, the word embedding for each word in each sentence in the dataset is normalized by the wordcount and append to form back the respective sentences in the embedded data array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c476464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data['age'])\n",
    "data['target'] = le.transform(data['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "788e1a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10s</td>\n",
       "      <td>Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10s</td>\n",
       "      <td>These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10s</td>\n",
       "      <td>In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10s</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30s</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can now 'capture' the URLs of popups...which means now I can show you some cool links to Korean Pop (K-Pop) audio and video without the need to relate ins...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  \\\n",
       "0  10s   \n",
       "1  10s   \n",
       "2  10s   \n",
       "3  10s   \n",
       "4  30s   \n",
       "\n",
       "                                                                                                                                                                                                      text  \\\n",
       "0                                                       Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.            \n",
       "1                               These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail             \n",
       "2             In het kader van kernfusie op aarde:  MAAK JE EIGEN WATERSTOFBOM   How to build an H-Bomb From: ascott@tartarus.uwa.edu.au (Andrew Scott) Newsgroups: rec.humor Subject: How To Build An ...   \n",
       "3                                                                                                                                                                         testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can now 'capture' the URLs of popups...which means now I can show you some cool links to Korean Pop (K-Pop) audio and video without the need to relate ins...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd913f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(word_data)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17e492d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size = 0.15, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7305e4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape : (579091, 300)\n",
      "\n",
      "x test shape : (102193, 300)\n",
      "\n",
      "y train shape : (579091,)\n",
      "\n",
      "y test shape : (102193,)\n"
     ]
    }
   ],
   "source": [
    "print(f'x train shape : {x_tr.shape}\\n\\nx test shape : {x_te.shape}\\n\\ny train shape : {y_tr.shape}\\n\\ny test shape : {y_te.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004367fb",
   "metadata": {},
   "source": [
    "###### Since the output is in the form of lists which can not be easily/ accurately rebuilt using prediction, we need to convert the output data to an appropriate format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a7910b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_counts=dict()\n",
    "\n",
    "# for labels in data.labels.values:\n",
    "#     for label in labels:\n",
    "#         if label in label_counts:\n",
    "#             label_counts[str(label)]+=1\n",
    "#         else:\n",
    "#             label_counts[str(label)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a15a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# binarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ac93c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_tr = binarizer.fit_transform(y_tr)\n",
    "# y_te = binarizer.fit_transform(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83fce120",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f210cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_rows = np.unique(y_tr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79031091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(unique_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22a27e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.nan_to_num(x_tr)\n",
    "x_te = np.nan_to_num(x_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34266cc4",
   "metadata": {},
   "source": [
    "This step is to fill in for the empty spots in the arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0a48f",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197247ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c31548e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4609806933938724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = BernoulliNB()\n",
    "clf.fit(x_tr,y_tr)\n",
    "pr = clf.predict(x_te)\n",
    "print(accuracy_score(y_te, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59054848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                 solver='liblinear'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear',max_iter=1000)\n",
    "lr.fit(x_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8e3f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5811259088195865\n"
     ]
    }
   ],
   "source": [
    "pr = lr.predict(x_te)\n",
    "print(accuracy_score(y_te, pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e6c78",
   "metadata": {},
   "source": [
    "Logistic Regression seems to perform better than BernoullieNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b214dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5811063380074957\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear',max_iter=3000)\n",
    "lr.fit(x_tr,y_tr)\n",
    "pr = lr.predict(x_te)\n",
    "print(accuracy_score(y_te, pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038bfff0",
   "metadata": {},
   "source": [
    "Increasing the iterations does not improve the fit at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a284cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2fe9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_n_print(model,x_train,x_test,y_train,y_test):\n",
    "    from sklearn import metrics \n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    score = round(model.score(x_test,y_test),3)\n",
    "\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd401f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_n_print(model,x_train,x_test,y_train,y_test):\n",
    "    from sklearn import metrics\n",
    "    model.fit(x_train,y_train)\n",
    "    bgcl = BaggingClassifier(base_estimator=model, n_estimators=7, random_state=1)\n",
    "    bgcl.fit(x_train,y_train)\n",
    "    pred = bgcl.predict(x_test)\n",
    "    score = bgcl.score(x_test,y_test)    \n",
    "\n",
    "    \n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e9aa987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_n_print(model,x_train,x_test,y_train,y_test):\n",
    "    from sklearn import metrics\n",
    "    model.fit(x_train,y_train)\n",
    "    abcl = AdaBoostClassifier(base_estimator = model,n_estimators=50,random_state=1,algorithm='SAMME')\n",
    "    \n",
    "    #[Discrete SAMME AdaBoost adapts based on errors in predicted class labels whereas real SAMME.R uses\n",
    "    #the predicted class probabilities.]\n",
    "    \n",
    "    abcl = abcl.fit(x_train,y_train)\n",
    "    pred = abcl.predict(x_test)\n",
    "    score = abcl.score(x_test,y_test)\n",
    "    \n",
    "\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fff4c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_result = pd.DataFrame({'Model':['lr_original'],\n",
    "                       'Accuracy':[0.5811063380074957]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42fa7cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ec7932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear',max_iter=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49b0a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracy = bag_n_print(lr,x_tr,x_te,y_tr,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e01dfc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5817326039944027"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac855d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106\n",
       "0       lr_bag  0.581733"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['lr_bag'],\n",
    "                       'Accuracy':[lr_accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c20094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracy = boost_n_print(lr,x_tr,x_te,y_tr,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b997ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4701006918282074"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb2a4ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106\n",
       "0       lr_bag  0.581733\n",
       "0     lr_boost  0.470101"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['lr_boost'],\n",
    "                       'Accuracy':[lr_accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32a450",
   "metadata": {},
   "source": [
    "###### Bagging and Boosting seems to bring no improvement either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "341b866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "feb87dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106\n",
       "0       lr_bag  0.581733\n",
       "0     lr_boost  0.470101\n",
       "0          knn  0.577000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_accuracy = fit_n_print(knn,x_tr,x_te,y_tr,y_te)\n",
    "lr_accuracy\n",
    "temp_result = pd.DataFrame({'Model':['knn'],\n",
    "                       'Accuracy':[lr_accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e55db3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_n_print(model,x_train,x_test,y_train,y_test, n_est):\n",
    "    from sklearn import metrics\n",
    "    model.fit(x_train,y_train)\n",
    "    bgcl = BaggingClassifier(base_estimator=model, n_estimators=n_est, random_state=1)\n",
    "    bgcl.fit(x_train,y_train)\n",
    "    pred = bgcl.predict(x_test)\n",
    "    score = bgcl.score(x_test,y_test)    \n",
    "\n",
    "    \n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21ffbbb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto', kernel = 'poly', degree = 3, max_iter = 1000)\n",
    "accuracy = fit_n_print(svm,x_tr,x_te,y_tr,y_te) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4b128c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.183"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4e362aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106\n",
       "0       lr_bag  0.581733\n",
       "0     lr_boost  0.470101\n",
       "0          knn  0.577000\n",
       "0          svm  0.183000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['svm'],\n",
    "                       'Accuracy':[accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d6fbf",
   "metadata": {},
   "source": [
    "###### KNN and SVM also do fit poorly on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd424597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto', kernel = 'poly', degree = 3, max_iter = 1000)\n",
    "accuracy = bag_n_print(svm,x_tr,x_te,y_tr,y_te,7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0a27488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_bag</td>\n",
       "      <td>0.471715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106\n",
       "0       lr_bag  0.581733\n",
       "0     lr_boost  0.470101\n",
       "0          knn  0.577000\n",
       "0          svm  0.183000\n",
       "0      svm_bag  0.471715"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['svm_bag'],\n",
    "                       'Accuracy':[accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2da2f6",
   "metadata": {},
   "source": [
    "##### Bagging and Boosting  have not helped improve the fit on any classification algorithm so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ceb084e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "BaseClassifier in AdaBoostClassifier ensemble is worse than random, ensemble can not be fit.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-ccfef5903ca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'poly'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboost_n_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_te\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-9d3e02613d83>\u001b[0m in \u001b[0;36mboost_n_print\u001b[1;34m(model, x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#the predicted class probabilities.]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mabcl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 random_state)\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             return self._boost_discrete(iboost, X, y, sample_weight,\n\u001b[1;32m--> 507\u001b[1;33m                                         random_state)\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vishak\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_discrete\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m                 raise ValueError('BaseClassifier in AdaBoostClassifier '\n\u001b[0m\u001b[0;32m    597\u001b[0m                                  \u001b[1;34m'ensemble is worse than random, ensemble '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                                  'can not be fit.')\n",
      "\u001b[1;31mValueError\u001b[0m: BaseClassifier in AdaBoostClassifier ensemble is worse than random, ensemble can not be fit."
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto', kernel = 'poly', degree = 3, max_iter = 1000)\n",
    "accuracy = boost_n_print(svm,x_tr,x_te,y_tr,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a38f8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc152a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.01, learning_rate='constant', max_iter=9800)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc = SGDClassifier(max_iter = 9800, learning_rate = 'constant', eta0 = 0.01)\n",
    "sgdc.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5db270d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.568209172839627"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sgdc.score(x_te,y_te)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52635642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_bag</td>\n",
       "      <td>0.471715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106\n",
       "0       lr_bag  0.581733\n",
       "0     lr_boost  0.470101\n",
       "0          knn  0.577000\n",
       "0          svm  0.183000\n",
       "0      svm_bag  0.471715\n",
       "0         SGDC  0.568209"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['SGDC'],\n",
    "                       'Accuracy':[score]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aaac6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = bag_n_print(sgdc,x_tr,x_te,y_tr,y_te,20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9526cd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_bag</td>\n",
       "      <td>0.471715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC_boost</td>\n",
       "      <td>0.580715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106\n",
       "0       lr_bag  0.581733\n",
       "0     lr_boost  0.470101\n",
       "0          knn  0.577000\n",
       "0          svm  0.183000\n",
       "0      svm_bag  0.471715\n",
       "0         SGDC  0.568209\n",
       "0   SGDC_boost  0.580715"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['SGDC_boost'],\n",
    "                       'Accuracy':[accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0dea59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6959abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "accuracy = fit_n_print(sgdc,x_tr,x_te,y_tr,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8f9e003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_bag</td>\n",
       "      <td>0.471715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC_boost</td>\n",
       "      <td>0.580715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.571000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy\n",
       "0  lr_original  0.581106\n",
       "0       lr_bag  0.581733\n",
       "0     lr_boost  0.470101\n",
       "0          knn  0.577000\n",
       "0          svm  0.183000\n",
       "0      svm_bag  0.471715\n",
       "0         SGDC  0.568209\n",
       "0   SGDC_boost  0.580715\n",
       "0  Naive Bayes  0.571000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['Naive Bayes'],\n",
    "                       'Accuracy':[accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ef226c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = bag_n_print(nb,x_tr,x_te,y_tr,y_te,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "65011fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_bag</td>\n",
       "      <td>0.471715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC_boost</td>\n",
       "      <td>0.580715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes_bag</td>\n",
       "      <td>0.468829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy\n",
       "0      lr_original  0.581106\n",
       "0           lr_bag  0.581733\n",
       "0         lr_boost  0.470101\n",
       "0              knn  0.577000\n",
       "0              svm  0.183000\n",
       "0          svm_bag  0.471715\n",
       "0             SGDC  0.568209\n",
       "0       SGDC_boost  0.580715\n",
       "0      Naive Bayes  0.571000\n",
       "0  Naive Bayes_bag  0.468829"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['Naive Bayes_bag'],\n",
    "                       'Accuracy':[accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "186bace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = boost_n_print(nb,x_tr,x_te,y_tr,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b2868b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_bag</td>\n",
       "      <td>0.471715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC_boost</td>\n",
       "      <td>0.580715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes_bag</td>\n",
       "      <td>0.468829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes_boost</td>\n",
       "      <td>0.470463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy\n",
       "0        lr_original  0.581106\n",
       "0             lr_bag  0.581733\n",
       "0           lr_boost  0.470101\n",
       "0                knn  0.577000\n",
       "0                svm  0.183000\n",
       "0            svm_bag  0.471715\n",
       "0               SGDC  0.568209\n",
       "0         SGDC_boost  0.580715\n",
       "0        Naive Bayes  0.571000\n",
       "0    Naive Bayes_bag  0.468829\n",
       "0  Naive Bayes_boost  0.470463"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['Naive Bayes_boost'],\n",
    "                       'Accuracy':[accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74666e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dTree = DecisionTreeClassifier(criterion = 'gini', random_state = 1)\n",
    "accuracy = fit_n_print(dTree,x_tr,x_te,y_tr,y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d6b08e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_bag</td>\n",
       "      <td>0.471715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC_boost</td>\n",
       "      <td>0.580715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes_bag</td>\n",
       "      <td>0.468829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes_boost</td>\n",
       "      <td>0.470463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.517000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy\n",
       "0        lr_original  0.581106\n",
       "0             lr_bag  0.581733\n",
       "0           lr_boost  0.470101\n",
       "0                knn  0.577000\n",
       "0                svm  0.183000\n",
       "0            svm_bag  0.471715\n",
       "0               SGDC  0.568209\n",
       "0         SGDC_boost  0.580715\n",
       "0        Naive Bayes  0.571000\n",
       "0    Naive Bayes_bag  0.468829\n",
       "0  Naive Bayes_boost  0.470463\n",
       "0      Decision Tree  0.517000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['Decision Tree'],\n",
    "                       'Accuracy':[accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6ff083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = bag_n_print(dTree,x_tr,x_te,y_tr,y_te,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "379b64cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_original</td>\n",
       "      <td>0.581106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bag</td>\n",
       "      <td>0.581733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_boost</td>\n",
       "      <td>0.470101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_bag</td>\n",
       "      <td>0.471715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDC_boost</td>\n",
       "      <td>0.580715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.571000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes_bag</td>\n",
       "      <td>0.468829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes_boost</td>\n",
       "      <td>0.470463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree_bag</td>\n",
       "      <td>0.554157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy\n",
       "0        lr_original  0.581106\n",
       "0             lr_bag  0.581733\n",
       "0           lr_boost  0.470101\n",
       "0                knn  0.577000\n",
       "0                svm  0.183000\n",
       "0            svm_bag  0.471715\n",
       "0               SGDC  0.568209\n",
       "0         SGDC_boost  0.580715\n",
       "0        Naive Bayes  0.571000\n",
       "0    Naive Bayes_bag  0.468829\n",
       "0  Naive Bayes_boost  0.470463\n",
       "0      Decision Tree  0.517000\n",
       "0  Decision Tree_bag  0.554157"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = pd.DataFrame({'Model':['Decision Tree_bag'],\n",
    "                       'Accuracy':[accuracy]})\n",
    "\n",
    "lr_result = pd.concat([lr_result,temp_result],axis = 0)\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c8f10",
   "metadata": {},
   "source": [
    "###### Basic supervised classfication algorithms have performed equally and poorly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f8d3d",
   "metadata": {},
   "source": [
    "###### THEREFORE, IT'S TIME NEURAL NETWORKS ARE TRIED. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e218b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5d066de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5616ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_cat = to_categorical(y_tr)\n",
    "y_te_cat = to_categorical(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a565615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_shape = (300,),kernel_initializer='he_normal',activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(94,activation='relu'))\n",
    "    model.add(Dense(3,activation='sigmoid', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "\n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(x_tr,y_tr_cat, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_te, y_te_cat, verbose=0)\n",
    "    print(score)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6cc61c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579091, 3)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e59419ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "579091/579091 [==============================] - 5s 9us/sample - loss: 0.3519 - mse: 0.3519\n"
     ]
    }
   ],
   "source": [
    "lr = 1e4\n",
    "Lambda = 0\n",
    "\n",
    "train_and_test_loop(1,lr,Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c5864531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.5223 - mse: 0.2418 0s - loss: 0.5223 -\n"
     ]
    }
   ],
   "source": [
    "lr = 0\n",
    "Lambda = 0.05\n",
    "\n",
    "train_and_test_loop(1,lr,Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d4451",
   "metadata": {},
   "source": [
    "###### As observed above, the neural networks fit nearly as much as the best basic supervised learning algorithm so far with just one iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cef50e13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2096 - mse: 0.1990\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1900 - mse: 0.1876\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1865 - mse: 0.1846\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1851 - mse: 0.1836\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1845 - mse: 0.1831\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1838 - mse: 0.1826\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1833 - mse: 0.1821\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1831 - mse: 0.1819\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1826 - mse: 0.1814\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1825 - mse: 0.1814\n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1821 - mse: 0.1810\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1818 - mse: 0.1806\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1814 - mse: 0.1802\n",
      "Epoch 14/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1809 - mse: 0.1797\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1805 - mse: 0.1793\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1801 - mse: 0.1789\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1799 - mse: 0.1787\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1795 - mse: 0.1783\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1792 - mse: 0.1780\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1789 - mse: 0.177 - 3s 5us/sample - loss: 0.1789 - mse: 0.1777\n",
      "Epoch 21/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1789 - mse: 0.1778\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1786 - mse: 0.1775\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1785 - mse: 0.1774\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1784 - mse: 0.1773\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1782 - mse: 0.1771\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1782 - mse: 0.1771\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1781 - mse: 0.1771\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1779 - mse: 0.1769\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1780 - mse: 0.1770\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1779 - mse: 0.1769\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1778 - mse: 0.1768\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1777 - mse: 0.1766\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1776 - mse: 0.1766\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1775 - mse: 0.1765\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1776 - mse: 0.1766\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1776 - mse: 0.1766\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1775 - mse: 0.1765\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1774 - mse: 0.1764\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1773 - mse: 0.1763\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1773 - mse: 0.1763\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1773 - mse: 0.1763\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1773 - mse: 0.1763\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1772 - mse: 0.1762\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1770 - mse: 0.1760\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1769 - mse: 0.1759\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1770 - mse: 0.1760\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1769 - mse: 0.1759\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1767 - mse: 0.1757\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1767 - mse: 0.1757\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1767 - mse: 0.1757\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1767 - mse: 0.1756\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1766 - mse: 0.1755\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1765 - mse: 0.1755\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1765 - mse: 0.1755\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1764 - mse: 0.1753\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1763 - mse: 0.1753\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1763 - mse: 0.1752\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1761 - mse: 0.1750\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1760 - mse: 0.1749\n",
      "Epoch 60/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1761 - mse: 0.1750\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1760 - mse: 0.1749\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1759 - mse: 0.1748\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1758 - mse: 0.1747\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1759 - mse: 0.1748\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1756 - mse: 0.1745\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1756 - mse: 0.1745\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1756 - mse: 0.1745\n",
      "Epoch 68/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1755 - mse: 0.1744\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1753 - mse: 0.1742\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1755 - mse: 0.1744\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1753 - mse: 0.1742\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1752 - mse: 0.1741\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1752 - mse: 0.1741\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1751 - mse: 0.1740\n",
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1750 - mse: 0.1739\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1750 - mse: 0.1739\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1749 - mse: 0.1738\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1749 - mse: 0.1738\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1749 - mse: 0.1738\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1747 - mse: 0.1736\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1748 - mse: 0.1737\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1746 - mse: 0.1735\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1746 - mse: 0.1735\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1745 - mse: 0.173 - 3s 5us/sample - loss: 0.1745 - mse: 0.1734\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1746 - mse: 0.1735\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1744 - mse: 0.1733\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1743 - mse: 0.1733\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1744 - mse: 0.1733\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1743 - mse: 0.1733\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1744 - mse: 0.1733\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1743 - mse: 0.1732\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1743 - mse: 0.1732\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1742 - mse: 0.1731\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1742 - mse: 0.1731\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1740 - mse: 0.1729\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1742 - mse: 0.1731\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1741 - mse: 0.1730\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1739 - mse: 0.172 - 3s 4us/sample - loss: 0.1740 - mse: 0.1729\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1739 - mse: 0.1729\n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1739 - mse: 0.1728\n"
     ]
    }
   ],
   "source": [
    "lr = 0.05\n",
    "Lambda = 0.05\n",
    "\n",
    "train_and_test_loop(100,lr,Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4abd350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_loop1(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape = (300,),kernel_initializer='he_normal',activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(3,activation='sigmoid', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "\n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(x_tr,y_tr_cat, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(x_te, y_te_cat, verbose=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "11f1b4a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2517 - accuracy: 0.2902\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2331 - accuracy: 0.4301\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2237 - accuracy: 0.46280s - loss: 0.2241 - ac\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2182 - accuracy: 0.4691\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2147 - accuracy: 0.4709\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2123 - accuracy: 0.4716\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2106 - accuracy: 0.4720\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2092 - accuracy: 0.4725\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2081 - accuracy: 0.4732\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2071 - accuracy: 0.4752\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2062 - accuracy: 0.4790\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2053 - accuracy: 0.4852\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2045 - accuracy: 0.4927\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2038 - accuracy: 0.4996\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2031 - accuracy: 0.5060\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2025 - accuracy: 0.5112\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2019 - accuracy: 0.5157\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2013 - accuracy: 0.5188\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2008 - accuracy: 0.5220\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2003 - accuracy: 0.5242\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1998 - accuracy: 0.5265\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1994 - accuracy: 0.5282\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1990 - accuracy: 0.5297\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1986 - accuracy: 0.5310\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1983 - accuracy: 0.5324\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1979 - accuracy: 0.5331\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1976 - accuracy: 0.5344\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1973 - accuracy: 0.5352\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1971 - accuracy: 0.5363\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1968 - accuracy: 0.5372\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1966 - accuracy: 0.5380\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1963 - accuracy: 0.5390\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1961 - accuracy: 0.5397\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1959 - accuracy: 0.5405\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1957 - accuracy: 0.5412\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1954 - accuracy: 0.5421\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1952 - accuracy: 0.5427\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1950 - accuracy: 0.5431\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1948 - accuracy: 0.5440\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1946 - accuracy: 0.5448\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1944 - accuracy: 0.5453\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1943 - accuracy: 0.5458\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1941 - accuracy: 0.5464\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1939 - accuracy: 0.5471\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1937 - accuracy: 0.5475\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1935 - accuracy: 0.5481\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1933 - accuracy: 0.5488\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1932 - accuracy: 0.5494\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1930 - accuracy: 0.5500\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1928 - accuracy: 0.5504\n",
      "[0.19244500141306387, 0.55301243]\n",
      "Try 1/10: Best_val_acc: None, lr: 0.00038537048945413234, Lambda: 0.00010889073676965853\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2277 - accuracy: 0.4668\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2113 - accuracy: 0.4727\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2062 - accuracy: 0.4790\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2034 - accuracy: 0.5036\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2012 - accuracy: 0.5251\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1993 - accuracy: 0.5341\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1978 - accuracy: 0.5397\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1966 - accuracy: 0.5430\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1956 - accuracy: 0.5457\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1947 - accuracy: 0.5478\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1939 - accuracy: 0.5501\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1931 - accuracy: 0.5520\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1925 - accuracy: 0.5540\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1918 - accuracy: 0.5556\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1912 - accuracy: 0.5577\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1906 - accuracy: 0.5592\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1900 - accuracy: 0.5609\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1895 - accuracy: 0.5623\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1889 - accuracy: 0.5638\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1885 - accuracy: 0.5651\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1880 - accuracy: 0.5661\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1876 - accuracy: 0.5667\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1872 - accuracy: 0.5677\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1868 - accuracy: 0.5685\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1865 - accuracy: 0.5693\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1862 - accuracy: 0.5698\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1859 - accuracy: 0.5704\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1856 - accuracy: 0.5713\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1853 - accuracy: 0.5719\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1851 - accuracy: 0.5722\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1848 - accuracy: 0.5730\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1846 - accuracy: 0.5737\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1844 - accuracy: 0.5740\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1842 - accuracy: 0.5748\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1840 - accuracy: 0.5751\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1838 - accuracy: 0.5760\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1836 - accuracy: 0.5763\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1834 - accuracy: 0.5768\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1832 - accuracy: 0.5772\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1830 - accuracy: 0.5777\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1829 - accuracy: 0.5784\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1827 - accuracy: 0.5786\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1826 - accuracy: 0.5788\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1824 - accuracy: 0.5794\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1823 - accuracy: 0.5797\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1822 - accuracy: 0.5798\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1820 - accuracy: 0.5803\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1819 - accuracy: 0.5805\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1818 - accuracy: 0.5809\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1817 - accuracy: 0.5812\n",
      "[0.18096614153217558, 0.58576417]\n",
      "Try 2/10: Best_val_acc: None, lr: 0.0009990952997802824, Lambda: 1.3905380199881787e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.2863 - accuracy: 0.4509\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2222 - accuracy: 0.4726\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2100 - accuracy: 0.4839\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2057 - accuracy: 0.5099\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2032 - accuracy: 0.5234\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2016 - accuracy: 0.5303\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2004 - accuracy: 0.5332\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1994 - accuracy: 0.5359\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1986 - accuracy: 0.5380\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1979 - accuracy: 0.5401\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1973 - accuracy: 0.5420\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1968 - accuracy: 0.5434\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1962 - accuracy: 0.5454\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1958 - accuracy: 0.5469\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1953 - accuracy: 0.5481\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1948 - accuracy: 0.5501\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1944 - accuracy: 0.55 - 3s 5us/sample - loss: 0.1943 - accuracy: 0.5518\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1939 - accuracy: 0.5536\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1934 - accuracy: 0.5555\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1929 - accuracy: 0.5573\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1925 - accuracy: 0.5595\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1920 - accuracy: 0.5608\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1916 - accuracy: 0.5627\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1912 - accuracy: 0.5641\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1908 - accuracy: 0.5653\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1905 - accuracy: 0.5663\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1901 - accuracy: 0.5675\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1898 - accuracy: 0.5685\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1894 - accuracy: 0.5695\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1891 - accuracy: 0.5702\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1888 - accuracy: 0.5709\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1886 - accuracy: 0.5714\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1883 - accuracy: 0.5720\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1881 - accuracy: 0.5725\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1878 - accuracy: 0.5731\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1876 - accuracy: 0.5737\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1874 - accuracy: 0.5742\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1872 - accuracy: 0.5747\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1870 - accuracy: 0.5751\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1868 - accuracy: 0.5755\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1866 - accuracy: 0.5758\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1865 - accuracy: 0.5765\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1863 - accuracy: 0.5767\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1862 - accuracy: 0.5773\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1860 - accuracy: 0.5775\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1859 - accuracy: 0.5778\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1858 - accuracy: 0.5780\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1856 - accuracy: 0.5783\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1855 - accuracy: 0.5785\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1854 - accuracy: 0.5788\n",
      "[0.18483453432428062, 0.58161515]\n",
      "Try 3/10: Best_val_acc: None, lr: 0.003224599764913466, Lambda: 0.023216119492734288\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.6710 - accuracy: 0.3879\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.5967 - accuracy: 0.4167\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.5351 - accuracy: 0.4383\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.4841 - accuracy: 0.4521\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.4416 - accuracy: 0.4599\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.4063 - accuracy: 0.4638\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3768 - accuracy: 0.4661\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3521 - accuracy: 0.4682\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3315 - accuracy: 0.4693\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3142 - accuracy: 0.4700\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2997 - accuracy: 0.4707\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2876 - accuracy: 0.4711\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2773 - accuracy: 0.4713\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2687 - accuracy: 0.4716\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2614 - accuracy: 0.4718\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2552 - accuracy: 0.4718\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2500 - accuracy: 0.4718\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2456 - accuracy: 0.4718\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2418 - accuracy: 0.4719\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2385 - accuracy: 0.4718\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2358 - accuracy: 0.4718\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2334 - accuracy: 0.4718\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2313 - accuracy: 0.4718\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2295 - accuracy: 0.4718\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2280 - accuracy: 0.4718\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2266 - accuracy: 0.4718\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2254 - accuracy: 0.4718\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2244 - accuracy: 0.4718\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2234 - accuracy: 0.4718\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2226 - accuracy: 0.4718\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2218 - accuracy: 0.4718\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2212 - accuracy: 0.4718\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2206 - accuracy: 0.4718\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2200 - accuracy: 0.4718\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2195 - accuracy: 0.4718\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2190 - accuracy: 0.4718\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2186 - accuracy: 0.4718\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2182 - accuracy: 0.4718\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2178 - accuracy: 0.4718\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2175 - accuracy: 0.4718\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2171 - accuracy: 0.4718\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2168 - accuracy: 0.4718\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2165 - accuracy: 0.4718\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2163 - accuracy: 0.4718\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2160 - accuracy: 0.4718\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2157 - accuracy: 0.4718\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2155 - accuracy: 0.4718\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2153 - accuracy: 0.4718\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2151 - accuracy: 0.4718\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2148 - accuracy: 0.4718\n",
      "[0.21480221613337117, 0.47169572]\n",
      "Try 4/10: Best_val_acc: None, lr: 8.99356661391494e-05, Lambda: 0.08666541779466942\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.4365 - accuracy: 0.4479\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2238 - accuracy: 0.4718\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2172 - accuracy: 0.4718\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2136 - accuracy: 0.4718\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2116 - accuracy: 0.4718\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2104 - accuracy: 0.4718\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2096 - accuracy: 0.4718\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2092 - accuracy: 0.4718\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2088 - accuracy: 0.4718\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2086 - accuracy: 0.4718\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2085 - accuracy: 0.4718\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2084 - accuracy: 0.4718\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2083 - accuracy: 0.4718\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2082 - accuracy: 0.4718\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2082 - accuracy: 0.4718\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2081 - accuracy: 0.4718\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2081 - accuracy: 0.4718\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2081 - accuracy: 0.4718\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2080 - accuracy: 0.4718\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2080 - accuracy: 0.4718\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2080 - accuracy: 0.4718\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2080 - accuracy: 0.4718\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2080 - accuracy: 0.4719\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2079 - accuracy: 0.4719\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2079 - accuracy: 0.4719\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2079 - accuracy: 0.4719\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2079 - accuracy: 0.4719\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2078 - accuracy: 0.4719\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2078 - accuracy: 0.4719\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2078 - accuracy: 0.4719\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2078 - accuracy: 0.4719\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2077 - accuracy: 0.4720\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2077 - accuracy: 0.4720\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2077 - accuracy: 0.4720\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2076 - accuracy: 0.4720\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2076 - accuracy: 0.4720\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2075 - accuracy: 0.4721\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2075 - accuracy: 0.4721\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2074 - accuracy: 0.4722\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2073 - accuracy: 0.4722\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2073 - accuracy: 0.4723\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2072 - accuracy: 0.4724\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2071 - accuracy: 0.4726\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2070 - accuracy: 0.4729\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2069 - accuracy: 0.4732\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2068 - accuracy: 0.4736\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2067 - accuracy: 0.4742\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2066 - accuracy: 0.4749\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2065 - accuracy: 0.4757\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2063 - accuracy: 0.4768\n",
      "[0.20627053005670287, 0.4776746]\n",
      "Try 5/10: Best_val_acc: None, lr: 0.0014246746557113137, Lambda: 0.2643234081486781\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2227 - accuracy: 0.4485\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2064 - accuracy: 0.4988\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2015 - accuracy: 0.5245\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1987 - accuracy: 0.5341\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1969 - accuracy: 0.5396\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1955 - accuracy: 0.5431\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1944 - accuracy: 0.5458\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1935 - accuracy: 0.5488\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1927 - accuracy: 0.5514\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1918 - accuracy: 0.5544\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1910 - accuracy: 0.5570\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1902 - accuracy: 0.5598\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1894 - accuracy: 0.5621\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1887 - accuracy: 0.5645\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1880 - accuracy: 0.5665\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1874 - accuracy: 0.5680\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1868 - accuracy: 0.5692\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1863 - accuracy: 0.5705\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1858 - accuracy: 0.5717\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1854 - accuracy: 0.5729\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1849 - accuracy: 0.5739\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1846 - accuracy: 0.5748\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1842 - accuracy: 0.5754\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1839 - accuracy: 0.5763\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1836 - accuracy: 0.5769\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1833 - accuracy: 0.5777\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1830 - accuracy: 0.5785\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1828 - accuracy: 0.5789\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1825 - accuracy: 0.5799\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1823 - accuracy: 0.5805\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1821 - accuracy: 0.5810\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1819 - accuracy: 0.5814\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1817 - accuracy: 0.5823\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1816 - accuracy: 0.5826\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1814 - accuracy: 0.5828\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1812 - accuracy: 0.5834\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1811 - accuracy: 0.5836\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1809 - accuracy: 0.5845\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1808 - accuracy: 0.5844\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1807 - accuracy: 0.5848\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1806 - accuracy: 0.5851\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1804 - accuracy: 0.5854\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1803 - accuracy: 0.5857\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1802 - accuracy: 0.5857\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1801 - accuracy: 0.5861\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1800 - accuracy: 0.5863\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1799 - accuracy: 0.5866\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1798 - accuracy: 0.5865\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1798 - accuracy: 0.5869\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1797 - accuracy: 0.5868\n",
      "[0.1791074670731007, 0.5897175]\n",
      "Try 6/10: Best_val_acc: None, lr: 0.0021688570252331933, Lambda: 7.722427620033958e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2513 - accuracy: 0.33980s - los\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2368 - accuracy: 0.4398\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2274 - accuracy: 0.4640\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2210 - accuracy: 0.46861s - loss: 0.2222 -  - ETA: 0s - l\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2165 - accuracy: 0.4701\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2131 - accuracy: 0.4709\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2106 - accuracy: 0.4720\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2087 - accuracy: 0.4756\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2071 - accuracy: 0.4841\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2059 - accuracy: 0.4939\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2048 - accuracy: 0.5026\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2039 - accuracy: 0.5093\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2031 - accuracy: 0.51431s - l - ETA: 1s - loss: 0.2 - ETA: 0s - loss: 0\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2024 - accuracy: 0.5186\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2017 - accuracy: 0.5214\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2012 - accuracy: 0.5244\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2006 - accuracy: 0.5267\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2001 - accuracy: 0.5284\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1997 - accuracy: 0.5303\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1993 - accuracy: 0.5314\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1989 - accuracy: 0.5327\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1985 - accuracy: 0.5338\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1981 - accuracy: 0.5347\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1978 - accuracy: 0.5359\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1975 - accuracy: 0.5365\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1972 - accuracy: 0.5372\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1969 - accuracy: 0.5381\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1967 - accuracy: 0.5389\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1964 - accuracy: 0.5397\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1962 - accuracy: 0.5400\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1960 - accuracy: 0.5408\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1958 - accuracy: 0.5415\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1956 - accuracy: 0.5419\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1954 - accuracy: 0.5425\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1952 - accuracy: 0.5432\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1950 - accuracy: 0.5438\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1948 - accuracy: 0.5441\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1946 - accuracy: 0.5449\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1945 - accuracy: 0.5453\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1943 - accuracy: 0.5460\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1941 - accuracy: 0.54650s - loss: 0.1941 - accuracy: \n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1940 - accuracy: 0.5471\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1938 - accuracy: 0.5476\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1937 - accuracy: 0.5480\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1935 - accuracy: 0.5485\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1933 - accuracy: 0.54920s - loss: 0.1934 - accuracy: 0.\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1932 - accuracy: 0.54971s - loss: 0.1929  -\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1931 - accuracy: 0.5500\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1929 - accuracy: 0.5508\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1928 - accuracy: 0.5512\n",
      "[0.19246918452466935, 0.55235684]\n",
      "Try 7/10: Best_val_acc: None, lr: 0.0002774495425276861, Lambda: 3.641005097523848e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.4121 - accuracy: 0.2271\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.4095 - accuracy: 0.2478\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.4070 - accuracy: 0.2694 - ETA: 0s - loss:\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.4045 - accuracy: 0.28990s - loss: 0.4045 - accuracy: \n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.4020 - accuracy: 0.3095\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.3996 - accuracy: 0.3270\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.3972 - accuracy: 0.3444\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.3949 - accuracy: 0.3601\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3927 - accuracy: 0.3739\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.3904 - accuracy: 0.3869\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3883 - accuracy: 0.3983\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.3861 - accuracy: 0.4081\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3841 - accuracy: 0.4170\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3820 - accuracy: 0.4243\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3800 - accuracy: 0.4306\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3780 - accuracy: 0.4359\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3761 - accuracy: 0.4403\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3742 - accuracy: 0.4439\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3724 - accuracy: 0.4469\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3705 - accuracy: 0.4492\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3688 - accuracy: 0.4515\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3670 - accuracy: 0.4533\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3653 - accuracy: 0.4549\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3636 - accuracy: 0.4562\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3619 - accuracy: 0.4573\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3603 - accuracy: 0.4584\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3587 - accuracy: 0.4593\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3571 - accuracy: 0.4601\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3556 - accuracy: 0.4609\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3541 - accuracy: 0.4616\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3526 - accuracy: 0.4620\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3511 - accuracy: 0.4626\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3496 - accuracy: 0.4631\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3482 - accuracy: 0.4635\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3468 - accuracy: 0.4639\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3454 - accuracy: 0.4642\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3441 - accuracy: 0.4645\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3427 - accuracy: 0.4648\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3414 - accuracy: 0.4652\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3401 - accuracy: 0.4655\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3389 - accuracy: 0.4658\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3376 - accuracy: 0.4659\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3364 - accuracy: 0.4662\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3351 - accuracy: 0.4664\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3339 - accuracy: 0.4666\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3327 - accuracy: 0.4669\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3316 - accuracy: 0.4670\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3304 - accuracy: 0.4676\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3293 - accuracy: 0.4685\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.3282 - accuracy: 0.4696\n",
      "[0.32768590597640573, 0.47033554]\n",
      "Try 8/10: Best_val_acc: None, lr: 1.2995977402485671e-05, Lambda: 0.028880993127011645\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2240 - accuracy: 0.4729\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2053 - accuracy: 0.51581s - l - ETA: 0s - los\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2003 - accuracy: 0.5381\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1977 - accuracy: 0.5456\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1959 - accuracy: 0.5501\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1944 - accuracy: 0.5543\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1931 - accuracy: 0.5574\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1920 - accuracy: 0.5603\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1910 - accuracy: 0.5627\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1901 - accuracy: 0.5650\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1893 - accuracy: 0.5674\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1886 - accuracy: 0.5692\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1879 - accuracy: 0.5711\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1873 - accuracy: 0.5723\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1868 - accuracy: 0.5736\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1863 - accuracy: 0.5745\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1859 - accuracy: 0.5754\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1855 - accuracy: 0.5766\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1851 - accuracy: 0.5773\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1848 - accuracy: 0.5780\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1845 - accuracy: 0.5785\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1842 - accuracy: 0.5792\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1840 - accuracy: 0.5794\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1837 - accuracy: 0.5800\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1835 - accuracy: 0.5805\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1833 - accuracy: 0.5809\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1830 - accuracy: 0.5812\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1829 - accuracy: 0.5815\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1827 - accuracy: 0.5821\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1825 - accuracy: 0.5824\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1823 - accuracy: 0.5826\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1822 - accuracy: 0.5828\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1820 - accuracy: 0.5833\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1818 - accuracy: 0.5834\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1817 - accuracy: 0.5840\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1816 - accuracy: 0.5841\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1814 - accuracy: 0.5845\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1813 - accuracy: 0.5848\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1811 - accuracy: 0.5851\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1810 - accuracy: 0.5853\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1809 - accuracy: 0.5853\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1808 - accuracy: 0.5855\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1806 - accuracy: 0.5859\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1806 - accuracy: 0.5859\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1805 - accuracy: 0.5862\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1803 - accuracy: 0.5864\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1802 - accuracy: 0.5866\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1801 - accuracy: 0.5868\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1800 - accuracy: 0.5867\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1799 - accuracy: 0.5875\n",
      "[0.17947544477041644, 0.5891989]\n",
      "Try 9/10: Best_val_acc: None, lr: 0.0026263170678647967, Lambda: 0.00036841249261508293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,10):\n",
    "    lr = math.pow(10, np.random.uniform(-5.0, -1))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5,0))\n",
    "    best_acc = train_and_test_loop(50, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84436b51",
   "metadata": {},
   "source": [
    "lr: 0.0009990952997802824, Lambda: 1.3905380199881787e-05 (58 for 50)\n",
    "\n",
    "lr: 0.003224599764913466, Lambda: 0.023216119492734288 (same)\n",
    "        \n",
    "lr: 0.0021688570252331933, Lambda: 7.722427620033958e-05\n",
    "\n",
    "lr: 0.0026263170678647967, Lambda: 0.00036841249261508293\n",
    "        \n",
    "\n",
    "##### Seems from the training results that the above pairs of learning rate and lambda values seem the most optimal for the neural network fit so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbc25469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 4s 7us/sample - loss: 0.2572 - accuracy: 0.3526\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2394 - accuracy: 0.4340\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2291 - accuracy: 0.4589\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2228 - accuracy: 0.4653\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2185 - accuracy: 0.4686\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2156 - accuracy: 0.4701\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2134 - accuracy: 0.4707\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2118 - accuracy: 0.4710\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2105 - accuracy: 0.4712\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.2095 - accuracy: 0.4713\n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2085 - accuracy: 0.4719\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2077 - accuracy: 0.4727\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2069 - accuracy: 0.4743\n",
      "Epoch 14/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2062 - accuracy: 0.4769\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2055 - accuracy: 0.4809\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2048 - accuracy: 0.4863\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2041 - accuracy: 0.4920\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2035 - accuracy: 0.4974\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2028 - accuracy: 0.5023\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2022 - accuracy: 0.5069\n",
      "Epoch 21/100\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.51 - 3s 5us/sample - loss: 0.2017 - accuracy: 0.5109\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2011 - accuracy: 0.5148\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2006 - accuracy: 0.5174\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2001 - accuracy: 0.5201\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1997 - accuracy: 0.5223\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1993 - accuracy: 0.5249\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1989 - accuracy: 0.5264\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1985 - accuracy: 0.5279\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1982 - accuracy: 0.5293\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1978 - accuracy: 0.5305\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1975 - accuracy: 0.5318\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1973 - accuracy: 0.5329\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1970 - accuracy: 0.5338\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1967 - accuracy: 0.5349\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1965 - accuracy: 0.5357\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1963 - accuracy: 0.5362\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1961 - accuracy: 0.5372\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1959 - accuracy: 0.5379\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1957 - accuracy: 0.5388\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1955 - accuracy: 0.5393\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1953 - accuracy: 0.5400\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1951 - accuracy: 0.5406\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1950 - accuracy: 0.5411\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1948 - accuracy: 0.5418\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1946 - accuracy: 0.5421\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1945 - accuracy: 0.5430\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1943 - accuracy: 0.5432\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1942 - accuracy: 0.5440\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1940 - accuracy: 0.5441\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1939 - accuracy: 0.5447\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1937 - accuracy: 0.5453\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1936 - accuracy: 0.5456\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1935 - accuracy: 0.5461\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1933 - accuracy: 0.5468\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1932 - accuracy: 0.5470\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1931 - accuracy: 0.5474\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1929 - accuracy: 0.5480\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1928 - accuracy: 0.5486\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1927 - accuracy: 0.5489\n",
      "Epoch 60/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1925 - accuracy: 0.5494\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1924 - accuracy: 0.5496\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1923 - accuracy: 0.5502\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1922 - accuracy: 0.5506\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1920 - accuracy: 0.5511\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1919 - accuracy: 0.5511\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1918 - accuracy: 0.5519\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1917 - accuracy: 0.5520\n",
      "Epoch 68/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1916 - accuracy: 0.5526\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1915 - accuracy: 0.5528\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1913 - accuracy: 0.5532\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1912 - accuracy: 0.5533\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1911 - accuracy: 0.5539\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1910 - accuracy: 0.5540\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1909 - accuracy: 0.5545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1908 - accuracy: 0.5548\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1907 - accuracy: 0.5551\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1906 - accuracy: 0.5556\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1904 - accuracy: 0.5557\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1903 - accuracy: 0.5563\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1902 - accuracy: 0.5569\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1901 - accuracy: 0.5571\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1900 - accuracy: 0.5573\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1899 - accuracy: 0.5577\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1898 - accuracy: 0.5578\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1897 - accuracy: 0.5581\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1896 - accuracy: 0.5586\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1895 - accuracy: 0.5588\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1894 - accuracy: 0.5592\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1893 - accuracy: 0.5594\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1892 - accuracy: 0.5599\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1891 - accuracy: 0.5600\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1890 - accuracy: 0.5602\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1889 - accuracy: 0.5607\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1888 - accuracy: 0.5607\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1887 - accuracy: 0.5610\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1886 - accuracy: 0.5613\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1886 - accuracy: 0.5616\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1885 - accuracy: 0.5617\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1884 - accuracy: 0.5620\n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1883 - accuracy: 0.5625\n",
      "[0.18773537624690453, 0.5658509]\n",
      "Try 1/10: Best_val_acc: None, lr: 0.000319851470116155, Lambda: 1.8259068749879754e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2336 - accuracy: 0.4593\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2172 - accuracy: 0.4832\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2103 - accuracy: 0.4902\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2067 - accuracy: 0.5026\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2043 - accuracy: 0.5150\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2026 - accuracy: 0.5234\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2012 - accuracy: 0.5291\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2001 - accuracy: 0.5329\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1991 - accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1982 - accuracy: 0.5384\n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1975 - accuracy: 0.5405\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1968 - accuracy: 0.5422\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1962 - accuracy: 0.5436\n",
      "Epoch 14/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1957 - accuracy: 0.5449\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1952 - accuracy: 0.5464\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1948 - accuracy: 0.5474\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1944 - accuracy: 0.5486\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1940 - accuracy: 0.5493\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1937 - accuracy: 0.5505\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1933 - accuracy: 0.5514\n",
      "Epoch 21/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1931 - accuracy: 0.5522\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1928 - accuracy: 0.5528\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1925 - accuracy: 0.5538\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1922 - accuracy: 0.5543\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1919 - accuracy: 0.5553\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1917 - accuracy: 0.5560\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1914 - accuracy: 0.5568\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1912 - accuracy: 0.5575\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1909 - accuracy: 0.5579\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1907 - accuracy: 0.5589\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1905 - accuracy: 0.5596\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1902 - accuracy: 0.5603\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1900 - accuracy: 0.5613\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1898 - accuracy: 0.5617\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1895 - accuracy: 0.5622\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1893 - accuracy: 0.5629\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1891 - accuracy: 0.5638\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1889 - accuracy: 0.5644\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1887 - accuracy: 0.5649\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1885 - accuracy: 0.5653\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1883 - accuracy: 0.5660\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1881 - accuracy: 0.5666\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1880 - accuracy: 0.5672\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1877 - accuracy: 0.5675\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1876 - accuracy: 0.5681\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1874 - accuracy: 0.5687\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1873 - accuracy: 0.5690\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1871 - accuracy: 0.5694\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1869 - accuracy: 0.5698\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1868 - accuracy: 0.5705\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1866 - accuracy: 0.5709\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1865 - accuracy: 0.5711\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1863 - accuracy: 0.5717\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1862 - accuracy: 0.5720\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1860 - accuracy: 0.5723\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1859 - accuracy: 0.5726\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1857 - accuracy: 0.5731\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1856 - accuracy: 0.5732\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1855 - accuracy: 0.5738\n",
      "Epoch 60/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1854 - accuracy: 0.5741\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1852 - accuracy: 0.5744\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1851 - accuracy: 0.5746\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1850 - accuracy: 0.5748\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1849 - accuracy: 0.5750\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1847 - accuracy: 0.5755\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1846 - accuracy: 0.5758\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1845 - accuracy: 0.5759\n",
      "Epoch 68/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1844 - accuracy: 0.5763\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1843 - accuracy: 0.5766\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1842 - accuracy: 0.5768\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1841 - accuracy: 0.5772\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1840 - accuracy: 0.5775\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1839 - accuracy: 0.5775\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1838 - accuracy: 0.5781\n",
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1837 - accuracy: 0.5781\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1836 - accuracy: 0.5785\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1835 - accuracy: 0.5786\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1834 - accuracy: 0.5787\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1833 - accuracy: 0.5789\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1832 - accuracy: 0.5793\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1832 - accuracy: 0.5793\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1831 - accuracy: 0.5797\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1830 - accuracy: 0.5797\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1829 - accuracy: 0.5801\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1828 - accuracy: 0.5802\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1827 - accuracy: 0.5803\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1827 - accuracy: 0.5805\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1826 - accuracy: 0.5807\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1825 - accuracy: 0.5811\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1824 - accuracy: 0.5809\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1824 - accuracy: 0.5809\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1823 - accuracy: 0.5812\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1822 - accuracy: 0.5815\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1821 - accuracy: 0.5814\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1821 - accuracy: 0.5816\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1820 - accuracy: 0.5820\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1819 - accuracy: 0.5821\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1818 - accuracy: 0.5821\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1818 - accuracy: 0.5821\n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1817 - accuracy: 0.5822\n",
      "[0.1809153605592652, 0.58647853]\n",
      "Try 2/10: Best_val_acc: None, lr: 0.0005809423422045694, Lambda: 4.8923142045536506e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2506 - accuracy: 0.3289\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2428 - accuracy: 0.4095\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2366 - accuracy: 0.4469\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2317 - accuracy: 0.4606\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2278 - accuracy: 0.4659\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2247 - accuracy: 0.4683\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2221 - accuracy: 0.4698\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2200 - accuracy: 0.4706\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2182 - accuracy: 0.4711\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2167 - accuracy: 0.4715\n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2154 - accuracy: 0.4717\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2144 - accuracy: 0.4719\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2134 - accuracy: 0.4719\n",
      "Epoch 14/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2126 - accuracy: 0.4719\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2119 - accuracy: 0.4722\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2113 - accuracy: 0.4723\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2107 - accuracy: 0.4724\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2102 - accuracy: 0.4727\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2097 - accuracy: 0.4726\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2093 - accuracy: 0.4728\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2089 - accuracy: 0.4732\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2086 - accuracy: 0.4736\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2082 - accuracy: 0.4739\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2079 - accuracy: 0.4745\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2076 - accuracy: 0.4751\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2073 - accuracy: 0.4761\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2070 - accuracy: 0.4771\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2067 - accuracy: 0.4782\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2064 - accuracy: 0.4795\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2061 - accuracy: 0.4811\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2058 - accuracy: 0.4827\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2056 - accuracy: 0.4847\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2053 - accuracy: 0.4871\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2050 - accuracy: 0.4892\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2047 - accuracy: 0.4917\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2045 - accuracy: 0.4941\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2042 - accuracy: 0.4971\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2039 - accuracy: 0.4998\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2037 - accuracy: 0.5026\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2034 - accuracy: 0.5052\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2031 - accuracy: 0.5080\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2029 - accuracy: 0.5105\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2026 - accuracy: 0.5127\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2024 - accuracy: 0.5147\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2021 - accuracy: 0.5166\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2019 - accuracy: 0.5186\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2017 - accuracy: 0.5202\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2014 - accuracy: 0.5217\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2012 - accuracy: 0.5234\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2010 - accuracy: 0.5248\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2008 - accuracy: 0.5262\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2005 - accuracy: 0.5271\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2003 - accuracy: 0.5282\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2001 - accuracy: 0.5290\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1999 - accuracy: 0.5300\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1998 - accuracy: 0.5308\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1996 - accuracy: 0.5315\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1994 - accuracy: 0.5321\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1992 - accuracy: 0.5329\n",
      "Epoch 60/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1990 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1989 - accuracy: 0.5341\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1987 - accuracy: 0.5344\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1985 - accuracy: 0.5350\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1984 - accuracy: 0.5354\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1982 - accuracy: 0.5358\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1981 - accuracy: 0.5364\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1980 - accuracy: 0.5370\n",
      "Epoch 68/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1978 - accuracy: 0.5373\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1977 - accuracy: 0.5378\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1975 - accuracy: 0.5381\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1974 - accuracy: 0.5385\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1973 - accuracy: 0.5388\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1972 - accuracy: 0.5389\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1970 - accuracy: 0.5398\n",
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1969 - accuracy: 0.5399\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1968 - accuracy: 0.5403\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1967 - accuracy: 0.5406\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1966 - accuracy: 0.5411\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1965 - accuracy: 0.5412\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1964 - accuracy: 0.5414\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1962 - accuracy: 0.5420\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1962 - accuracy: 0.5425\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1960 - accuracy: 0.5425\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1960 - accuracy: 0.5429\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1959 - accuracy: 0.5430\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1958 - accuracy: 0.5437\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1957 - accuracy: 0.5436\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1956 - accuracy: 0.5441\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1955 - accuracy: 0.5442\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1954 - accuracy: 0.5447\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1953 - accuracy: 0.5450\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1952 - accuracy: 0.5451\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1951 - accuracy: 0.5455\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1950 - accuracy: 0.5457\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1950 - accuracy: 0.5459\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1949 - accuracy: 0.5464\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1948 - accuracy: 0.5464\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1947 - accuracy: 0.5468\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1946 - accuracy: 0.5470\n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1945 - accuracy: 0.5473\n",
      "[0.19427863796394348, 0.55033123]\n",
      "Try 3/10: Best_val_acc: None, lr: 0.0001499483441132836, Lambda: 5.0292890120801135e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2408 - accuracy: 0.4252\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2275 - accuracy: 0.4707\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2194 - accuracy: 0.4728\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2142 - accuracy: 0.4739\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2109 - accuracy: 0.4755\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2086 - accuracy: 0.4784\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2070 - accuracy: 0.4825\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2057 - accuracy: 0.4881\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2046 - accuracy: 0.4946\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2037 - accuracy: 0.5013\n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2028 - accuracy: 0.5078\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2021 - accuracy: 0.5134\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2014 - accuracy: 0.5180\n",
      "Epoch 14/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2008 - accuracy: 0.5222\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2002 - accuracy: 0.5254\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1996 - accuracy: 0.5281\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1991 - accuracy: 0.5305\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1987 - accuracy: 0.5323\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1982 - accuracy: 0.5341\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1978 - accuracy: 0.5357\n",
      "Epoch 21/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1975 - accuracy: 0.5370\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1971 - accuracy: 0.5381\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1968 - accuracy: 0.5391\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1965 - accuracy: 0.5400\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1962 - accuracy: 0.5410\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1959 - accuracy: 0.5418\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1957 - accuracy: 0.5424\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1954 - accuracy: 0.5433\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1952 - accuracy: 0.5442\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1950 - accuracy: 0.5447\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1948 - accuracy: 0.5452\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1946 - accuracy: 0.5461\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1943 - accuracy: 0.5467\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1942 - accuracy: 0.5474\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1940 - accuracy: 0.5479\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1938 - accuracy: 0.5485\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1936 - accuracy: 0.5492\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1934 - accuracy: 0.5496\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1932 - accuracy: 0.5503\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1931 - accuracy: 0.5508\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1929 - accuracy: 0.5512\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1927 - accuracy: 0.5519\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1926 - accuracy: 0.5523\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1924 - accuracy: 0.5528\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1922 - accuracy: 0.5534\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1921 - accuracy: 0.5538\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1919 - accuracy: 0.5544\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1917 - accuracy: 0.5551\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1916 - accuracy: 0.5555\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1914 - accuracy: 0.5560\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1913 - accuracy: 0.5564\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1911 - accuracy: 0.5568\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1910 - accuracy: 0.5575\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1908 - accuracy: 0.5579\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1907 - accuracy: 0.5583\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1905 - accuracy: 0.5585\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1904 - accuracy: 0.5590\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1902 - accuracy: 0.5595\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1901 - accuracy: 0.5602\n",
      "Epoch 60/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1899 - accuracy: 0.5604\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1898 - accuracy: 0.5612\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1896 - accuracy: 0.5614\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1895 - accuracy: 0.5616\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1893 - accuracy: 0.5621\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1892 - accuracy: 0.5624\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1891 - accuracy: 0.5630\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1889 - accuracy: 0.5631\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1888 - accuracy: 0.5636\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1887 - accuracy: 0.5640\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1885 - accuracy: 0.5642\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1884 - accuracy: 0.5645\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1883 - accuracy: 0.5651\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1882 - accuracy: 0.5652\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1880 - accuracy: 0.5655\n",
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1879 - accuracy: 0.5658\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1878 - accuracy: 0.5659\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1877 - accuracy: 0.5664\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1876 - accuracy: 0.5669\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1874 - accuracy: 0.5669\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1873 - accuracy: 0.5673\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1872 - accuracy: 0.5675\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1871 - accuracy: 0.5681\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1870 - accuracy: 0.5683\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1869 - accuracy: 0.5685\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1868 - accuracy: 0.5689\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1867 - accuracy: 0.5692\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1866 - accuracy: 0.5695\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1865 - accuracy: 0.5697\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1864 - accuracy: 0.5699\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1863 - accuracy: 0.5702\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1862 - accuracy: 0.5705\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1861 - accuracy: 0.5709\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1860 - accuracy: 0.5707\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1859 - accuracy: 0.5713\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1859 - accuracy: 0.5712\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1858 - accuracy: 0.5717\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1857 - accuracy: 0.5722\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1856 - accuracy: 0.5721\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1855 - accuracy: 0.5725\n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1854 - accuracy: 0.5727\n",
      "[0.1847576647948784, 0.57519597]\n",
      "Try 4/10: Best_val_acc: None, lr: 0.000354872112228703, Lambda: 2.588893528455639e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2361 - accuracy: 0.3826\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2197 - accuracy: 0.4627\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2124 - accuracy: 0.4704\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2082 - accuracy: 0.4744\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2053 - accuracy: 0.4903\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2031 - accuracy: 0.5168\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2013 - accuracy: 0.5294\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2000 - accuracy: 0.5334\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1989 - accuracy: 0.5352\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1981 - accuracy: 0.5362\n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1974 - accuracy: 0.5370\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1968 - accuracy: 0.5382\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1963 - accuracy: 0.5393\n",
      "Epoch 14/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1959 - accuracy: 0.5404\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1954 - accuracy: 0.5415\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1950 - accuracy: 0.5427\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1946 - accuracy: 0.5442\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1943 - accuracy: 0.5452\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1939 - accuracy: 0.5463\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1936 - accuracy: 0.5475\n",
      "Epoch 21/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1932 - accuracy: 0.5485\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1929 - accuracy: 0.5497\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1926 - accuracy: 0.5507\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1923 - accuracy: 0.5517\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1920 - accuracy: 0.5528\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1917 - accuracy: 0.5537\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1914 - accuracy: 0.5545\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1911 - accuracy: 0.5551\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1908 - accuracy: 0.5565\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1905 - accuracy: 0.5574\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1902 - accuracy: 0.5582\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1899 - accuracy: 0.5591\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1896 - accuracy: 0.5597\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1893 - accuracy: 0.5608\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1890 - accuracy: 0.5614\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1888 - accuracy: 0.5623\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1885 - accuracy: 0.5630\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1883 - accuracy: 0.5634\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1880 - accuracy: 0.5645\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1878 - accuracy: 0.5650\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1876 - accuracy: 0.5657\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1874 - accuracy: 0.5665\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1872 - accuracy: 0.5672\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1870 - accuracy: 0.5677\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1868 - accuracy: 0.5680\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1866 - accuracy: 0.5687\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1864 - accuracy: 0.5694\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1862 - accuracy: 0.5698\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1860 - accuracy: 0.5704\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1859 - accuracy: 0.5708\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1857 - accuracy: 0.5712\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1855 - accuracy: 0.5718\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1854 - accuracy: 0.5723\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1853 - accuracy: 0.5725\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1851 - accuracy: 0.5730\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1849 - accuracy: 0.5734\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1848 - accuracy: 0.5736\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1847 - accuracy: 0.5744\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1845 - accuracy: 0.5747\n",
      "Epoch 60/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1844 - accuracy: 0.5748\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1843 - accuracy: 0.5752\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1842 - accuracy: 0.5756\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1840 - accuracy: 0.5759\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1839 - accuracy: 0.5762\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1838 - accuracy: 0.5765\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1837 - accuracy: 0.5767\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1836 - accuracy: 0.5771\n",
      "Epoch 68/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1835 - accuracy: 0.5774\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1834 - accuracy: 0.5776\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1833 - accuracy: 0.5781\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1832 - accuracy: 0.5781\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1831 - accuracy: 0.5785\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1830 - accuracy: 0.5789\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1829 - accuracy: 0.5788\n",
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1829 - accuracy: 0.5789\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1828 - accuracy: 0.5793\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1827 - accuracy: 0.5795\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1826 - accuracy: 0.5798\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1825 - accuracy: 0.5802\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1825 - accuracy: 0.5804\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1824 - accuracy: 0.5807\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1823 - accuracy: 0.5808\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1822 - accuracy: 0.5810\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1822 - accuracy: 0.5807\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1821 - accuracy: 0.5812\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1820 - accuracy: 0.5812\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1820 - accuracy: 0.5812\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1819 - accuracy: 0.5815\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1818 - accuracy: 0.5819\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1818 - accuracy: 0.5818\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1817 - accuracy: 0.5820\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1817 - accuracy: 0.5823\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1816 - accuracy: 0.5824\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1815 - accuracy: 0.5822\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1815 - accuracy: 0.5825\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1814 - accuracy: 0.5827\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1814 - accuracy: 0.5831\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1813 - accuracy: 0.5833\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1813 - accuracy: 0.5831\n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1812 - accuracy: 0.5835\n",
      "[0.1805756863383388, 0.58625346]\n",
      "Try 5/10: Best_val_acc: None, lr: 0.0007422361981160092, Lambda: 7.066457700089558e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2529 - accuracy: 0.2778\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2427 - accuracy: 0.3913\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2352 - accuracy: 0.4429\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2295 - accuracy: 0.4640\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2252 - accuracy: 0.4734\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2218 - accuracy: 0.4776\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2191 - accuracy: 0.4800\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2168 - accuracy: 0.4818\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2150 - accuracy: 0.4831\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2134 - accuracy: 0.4846\n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2121 - accuracy: 0.4862\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2110 - accuracy: 0.4876\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2101 - accuracy: 0.4893\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2093 - accuracy: 0.4913\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2085 - accuracy: 0.4933\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2079 - accuracy: 0.4955\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2073 - accuracy: 0.4979\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2068 - accuracy: 0.5001\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2063 - accuracy: 0.5024\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2058 - accuracy: 0.5045\n",
      "Epoch 21/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2053 - accuracy: 0.5071\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2049 - accuracy: 0.5091\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2045 - accuracy: 0.5115\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2040 - accuracy: 0.5134\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2037 - accuracy: 0.5156\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2033 - accuracy: 0.5175\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2029 - accuracy: 0.5193\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2025 - accuracy: 0.5209\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2022 - accuracy: 0.5225\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2018 - accuracy: 0.5238\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2015 - accuracy: 0.5252\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2012 - accuracy: 0.5266\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2008 - accuracy: 0.5275\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2005 - accuracy: 0.5285\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2002 - accuracy: 0.5297\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1999 - accuracy: 0.5309\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1997 - accuracy: 0.5315\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1994 - accuracy: 0.5326\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1991 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1989 - accuracy: 0.5340\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1986 - accuracy: 0.5347\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1984 - accuracy: 0.5354\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1982 - accuracy: 0.5359\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1980 - accuracy: 0.5369\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1978 - accuracy: 0.5370\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1976 - accuracy: 0.5379\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1973 - accuracy: 0.5384\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1972 - accuracy: 0.5385\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1970 - accuracy: 0.5393\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1968 - accuracy: 0.5394\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1966 - accuracy: 0.5402\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1965 - accuracy: 0.5405\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1963 - accuracy: 0.5410\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1961 - accuracy: 0.5414\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1960 - accuracy: 0.5417\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1958 - accuracy: 0.5421\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1957 - accuracy: 0.5424\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1955 - accuracy: 0.5429\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1954 - accuracy: 0.5431\n",
      "Epoch 60/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1953 - accuracy: 0.5436\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1951 - accuracy: 0.5437\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1950 - accuracy: 0.5442\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1949 - accuracy: 0.5445\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1947 - accuracy: 0.5448\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1946 - accuracy: 0.5452\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1945 - accuracy: 0.5455\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1944 - accuracy: 0.5458\n",
      "Epoch 68/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1943 - accuracy: 0.5461\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1942 - accuracy: 0.5465\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1941 - accuracy: 0.5467\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1939 - accuracy: 0.5468\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1938 - accuracy: 0.5475\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1937 - accuracy: 0.5476\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1936 - accuracy: 0.5479\n",
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1935 - accuracy: 0.5483\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1934 - accuracy: 0.5485\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1933 - accuracy: 0.5487\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1932 - accuracy: 0.5491\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1931 - accuracy: 0.5495\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1930 - accuracy: 0.5494\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1929 - accuracy: 0.5500\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1928 - accuracy: 0.5505\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1927 - accuracy: 0.5503\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1926 - accuracy: 0.5506\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1926 - accuracy: 0.5508\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1925 - accuracy: 0.5513\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1924 - accuracy: 0.5513\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1923 - accuracy: 0.5516\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1922 - accuracy: 0.5520\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1921 - accuracy: 0.5521\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1920 - accuracy: 0.5522\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1919 - accuracy: 0.5528\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1919 - accuracy: 0.5528\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1918 - accuracy: 0.5532\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1917 - accuracy: 0.5533\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1916 - accuracy: 0.5539\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1915 - accuracy: 0.5539\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1914 - accuracy: 0.5543\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1914 - accuracy: 0.5544\n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1913 - accuracy: 0.5548\n",
      "[0.1908230269375058, 0.5572104]\n",
      "Try 6/10: Best_val_acc: None, lr: 0.0001595958553673771, Lambda: 3.893115190233336e-05\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2357 - accuracy: 0.4715\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2201 - accuracy: 0.4719\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2134 - accuracy: 0.4721\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2099 - accuracy: 0.4732\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2074 - accuracy: 0.4818\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2054 - accuracy: 0.4982\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2037 - accuracy: 0.5098\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2023 - accuracy: 0.5173\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2011 - accuracy: 0.5221\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2000 - accuracy: 0.52600s - loss: 0.2001 - \n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1992 - accuracy: 0.5293\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1985 - accuracy: 0.5317\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1978 - accuracy: 0.53410s -\n",
      "Epoch 14/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1973 - accuracy: 0.5360\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1968 - accuracy: 0.5378\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1963 - accuracy: 0.5391\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1959 - accuracy: 0.5406\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1955 - accuracy: 0.54200s - loss: 0.1955 - accuracy\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1951 - accuracy: 0.5431\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1948 - accuracy: 0.5443\n",
      "Epoch 21/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1944 - accuracy: 0.5454\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1941 - accuracy: 0.5467\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1937 - accuracy: 0.5478\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1934 - accuracy: 0.5488\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1930 - accuracy: 0.5502\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1927 - accuracy: 0.5507\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1923 - accuracy: 0.5519\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1920 - accuracy: 0.5528\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1917 - accuracy: 0.5537\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1914 - accuracy: 0.5546\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1911 - accuracy: 0.5556\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1908 - accuracy: 0.5565\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1904 - accuracy: 0.5574\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1902 - accuracy: 0.5582\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1899 - accuracy: 0.5589\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1896 - accuracy: 0.5599\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1893 - accuracy: 0.5607\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 4us/sample - loss: 0.1891 - accuracy: 0.5612\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1888 - accuracy: 0.5617\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1886 - accuracy: 0.5623\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1884 - accuracy: 0.5629\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1881 - accuracy: 0.5634\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1879 - accuracy: 0.5639\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1877 - accuracy: 0.5645\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1875 - accuracy: 0.5651\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1873 - accuracy: 0.5655\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1871 - accuracy: 0.5661\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1870 - accuracy: 0.5666\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1868 - accuracy: 0.5672\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1866 - accuracy: 0.5678\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1865 - accuracy: 0.5679\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1863 - accuracy: 0.5686\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1862 - accuracy: 0.5691\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1860 - accuracy: 0.5694\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1859 - accuracy: 0.5698\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1857 - accuracy: 0.5703\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1856 - accuracy: 0.5706\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1855 - accuracy: 0.57080s - loss: 0.1855 - accuracy: 0.\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1853 - accuracy: 0.5712\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1852 - accuracy: 0.5714\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1851 - accuracy: 0.5719\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1849 - accuracy: 0.5723\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1848 - accuracy: 0.5726\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1847 - accuracy: 0.5728\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1846 - accuracy: 0.5732\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1845 - accuracy: 0.5734\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1844 - accuracy: 0.5737\n",
      "Epoch 68/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1843 - accuracy: 0.5741\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1842 - accuracy: 0.5741\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1841 - accuracy: 0.5743\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1840 - accuracy: 0.5744\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1839 - accuracy: 0.5750\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1838 - accuracy: 0.5752\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1837 - accuracy: 0.5756\n",
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1836 - accuracy: 0.5758\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1835 - accuracy: 0.5760\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1835 - accuracy: 0.5760\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1833 - accuracy: 0.5765\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1833 - accuracy: 0.57660s - loss: 0.1833 - ac\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1832 - accuracy: 0.5769\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1831 - accuracy: 0.5772\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1830 - accuracy: 0.5774\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1830 - accuracy: 0.5775\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1829 - accuracy: 0.5776\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1828 - accuracy: 0.5777\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1828 - accuracy: 0.5779\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1827 - accuracy: 0.5780\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1826 - accuracy: 0.5783\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1826 - accuracy: 0.5784\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1825 - accuracy: 0.5787\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1824 - accuracy: 0.5793\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1824 - accuracy: 0.5788\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1823 - accuracy: 0.5791\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1823 - accuracy: 0.5793\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1822 - accuracy: 0.5797\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1821 - accuracy: 0.5797\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1821 - accuracy: 0.5797\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1820 - accuracy: 0.5799\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1820 - accuracy: 0.57980s - loss: 0.1821 \n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1819 - accuracy: 0.5801\n",
      "[0.18134847044738875, 0.5830439]\n",
      "Try 7/10: Best_val_acc: None, lr: 0.0006810585501297726, Lambda: 7.68520005919144e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,8):\n",
    "    lr = math.pow(10, np.random.uniform(-4.0, -3.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5.0,-4.0))\n",
    "    best_acc = train_and_test_loop(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c81ff9",
   "metadata": {},
   "source": [
    "###### Nonetheless, it is difficult to improve the Neural Network fit even despite narrowing down on the learning rate and lambda value ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "75ab35da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 4s 7us/sample - loss: 0.2021 - accuracy: 0.5464\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1875 - accuracy: 0.57870s - loss: 0.1879 - ac\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1821 - accuracy: 0.58801s - ETA: 0s - loss: 0.1823 - accuracy:  - ETA: 0s - loss: 0.1823 - ac\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.59 - 3s 5us/sample - loss: 0.1790 - accuracy: 0.5929\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1769 - accuracy: 0.59601s - loss: 0\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1753 - accuracy: 0.59840s - loss: 0.1754 - accuracy\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1741 - accuracy: 0.6003\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1731 - accuracy: 0.6018\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1722 - accuracy: 0.6042\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1714 - accuracy: 0.6056\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1708 - accuracy: 0.6069\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1701 - accuracy: 0.6087\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1696 - accuracy: 0.60970s - loss: 0.1696 - accura\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1690 - accuracy: 0.6112\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1685 - accuracy: 0.6126\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1680 - accuracy: 0.6138\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1676 - accuracy: 0.6147\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1672 - accuracy: 0.6161\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1667 - accuracy: 0.6176\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1663 - accuracy: 0.6184\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1659 - accuracy: 0.6197\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1655 - accuracy: 0.6210\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1652 - accuracy: 0.6220\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1648 - accuracy: 0.6227\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1645 - accuracy: 0.6241\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1641 - accuracy: 0.6247\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1638 - accuracy: 0.6262\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1634 - accuracy: 0.6269\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1631 - accuracy: 0.6281\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1628 - accuracy: 0.6287\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1626 - accuracy: 0.6296\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1623 - accuracy: 0.6302\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1620 - accuracy: 0.6313\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1617 - accuracy: 0.6324\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1614 - accuracy: 0.6329\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1612 - accuracy: 0.6336\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1608 - accuracy: 0.6349\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1606 - accuracy: 0.6358\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1604 - accuracy: 0.6361\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1601 - accuracy: 0.6372\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1598 - accuracy: 0.6380\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1596 - accuracy: 0.6384\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1593 - accuracy: 0.6394\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1592 - accuracy: 0.6399\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1590 - accuracy: 0.6405\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1588 - accuracy: 0.6416\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 4s 7us/sample - loss: 0.1585 - accuracy: 0.6421\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 4s 7us/sample - loss: 0.1582 - accuracy: 0.6429\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1580 - accuracy: 0.6438\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1578 - accuracy: 0.6443\n",
      "Try 1/10: Best_val_acc: None, lr: 0.017722015080147924, Lambda: 0.0017666871837345405\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 4s 7us/sample - loss: 0.2601 - accuracy: 0.4681\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2101 - accuracy: 0.47180s - l\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2064 - accuracy: 0.4722\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2030 - accuracy: 0.5089\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.2005 - accuracy: 0.5431\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1987 - accuracy: 0.5484\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1973 - accuracy: 0.5507\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1961 - accuracy: 0.55320s - loss: 0.1961 - accuracy:  - ETA: 0s - loss: 0.1961 - accura - ETA: 0s - loss: 0.1961 - accuracy: 0.\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1950 - accuracy: 0.5551\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1941 - accuracy: 0.5575\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1931 - accuracy: 0.5600\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1923 - accuracy: 0.5622\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1914 - accuracy: 0.5647\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1907 - accuracy: 0.5672\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1900 - accuracy: 0.5692\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1893 - accuracy: 0.5711\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1886 - accuracy: 0.5730\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1881 - accuracy: 0.5742\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1875 - accuracy: 0.5755\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1870 - accuracy: 0.5768\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1865 - accuracy: 0.5780\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1861 - accuracy: 0.5788\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1856 - accuracy: 0.5795\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1853 - accuracy: 0.5803\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1849 - accuracy: 0.5811\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1846 - accuracy: 0.5816\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1844 - accuracy: 0.5821\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1840 - accuracy: 0.5829\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1837 - accuracy: 0.5831\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1835 - accuracy: 0.5836\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1831 - accuracy: 0.5842\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1830 - accuracy: 0.5841\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1827 - accuracy: 0.5848\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1825 - accuracy: 0.5855\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1823 - accuracy: 0.5857\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1821 - accuracy: 0.5858\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1819 - accuracy: 0.5860\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1817 - accuracy: 0.5867\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1816 - accuracy: 0.5871\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1814 - accuracy: 0.5873\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1812 - accuracy: 0.58780s - loss: 0.1812 - ac\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1811 - accuracy: 0.5878\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1810 - accuracy: 0.5884\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1808 - accuracy: 0.5887\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1807 - accuracy: 0.5890\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1804 - accuracy: 0.5895\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1802 - accuracy: 0.58950s - loss: 0.1801 - accuracy\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1802 - accuracy: 0.5895\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1799 - accuracy: 0.5901\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1798 - accuracy: 0.5905\n",
      "Try 2/10: Best_val_acc: None, lr: 0.0054903805635708606, Lambda: 0.21041422573348215\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.2827 - accuracy: 0.4919\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2288 - accuracy: 0.5315\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2109 - accuracy: 0.5425\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2036 - accuracy: 0.5462\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2002 - accuracy: 0.5488\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1981 - accuracy: 0.5514\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1967 - accuracy: 0.5536\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1956 - accuracy: 0.5556\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1945 - accuracy: 0.5578\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1936 - accuracy: 0.5599\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1928 - accuracy: 0.5622\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1920 - accuracy: 0.56390s - l\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1912 - accuracy: 0.5659\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1905 - accuracy: 0.5675\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1898 - accuracy: 0.5689\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1892 - accuracy: 0.5703\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1886 - accuracy: 0.5716\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1881 - accuracy: 0.57281s - loss: 0.1883 - ac -\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1876 - accuracy: 0.5739\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1872 - accuracy: 0.5750\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1867 - accuracy: 0.5757\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1863 - accuracy: 0.5766\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1858 - accuracy: 0.5774\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1854 - accuracy: 0.5781\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1851 - accuracy: 0.5787\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1847 - accuracy: 0.5795\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1844 - accuracy: 0.5801\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1840 - accuracy: 0.5807\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1837 - accuracy: 0.5813\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1834 - accuracy: 0.5817\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1831 - accuracy: 0.5822\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1829 - accuracy: 0.5829\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1826 - accuracy: 0.5832\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1823 - accuracy: 0.5837\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1821 - accuracy: 0.5840\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1819 - accuracy: 0.5845\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1817 - accuracy: 0.5852\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1815 - accuracy: 0.5857\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1812 - accuracy: 0.5864\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1810 - accuracy: 0.5874\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1809 - accuracy: 0.5876\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1807 - accuracy: 0.5881\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1805 - accuracy: 0.5884\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1803 - accuracy: 0.58901s - loss: 0.1801 - ac - ETA: 1s - loss: 0.1 - ETA: 1s - ETA: 0s - loss: 0.1803 - accuracy: 0.\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1802 - accuracy: 0.5893\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1800 - accuracy: 0.5897\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1798 - accuracy: 0.5902\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1797 - accuracy: 0.5906\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1795 - accuracy: 0.5908\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1794 - accuracy: 0.5912\n",
      "Try 3/10: Best_val_acc: None, lr: 0.0021093935219443005, Lambda: 0.02237656317656814\n",
      "\n",
      "Train on 579091 samples\n",
      "Epoch 1/50\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.2587 - accuracy: 0.2662\n",
      "Epoch 2/50\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.34 - 3s 6us/sample - loss: 0.2478 - accuracy: 0.3443\n",
      "Epoch 3/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2402 - accuracy: 0.3979\n",
      "Epoch 4/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2344 - accuracy: 0.4317\n",
      "Epoch 5/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2297 - accuracy: 0.4539\n",
      "Epoch 6/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2258 - accuracy: 0.4695\n",
      "Epoch 7/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2224 - accuracy: 0.4808\n",
      "Epoch 8/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2196 - accuracy: 0.4897\n",
      "Epoch 9/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2172 - accuracy: 0.4974\n",
      "Epoch 10/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2151 - accuracy: 0.5030\n",
      "Epoch 11/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2133 - accuracy: 0.5082\n",
      "Epoch 12/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2118 - accuracy: 0.5129\n",
      "Epoch 13/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2104 - accuracy: 0.5168\n",
      "Epoch 14/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2093 - accuracy: 0.5201\n",
      "Epoch 15/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2082 - accuracy: 0.5229\n",
      "Epoch 16/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2073 - accuracy: 0.5255\n",
      "Epoch 17/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2066 - accuracy: 0.5274\n",
      "Epoch 18/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2059 - accuracy: 0.5294\n",
      "Epoch 19/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2052 - accuracy: 0.5308\n",
      "Epoch 20/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2047 - accuracy: 0.5321\n",
      "Epoch 21/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2042 - accuracy: 0.5337\n",
      "Epoch 22/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2037 - accuracy: 0.5344\n",
      "Epoch 23/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2033 - accuracy: 0.5356\n",
      "Epoch 24/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2029 - accuracy: 0.5365\n",
      "Epoch 25/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2025 - accuracy: 0.5372\n",
      "Epoch 26/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2022 - accuracy: 0.5381\n",
      "Epoch 27/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.2019 - accuracy: 0.5390\n",
      "Epoch 28/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2016 - accuracy: 0.5395\n",
      "Epoch 29/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2013 - accuracy: 0.5401\n",
      "Epoch 30/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2011 - accuracy: 0.5408\n",
      "Epoch 31/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2008 - accuracy: 0.5410\n",
      "Epoch 32/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2006 - accuracy: 0.5418\n",
      "Epoch 33/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2004 - accuracy: 0.5422\n",
      "Epoch 34/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2002 - accuracy: 0.54260s - loss: 0\n",
      "Epoch 35/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.2000 - accuracy: 0.5431\n",
      "Epoch 36/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1998 - accuracy: 0.5433\n",
      "Epoch 37/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1996 - accuracy: 0.5439\n",
      "Epoch 38/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1994 - accuracy: 0.5442\n",
      "Epoch 39/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1992 - accuracy: 0.5446\n",
      "Epoch 40/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1991 - accuracy: 0.5449\n",
      "Epoch 41/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1989 - accuracy: 0.5451\n",
      "Epoch 42/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1987 - accuracy: 0.5456\n",
      "Epoch 43/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1986 - accuracy: 0.5458\n",
      "Epoch 44/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1984 - accuracy: 0.5462\n",
      "Epoch 45/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1983 - accuracy: 0.5464\n",
      "Epoch 46/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1981 - accuracy: 0.5467\n",
      "Epoch 47/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1980 - accuracy: 0.5470\n",
      "Epoch 48/50\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1979 - accuracy: 0.5473\n",
      "Epoch 49/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1977 - accuracy: 0.5475\n",
      "Epoch 50/50\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1976 - accuracy: 0.5477\n",
      "Try 4/10: Best_val_acc: None, lr: 6.522871845750783e-05, Lambda: 0.00010511549191348351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,5):\n",
    "    lr = math.pow(10, np.random.uniform(-5.0, -1))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5,0))\n",
    "    best_acc = train_and_test_loop1(50, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8a30b",
   "metadata": {},
   "source": [
    "lr =  0.017722015080147924\n",
    "Lambda = 0.001766687183734540564\n",
    "\n",
    "##### At the above pair of values, the neural network seems to fit the data better with more iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4e8113e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "Epoch 1/100\n",
      "579091/579091 [==============================] - 13s 23us/sample - loss: 0.2023 - accuracy: 0.5495\n",
      "Epoch 2/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1874 - accuracy: 0.5774\n",
      "Epoch 3/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1818 - accuracy: 0.5870\n",
      "Epoch 4/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1787 - accuracy: 0.5931\n",
      "Epoch 5/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1767 - accuracy: 0.5966\n",
      "Epoch 6/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1752 - accuracy: 0.5988\n",
      "Epoch 7/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1741 - accuracy: 0.6006\n",
      "Epoch 8/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1731 - accuracy: 0.6020\n",
      "Epoch 9/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1723 - accuracy: 0.6038\n",
      "Epoch 10/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1716 - accuracy: 0.6054\n",
      "Epoch 11/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1709 - accuracy: 0.6064\n",
      "Epoch 12/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1703 - accuracy: 0.6082\n",
      "Epoch 13/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1697 - accuracy: 0.6093\n",
      "Epoch 14/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1691 - accuracy: 0.6106\n",
      "Epoch 15/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1687 - accuracy: 0.6119\n",
      "Epoch 16/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1682 - accuracy: 0.6129\n",
      "Epoch 17/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1677 - accuracy: 0.6142\n",
      "Epoch 18/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1672 - accuracy: 0.6155\n",
      "Epoch 19/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1668 - accuracy: 0.6168\n",
      "Epoch 20/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1664 - accuracy: 0.6184\n",
      "Epoch 21/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1661 - accuracy: 0.6188\n",
      "Epoch 22/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1657 - accuracy: 0.6195\n",
      "Epoch 23/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1653 - accuracy: 0.6210\n",
      "Epoch 24/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1649 - accuracy: 0.6220\n",
      "Epoch 25/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1646 - accuracy: 0.6231\n",
      "Epoch 26/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1643 - accuracy: 0.6237\n",
      "Epoch 27/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1639 - accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1636 - accuracy: 0.6258\n",
      "Epoch 29/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1633 - accuracy: 0.6270\n",
      "Epoch 30/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1630 - accuracy: 0.6279\n",
      "Epoch 31/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1627 - accuracy: 0.6287\n",
      "Epoch 32/100\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1624 - accuracy: 0.6298\n",
      "Epoch 33/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1621 - accuracy: 0.6306\n",
      "Epoch 34/100\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1618 - accuracy: 0.6318\n",
      "Epoch 35/100\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1616 - accuracy: 0.6323\n",
      "Epoch 36/100\n",
      "579091/579091 [==============================] - 4s 7us/sample - loss: 0.1614 - accuracy: 0.6329\n",
      "Epoch 37/100\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1610 - accuracy: 0.6338\n",
      "Epoch 38/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1608 - accuracy: 0.6348\n",
      "Epoch 39/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1605 - accuracy: 0.6354\n",
      "Epoch 40/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1603 - accuracy: 0.6360\n",
      "Epoch 41/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1600 - accuracy: 0.6373\n",
      "Epoch 42/100\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1597 - accuracy: 0.6378\n",
      "Epoch 43/100\n",
      "579091/579091 [==============================] - 4s 6us/sample - loss: 0.1595 - accuracy: 0.6383\n",
      "Epoch 44/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1593 - accuracy: 0.6389\n",
      "Epoch 45/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1590 - accuracy: 0.6397\n",
      "Epoch 46/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1588 - accuracy: 0.6408\n",
      "Epoch 47/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1585 - accuracy: 0.6414\n",
      "Epoch 48/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1584 - accuracy: 0.6422\n",
      "Epoch 49/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1581 - accuracy: 0.6426\n",
      "Epoch 50/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1578 - accuracy: 0.6435\n",
      "Epoch 51/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1577 - accuracy: 0.6439\n",
      "Epoch 52/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1575 - accuracy: 0.6447\n",
      "Epoch 53/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1572 - accuracy: 0.6454\n",
      "Epoch 54/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1570 - accuracy: 0.6462\n",
      "Epoch 55/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1568 - accuracy: 0.6470\n",
      "Epoch 56/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1565 - accuracy: 0.6479\n",
      "Epoch 57/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1564 - accuracy: 0.6484\n",
      "Epoch 58/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1562 - accuracy: 0.6488\n",
      "Epoch 59/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1560 - accuracy: 0.6495\n",
      "Epoch 60/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1558 - accuracy: 0.6503\n",
      "Epoch 61/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1556 - accuracy: 0.6504\n",
      "Epoch 62/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1554 - accuracy: 0.6511\n",
      "Epoch 63/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1551 - accuracy: 0.6524\n",
      "Epoch 64/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1550 - accuracy: 0.6525\n",
      "Epoch 65/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1549 - accuracy: 0.6537\n",
      "Epoch 66/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1547 - accuracy: 0.6539\n",
      "Epoch 67/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1545 - accuracy: 0.6545\n",
      "Epoch 68/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1543 - accuracy: 0.6548\n",
      "Epoch 69/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1541 - accuracy: 0.6560\n",
      "Epoch 70/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1540 - accuracy: 0.6557\n",
      "Epoch 71/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1538 - accuracy: 0.6569\n",
      "Epoch 72/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1537 - accuracy: 0.6571\n",
      "Epoch 73/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1535 - accuracy: 0.6579\n",
      "Epoch 74/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1534 - accuracy: 0.6580\n",
      "Epoch 75/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1532 - accuracy: 0.6591\n",
      "Epoch 76/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1530 - accuracy: 0.6594\n",
      "Epoch 77/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1528 - accuracy: 0.6602\n",
      "Epoch 78/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1527 - accuracy: 0.6610\n",
      "Epoch 79/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1526 - accuracy: 0.6610\n",
      "Epoch 80/100\n",
      "579091/579091 [==============================] - 3s 6us/sample - loss: 0.1524 - accuracy: 0.6614\n",
      "Epoch 81/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1522 - accuracy: 0.6622\n",
      "Epoch 82/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1521 - accuracy: 0.6625\n",
      "Epoch 83/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1519 - accuracy: 0.6631\n",
      "Epoch 84/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1518 - accuracy: 0.6635\n",
      "Epoch 85/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1517 - accuracy: 0.6636\n",
      "Epoch 86/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1516 - accuracy: 0.6637\n",
      "Epoch 87/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1514 - accuracy: 0.6646\n",
      "Epoch 88/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1513 - accuracy: 0.6651\n",
      "Epoch 89/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1511 - accuracy: 0.6657\n",
      "Epoch 90/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1509 - accuracy: 0.6663\n",
      "Epoch 91/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1508 - accuracy: 0.6669\n",
      "Epoch 92/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1507 - accuracy: 0.6666\n",
      "Epoch 93/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1506 - accuracy: 0.6670\n",
      "Epoch 94/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1505 - accuracy: 0.6678\n",
      "Epoch 95/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1504 - accuracy: 0.6680\n",
      "Epoch 96/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1502 - accuracy: 0.6688\n",
      "Epoch 97/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1500 - accuracy: 0.6692\n",
      "Epoch 98/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1499 - accuracy: 0.6694\n",
      "Epoch 99/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1498 - accuracy: 0.6699\n",
      "Epoch 100/100\n",
      "579091/579091 [==============================] - 3s 5us/sample - loss: 0.1497 - accuracy: 0.6705\n"
     ]
    }
   ],
   "source": [
    "lr =  0.017722015080147924\n",
    "Lambda = 0.001766687183734540564\n",
    "\n",
    "score = train_and_test_loop1(100, lr, Lambda, False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98d81c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_loop1(iterations, lr, Lambda,batch_size,verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape = (300,),kernel_initializer='he_normal',activation=None))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(3,activation='sigmoid', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "\n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(x_tr,y_tr_cat, epochs=iterations, batch_size= batch_size, verbose= 1)\n",
    "    score = model.evaluate(x_te, y_te_cat, verbose=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b738bd",
   "metadata": {},
   "source": [
    "##### few more hidden layers with more neurons and iterations, the model seems to fit the data much better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73aeca25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "Epoch 1/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1876 - accuracy: 0.5767\n",
      "Epoch 2/200\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1760 - accuracy: 0.5953\n",
      "Epoch 3/200\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1726 - accuracy: 0.6014\n",
      "Epoch 4/200\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1706 - accuracy: 0.6058\n",
      "Epoch 5/200\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1690 - accuracy: 0.6096\n",
      "Epoch 6/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1678 - accuracy: 0.6130\n",
      "Epoch 7/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1665 - accuracy: 0.6168\n",
      "Epoch 8/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1655 - accuracy: 0.6196s\n",
      "Epoch 9/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1646 - accuracy: 0.6218\n",
      "Epoch 10/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1637 - accuracy: 0.6247\n",
      "Epoch 11/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1629 - accuracy: 0.6269\n",
      "Epoch 12/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1622 - accuracy: 0.6288\n",
      "Epoch 13/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1616 - accuracy: 0.6311\n",
      "Epoch 14/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1609 - accuracy: 0.6329\n",
      "Epoch 15/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1604 - accuracy: 0.6348\n",
      "Epoch 16/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1598 - accuracy: 0.6367\n",
      "Epoch 17/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1593 - accuracy: 0.6379\n",
      "Epoch 18/200\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1588 - accuracy: 0.6393\n",
      "Epoch 19/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1583 - accuracy: 0.6414\n",
      "Epoch 20/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1578 - accuracy: 0.6423\n",
      "Epoch 21/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1573 - accuracy: 0.6446\n",
      "Epoch 22/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1570 - accuracy: 0.6452s - loss: 0.156\n",
      "Epoch 23/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1565 - accuracy: 0.6467\n",
      "Epoch 24/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1562 - accuracy: 0.6479\n",
      "Epoch 25/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1558 - accuracy: 0.6489s - loss: 0.155\n",
      "Epoch 26/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1554 - accuracy: 0.6501\n",
      "Epoch 27/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1551 - accuracy: 0.6516\n",
      "Epoch 28/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1547 - accuracy: 0.6524\n",
      "Epoch 29/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1543 - accuracy: 0.6537\n",
      "Epoch 30/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1540 - accuracy: 0.6546\n",
      "Epoch 31/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1536 - accuracy: 0.6560\n",
      "Epoch 32/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1534 - accuracy: 0.6568\n",
      "Epoch 33/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1531 - accuracy: 0.6581\n",
      "Epoch 34/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1528 - accuracy: 0.6592\n",
      "Epoch 35/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1524 - accuracy: 0.6598\n",
      "Epoch 36/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1520 - accuracy: 0.6607\n",
      "Epoch 37/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1519 - accuracy: 0.6618\n",
      "Epoch 38/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1516 - accuracy: 0.6631\n",
      "Epoch 39/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1514 - accuracy: 0.6632\n",
      "Epoch 40/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1510 - accuracy: 0.6644\n",
      "Epoch 41/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1509 - accuracy: 0.6647\n",
      "Epoch 42/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1506 - accuracy: 0.6654\n",
      "Epoch 43/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1504 - accuracy: 0.6663\n",
      "Epoch 44/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1502 - accuracy: 0.6672\n",
      "Epoch 45/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1499 - accuracy: 0.6679\n",
      "Epoch 46/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1497 - accuracy: 0.6685s - loss: 0.1496 - ac\n",
      "Epoch 47/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1495 - accuracy: 0.6690\n",
      "Epoch 48/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1494 - accuracy: 0.6699\n",
      "Epoch 49/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1491 - accuracy: 0.6704\n",
      "Epoch 50/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1490 - accuracy: 0.6706\n",
      "Epoch 51/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1487 - accuracy: 0.6714\n",
      "Epoch 52/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1485 - accuracy: 0.6721\n",
      "Epoch 53/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1485 - accuracy: 0.6719\n",
      "Epoch 54/200\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1482 - accuracy: 0.6733\n",
      "Epoch 55/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1480 - accuracy: 0.6735\n",
      "Epoch 56/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1479 - accuracy: 0.6735s - loss: 0.1479 - accuracy: 0.\n",
      "Epoch 57/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1477 - accuracy: 0.6751\n",
      "Epoch 58/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1475 - accuracy: 0.6757\n",
      "Epoch 59/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1475 - accuracy: 0.6755\n",
      "Epoch 60/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1472 - accuracy: 0.6760\n",
      "Epoch 61/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1471 - accuracy: 0.6766\n",
      "Epoch 62/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1470 - accuracy: 0.6770\n",
      "Epoch 63/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1469 - accuracy: 0.6769\n",
      "Epoch 64/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1467 - accuracy: 0.6777\n",
      "Epoch 65/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1466 - accuracy: 0.6780\n",
      "Epoch 66/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1465 - accuracy: 0.6787\n",
      "Epoch 67/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1463 - accuracy: 0.6792\n",
      "Epoch 68/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1461 - accuracy: 0.6796\n",
      "Epoch 69/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1460 - accuracy: 0.6798\n",
      "Epoch 70/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1459 - accuracy: 0.6801\n",
      "Epoch 71/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1457 - accuracy: 0.6810\n",
      "Epoch 72/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1456 - accuracy: 0.6810\n",
      "Epoch 73/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1455 - accuracy: 0.6816\n",
      "Epoch 74/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1454 - accuracy: 0.6819\n",
      "Epoch 75/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1452 - accuracy: 0.6823\n",
      "Epoch 76/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1451 - accuracy: 0.6828\n",
      "Epoch 77/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1451 - accuracy: 0.6824\n",
      "Epoch 78/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1450 - accuracy: 0.6829\n",
      "Epoch 79/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1448 - accuracy: 0.6840\n",
      "Epoch 80/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1447 - accuracy: 0.6837\n",
      "Epoch 81/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1446 - accuracy: 0.6839\n",
      "Epoch 82/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1445 - accuracy: 0.6849\n",
      "Epoch 83/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1445 - accuracy: 0.6847\n",
      "Epoch 84/200\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1441 - accuracy: 0.6859\n",
      "Epoch 85/200\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1442 - accuracy: 0.6860\n",
      "Epoch 86/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1441 - accuracy: 0.6859\n",
      "Epoch 87/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1438 - accuracy: 0.6867\n",
      "Epoch 88/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1439 - accuracy: 0.6866\n",
      "Epoch 89/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1437 - accuracy: 0.6869\n",
      "Epoch 90/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1436 - accuracy: 0.6878\n",
      "Epoch 91/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1437 - accuracy: 0.6875\n",
      "Epoch 92/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1435 - accuracy: 0.6881\n",
      "Epoch 93/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1434 - accuracy: 0.6876\n",
      "Epoch 94/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1433 - accuracy: 0.6884\n",
      "Epoch 95/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1432 - accuracy: 0.6888\n",
      "Epoch 96/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1431 - accuracy: 0.6890\n",
      "Epoch 97/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1430 - accuracy: 0.6890s - loss: 0.1431 - ac\n",
      "Epoch 98/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1430 - accuracy: 0.6891\n",
      "Epoch 99/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1430 - accuracy: 0.6894\n",
      "Epoch 100/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1429 - accuracy: 0.6896\n",
      "Epoch 101/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1427 - accuracy: 0.6899s - loss: 0.142\n",
      "Epoch 102/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1427 - accuracy: 0.6903\n",
      "Epoch 103/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1426 - accuracy: 0.6903\n",
      "Epoch 104/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1425 - accuracy: 0.6913- ETA: 0s - loss: 0.1425 - ac\n",
      "Epoch 105/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1424 - accuracy: 0.6912\n",
      "Epoch 106/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1424 - accuracy: 0.6911\n",
      "Epoch 107/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1423 - accuracy: 0.6915\n",
      "Epoch 108/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1422 - accuracy: 0.6914\n",
      "Epoch 109/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1421 - accuracy: 0.6922\n",
      "Epoch 110/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1421 - accuracy: 0.6922\n",
      "Epoch 111/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1420 - accuracy: 0.6924\n",
      "Epoch 112/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1420 - accuracy: 0.6923\n",
      "Epoch 113/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1418 - accuracy: 0.6929\n",
      "Epoch 114/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1418 - accuracy: 0.6930\n",
      "Epoch 115/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1418 - accuracy: 0.6933\n",
      "Epoch 116/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1416 - accuracy: 0.6934\n",
      "Epoch 117/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1415 - accuracy: 0.6942\n",
      "Epoch 118/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1415 - accuracy: 0.6941\n",
      "Epoch 119/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1414 - accuracy: 0.6942\n",
      "Epoch 120/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1414 - accuracy: 0.6944\n",
      "Epoch 121/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1413 - accuracy: 0.6941\n",
      "Epoch 122/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1413 - accuracy: 0.6949\n",
      "Epoch 123/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1412 - accuracy: 0.6950\n",
      "Epoch 124/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1413 - accuracy: 0.6945\n",
      "Epoch 125/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1412 - accuracy: 0.6950\n",
      "Epoch 126/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1411 - accuracy: 0.6955s - loss:\n",
      "Epoch 127/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1410 - accuracy: 0.6952\n",
      "Epoch 128/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1410 - accuracy: 0.6955\n",
      "Epoch 129/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1408 - accuracy: 0.6960\n",
      "Epoch 130/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1408 - accuracy: 0.6963\n",
      "Epoch 131/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1407 - accuracy: 0.6963s - loss: 0\n",
      "Epoch 132/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1407 - accuracy: 0.6966\n",
      "Epoch 133/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1406 - accuracy: 0.6971\n",
      "Epoch 134/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1406 - accuracy: 0.6968\n",
      "Epoch 135/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1406 - accuracy: 0.6968\n",
      "Epoch 136/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1404 - accuracy: 0.6975\n",
      "Epoch 137/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1405 - accuracy: 0.6969\n",
      "Epoch 138/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1404 - accuracy: 0.6974\n",
      "Epoch 139/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1404 - accuracy: 0.6972\n",
      "Epoch 140/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1402 - accuracy: 0.6980\n",
      "Epoch 141/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1403 - accuracy: 0.6980\n",
      "Epoch 142/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1401 - accuracy: 0.6981\n",
      "Epoch 143/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1401 - accuracy: 0.6980\n",
      "Epoch 144/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1401 - accuracy: 0.6983\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1400 - accuracy: 0.6985\n",
      "Epoch 146/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1399 - accuracy: 0.6987\n",
      "Epoch 147/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1399 - accuracy: 0.6987s - loss: 0.1398 - \n",
      "Epoch 148/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1399 - accuracy: 0.6991\n",
      "Epoch 149/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1399 - accuracy: 0.6989\n",
      "Epoch 150/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1398 - accuracy: 0.6993\n",
      "Epoch 151/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1397 - accuracy: 0.6993\n",
      "Epoch 152/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1398 - accuracy: 0.6986\n",
      "Epoch 153/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1396 - accuracy: 0.6996\n",
      "Epoch 154/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1396 - accuracy: 0.6998\n",
      "Epoch 155/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1396 - accuracy: 0.6995\n",
      "Epoch 156/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1395 - accuracy: 0.6999\n",
      "Epoch 157/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1394 - accuracy: 0.7007\n",
      "Epoch 158/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1394 - accuracy: 0.7003\n",
      "Epoch 159/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1395 - accuracy: 0.7002\n",
      "Epoch 160/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1393 - accuracy: 0.7004\n",
      "Epoch 161/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1394 - accuracy: 0.7002\n",
      "Epoch 162/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1393 - accuracy: 0.7009\n",
      "Epoch 163/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1393 - accuracy: 0.7011\n",
      "Epoch 164/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1392 - accuracy: 0.7008\n",
      "Epoch 165/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1392 - accuracy: 0.7008\n",
      "Epoch 166/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1391 - accuracy: 0.7012\n",
      "Epoch 167/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1391 - accuracy: 0.7011\n",
      "Epoch 168/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1391 - accuracy: 0.7010\n",
      "Epoch 169/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1389 - accuracy: 0.7017\n",
      "Epoch 170/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1389 - accuracy: 0.7016\n",
      "Epoch 171/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1390 - accuracy: 0.7018\n",
      "Epoch 172/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1389 - accuracy: 0.7019\n",
      "Epoch 173/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1388 - accuracy: 0.7019\n",
      "Epoch 174/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1388 - accuracy: 0.7020\n",
      "Epoch 175/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1388 - accuracy: 0.7021\n",
      "Epoch 176/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1387 - accuracy: 0.7023\n",
      "Epoch 177/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1387 - accuracy: 0.7023\n",
      "Epoch 178/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1387 - accuracy: 0.7025\n",
      "Epoch 179/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1386 - accuracy: 0.7028\n",
      "Epoch 180/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1386 - accuracy: 0.7028\n",
      "Epoch 181/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1385 - accuracy: 0.7029\n",
      "Epoch 182/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1385 - accuracy: 0.7032\n",
      "Epoch 183/200\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1385 - accuracy: 0.7031\n",
      "Epoch 184/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1385 - accuracy: 0.7032\n",
      "Epoch 185/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1385 - accuracy: 0.7030\n",
      "Epoch 186/200\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1383 - accuracy: 0.7031\n",
      "Epoch 187/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1383 - accuracy: 0.7038\n",
      "Epoch 188/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1382 - accuracy: 0.7042\n",
      "Epoch 189/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1382 - accuracy: 0.7042\n",
      "Epoch 190/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1382 - accuracy: 0.7038\n",
      "Epoch 191/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1383 - accuracy: 0.7035\n",
      "Epoch 192/200\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1381 - accuracy: 0.7046\n",
      "Epoch 193/200\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1381 - accuracy: 0.7040\n",
      "Epoch 194/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1381 - accuracy: 0.7047\n",
      "Epoch 195/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1381 - accuracy: 0.7039\n",
      "Epoch 196/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1380 - accuracy: 0.7053\n",
      "Epoch 197/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1379 - accuracy: 0.7049\n",
      "Epoch 198/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1380 - accuracy: 0.7049\n",
      "Epoch 199/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1380 - accuracy: 0.7046\n",
      "Epoch 200/200\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1379 - accuracy: 0.7048\n"
     ]
    }
   ],
   "source": [
    "lr =  0.017722015080147924\n",
    "Lambda = 0.001766687183734540564\n",
    "\n",
    "score = train_and_test_loop1(200, lr, Lambda,250, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbce6ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "Epoch 1/200\n",
      "579091/579091 [==============================] - 77s 134us/sample - loss: 0.1829 - accuracy: 0.5810\n",
      "Epoch 2/200\n",
      "579091/579091 [==============================] - 66s 113us/sample - loss: 0.1728 - accuracy: 0.5985\n",
      "Epoch 3/200\n",
      "579091/579091 [==============================] - 57s 98us/sample - loss: 0.1699 - accuracy: 0.6059\n",
      "Epoch 4/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1681 - accuracy: 0.6107\n",
      "Epoch 5/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1665 - accuracy: 0.6156\n",
      "Epoch 6/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1652 - accuracy: 0.6197\n",
      "Epoch 7/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1641 - accuracy: 0.6228\n",
      "Epoch 8/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1632 - accuracy: 0.6253\n",
      "Epoch 9/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1622 - accuracy: 0.6284\n",
      "Epoch 10/200\n",
      "579091/579091 [==============================] - 22s 37us/sample - loss: 0.1613 - accuracy: 0.6315\n",
      "Epoch 11/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1607 - accuracy: 0.6331\n",
      "Epoch 12/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1599 - accuracy: 0.6360\n",
      "Epoch 13/200\n",
      "579091/579091 [==============================] - 21s 37us/sample - loss: 0.1593 - accuracy: 0.6374\n",
      "Epoch 14/200\n",
      "579091/579091 [==============================] - 24s 42us/sample - loss: 0.1588 - accuracy: 0.6395\n",
      "Epoch 15/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1582 - accuracy: 0.6410 - loss: 0.1581 \n",
      "Epoch 16/200\n",
      "579091/579091 [==============================] - 21s 37us/sample - loss: 0.1576 - accuracy: 0.6429\n",
      "Epoch 17/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1572 - accuracy: 0.6437\n",
      "Epoch 18/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1568 - accuracy: 0.6458 - loss: 0.1568 \n",
      "Epoch 19/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1563 - accuracy: 0.6471\n",
      "Epoch 20/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1558 - accuracy: 0.6483\n",
      "Epoch 21/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1554 - accuracy: 0.6492\n",
      "Epoch 22/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1550 - accuracy: 0.6510\n",
      "Epoch 23/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1547 - accuracy: 0.6526\n",
      "Epoch 24/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1543 - accuracy: 0.6529 - loss: 0.1\n",
      "Epoch 25/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1540 - accuracy: 0.6543\n",
      "Epoch 26/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1538 - accuracy: 0.6546\n",
      "Epoch 27/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1535 - accuracy: 0.6559\n",
      "Epoch 28/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1530 - accuracy: 0.6578\n",
      "Epoch 29/200\n",
      "579091/579091 [==============================] - 21s 37us/sample - loss: 0.1528 - accuracy: 0.6577\n",
      "Epoch 30/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1524 - accuracy: 0.6587\n",
      "Epoch 31/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1522 - accuracy: 0.6599\n",
      "Epoch 32/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1521 - accuracy: 0.6604\n",
      "Epoch 33/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1517 - accuracy: 0.6614\n",
      "Epoch 34/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1514 - accuracy: 0.6621\n",
      "Epoch 35/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1512 - accuracy: 0.6626\n",
      "Epoch 36/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1509 - accuracy: 0.6638\n",
      "Epoch 37/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1508 - accuracy: 0.6645 - loss: 0.1507 - \n",
      "Epoch 38/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1506 - accuracy: 0.6655\n",
      "Epoch 39/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1504 - accuracy: 0.6657\n",
      "Epoch 40/200\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.66 - 21s 36us/sample - loss: 0.1502 - accuracy: 0.6666\n",
      "Epoch 41/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1499 - accuracy: 0.6672\n",
      "Epoch 42/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1497 - accuracy: 0.6680 - l\n",
      "Epoch 43/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1496 - accuracy: 0.6685\n",
      "Epoch 44/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1495 - accuracy: 0.6681\n",
      "Epoch 45/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1492 - accuracy: 0.6696\n",
      "Epoch 46/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1492 - accuracy: 0.6691 - loss: 0.1\n",
      "Epoch 47/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1489 - accuracy: 0.6699\n",
      "Epoch 48/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1487 - accuracy: 0.6711\n",
      "Epoch 49/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1485 - accuracy: 0.6712\n",
      "Epoch 50/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1485 - accuracy: 0.6711 - loss: 0.1 - ETA: 0s - loss: 0.1485 - accura\n",
      "Epoch 51/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1482 - accuracy: 0.6724\n",
      "Epoch 52/200\n",
      "579091/579091 [==============================] - 21s 35us/sample - loss: 0.1481 - accuracy: 0.6722\n",
      "Epoch 53/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1479 - accuracy: 0.6729\n",
      "Epoch 54/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1477 - accuracy: 0.6738\n",
      "Epoch 55/200\n",
      "579091/579091 [==============================] - 21s 35us/sample - loss: 0.1476 - accuracy: 0.6740\n",
      "Epoch 56/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1475 - accuracy: 0.6746\n",
      "Epoch 57/200\n",
      "579091/579091 [==============================] - 22s 37us/sample - loss: 0.1475 - accuracy: 0.6749\n",
      "Epoch 58/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1473 - accuracy: 0.6747\n",
      "Epoch 59/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1472 - accuracy: 0.6755\n",
      "Epoch 60/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1469 - accuracy: 0.6766\n",
      "Epoch 61/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1468 - accuracy: 0.6770\n",
      "Epoch 62/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1467 - accuracy: 0.6769\n",
      "Epoch 63/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1466 - accuracy: 0.6777\n",
      "Epoch 64/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1466 - accuracy: 0.6771\n",
      "Epoch 65/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1464 - accuracy: 0.6779\n",
      "Epoch 66/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1462 - accuracy: 0.6788\n",
      "Epoch 67/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1462 - accuracy: 0.6785\n",
      "Epoch 68/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1460 - accuracy: 0.6790\n",
      "Epoch 69/200\n",
      "579091/579091 [==============================] - 24s 41us/sample - loss: 0.1459 - accuracy: 0.6791\n",
      "Epoch 70/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1459 - accuracy: 0.6795\n",
      "Epoch 71/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1458 - accuracy: 0.6798 -\n",
      "Epoch 72/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1456 - accuracy: 0.6799\n",
      "Epoch 73/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1453 - accuracy: 0.6810\n",
      "Epoch 74/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1454 - accuracy: 0.6811\n",
      "Epoch 75/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1455 - accuracy: 0.6803\n",
      "Epoch 76/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1453 - accuracy: 0.6812 - loss: 0.1453 - accuracy\n",
      "Epoch 77/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1451 - accuracy: 0.6819\n",
      "Epoch 78/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1451 - accuracy: 0.6817 ETA: 0s - los\n",
      "Epoch 79/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1450 - accuracy: 0.6825\n",
      "Epoch 80/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1449 - accuracy: 0.6823\n",
      "Epoch 81/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1450 - accuracy: 0.6817\n",
      "Epoch 82/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1447 - accuracy: 0.6829\n",
      "Epoch 83/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1446 - accuracy: 0.6829\n",
      "Epoch 84/200\n",
      "579091/579091 [==============================] - 21s 35us/sample - loss: 0.1445 - accuracy: 0.6837\n",
      "Epoch 85/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1445 - accuracy: 0.6835\n",
      "Epoch 86/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1444 - accuracy: 0.6840\n",
      "Epoch 87/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1443 - accuracy: 0.6846\n",
      "Epoch 88/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1442 - accuracy: 0.6838\n",
      "Epoch 89/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1440 - accuracy: 0.6846\n",
      "Epoch 90/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1441 - accuracy: 0.6845\n",
      "Epoch 91/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1441 - accuracy: 0.6847\n",
      "Epoch 92/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1439 - accuracy: 0.6851\n",
      "Epoch 93/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1439 - accuracy: 0.6857\n",
      "Epoch 94/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1438 - accuracy: 0.6859\n",
      "Epoch 95/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1437 - accuracy: 0.6861\n",
      "Epoch 96/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1437 - accuracy: 0.6862 - loss:\n",
      "Epoch 97/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1435 - accuracy: 0.6864\n",
      "Epoch 98/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1435 - accuracy: 0.6865\n",
      "Epoch 99/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1433 - accuracy: 0.6870\n",
      "Epoch 100/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1433 - accuracy: 0.6869 - loss:\n",
      "Epoch 101/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1433 - accuracy: 0.6874\n",
      "Epoch 102/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1433 - accuracy: 0.6872\n",
      "Epoch 103/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1432 - accuracy: 0.6872\n",
      "Epoch 104/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1431 - accuracy: 0.6874\n",
      "Epoch 105/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1431 - accuracy: 0.6881 - loss: 0.1430 - accu\n",
      "Epoch 106/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1431 - accuracy: 0.6876\n",
      "Epoch 107/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1429 - accuracy: 0.6883\n",
      "Epoch 108/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1428 - accuracy: 0.6884 - loss: 0.1428 - accuracy: \n",
      "Epoch 109/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1428 - accuracy: 0.6890 - loss: 0.1427 - ac\n",
      "Epoch 110/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1428 - accuracy: 0.6887\n",
      "Epoch 111/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1428 - accuracy: 0.6886\n",
      "Epoch 112/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1427 - accuracy: 0.6895\n",
      "Epoch 113/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1426 - accuracy: 0.6895\n",
      "Epoch 114/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1425 - accuracy: 0.6893\n",
      "Epoch 115/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1425 - accuracy: 0.6898\n",
      "Epoch 116/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1424 - accuracy: 0.6904\n",
      "Epoch 117/200\n",
      "579091/579091 [==============================] - 21s 37us/sample - loss: 0.1425 - accuracy: 0.6895\n",
      "Epoch 118/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1423 - accuracy: 0.6901\n",
      "Epoch 119/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1422 - accuracy: 0.6900\n",
      "Epoch 120/200\n",
      "579091/579091 [==============================] - 21s 37us/sample - loss: 0.1422 - accuracy: 0.6905\n",
      "Epoch 121/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1421 - accuracy: 0.6909\n",
      "Epoch 122/200\n",
      "579091/579091 [==============================] - 22s 38us/sample - loss: 0.1421 - accuracy: 0.6911\n",
      "Epoch 123/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1420 - accuracy: 0.6915\n",
      "Epoch 124/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1420 - accuracy: 0.6910\n",
      "Epoch 125/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1420 - accuracy: 0.6909\n",
      "Epoch 126/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1419 - accuracy: 0.6909\n",
      "Epoch 127/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1417 - accuracy: 0.6916\n",
      "Epoch 128/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1418 - accuracy: 0.6919\n",
      "Epoch 129/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1419 - accuracy: 0.6920\n",
      "Epoch 130/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1418 - accuracy: 0.6917\n",
      "Epoch 131/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1417 - accuracy: 0.6918\n",
      "Epoch 132/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1416 - accuracy: 0.6922\n",
      "Epoch 133/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1416 - accuracy: 0.6923\n",
      "Epoch 134/200\n",
      "579091/579091 [==============================] - 21s 35us/sample - loss: 0.1416 - accuracy: 0.6921\n",
      "Epoch 135/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1416 - accuracy: 0.6920\n",
      "Epoch 136/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1414 - accuracy: 0.6926\n",
      "Epoch 137/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1414 - accuracy: 0.6926\n",
      "Epoch 138/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1415 - accuracy: 0.6926\n",
      "Epoch 139/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1414 - accuracy: 0.6929\n",
      "Epoch 140/200\n",
      "579091/579091 [==============================] - 19s 33us/sample - loss: 0.1412 - accuracy: 0.6935\n",
      "Epoch 141/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1412 - accuracy: 0.6932\n",
      "Epoch 142/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1412 - accuracy: 0.6935\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1411 - accuracy: 0.6933\n",
      "Epoch 144/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1411 - accuracy: 0.6939\n",
      "Epoch 145/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1412 - accuracy: 0.6937\n",
      "Epoch 146/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1410 - accuracy: 0.6937\n",
      "Epoch 147/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1411 - accuracy: 0.6938\n",
      "Epoch 148/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1410 - accuracy: 0.6942\n",
      "Epoch 149/200\n",
      "579091/579091 [==============================] - 19s 34us/sample - loss: 0.1408 - accuracy: 0.6947\n",
      "Epoch 150/200\n",
      "579091/579091 [==============================] - 20s 34us/sample - loss: 0.1408 - accuracy: 0.6947\n",
      "Epoch 151/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1409 - accuracy: 0.6944\n",
      "Epoch 152/200\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.69 - 21s 35us/sample - loss: 0.1409 - accuracy: 0.6939\n",
      "Epoch 153/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1407 - accuracy: 0.6949\n",
      "Epoch 154/200\n",
      "579091/579091 [==============================] - 22s 37us/sample - loss: 0.1407 - accuracy: 0.6952\n",
      "Epoch 155/200\n",
      "579091/579091 [==============================] - 21s 35us/sample - loss: 0.1408 - accuracy: 0.6950 - loss: 0.1408 - accuracy: \n",
      "Epoch 156/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1406 - accuracy: 0.6954\n",
      "Epoch 157/200\n",
      "579091/579091 [==============================] - 21s 35us/sample - loss: 0.1406 - accuracy: 0.6951\n",
      "Epoch 158/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1405 - accuracy: 0.6955 - loss: 0.1405 - accura\n",
      "Epoch 159/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1406 - accuracy: 0.6955\n",
      "Epoch 160/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1405 - accuracy: 0.6956\n",
      "Epoch 161/200\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1404 - accuracy: 0.6960\n",
      "Epoch 162/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1405 - accuracy: 0.6955\n",
      "Epoch 163/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1405 - accuracy: 0.6951\n",
      "Epoch 164/200\n",
      "579091/579091 [==============================] - 22s 38us/sample - loss: 0.1403 - accuracy: 0.6957\n",
      "Epoch 165/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1402 - accuracy: 0.6960\n",
      "Epoch 166/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1404 - accuracy: 0.6957\n",
      "Epoch 167/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1402 - accuracy: 0.6964\n",
      "Epoch 168/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1402 - accuracy: 0.6965\n",
      "Epoch 169/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1403 - accuracy: 0.6960\n",
      "Epoch 170/200\n",
      "579091/579091 [==============================] - 21s 35us/sample - loss: 0.1402 - accuracy: 0.6963\n",
      "Epoch 171/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1401 - accuracy: 0.6966\n",
      "Epoch 172/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1400 - accuracy: 0.6966\n",
      "Epoch 173/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1401 - accuracy: 0.6965 - loss: 0.1401 - ac\n",
      "Epoch 174/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1401 - accuracy: 0.6970\n",
      "Epoch 175/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1400 - accuracy: 0.6971\n",
      "Epoch 176/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1400 - accuracy: 0.6966\n",
      "Epoch 177/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1399 - accuracy: 0.6972\n",
      "Epoch 178/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1400 - accuracy: 0.6968\n",
      "Epoch 179/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1398 - accuracy: 0.6978\n",
      "Epoch 180/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1398 - accuracy: 0.6978\n",
      "Epoch 181/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1398 - accuracy: 0.6975\n",
      "Epoch 182/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1397 - accuracy: 0.6977\n",
      "Epoch 183/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1398 - accuracy: 0.6974\n",
      "Epoch 184/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1398 - accuracy: 0.6978\n",
      "Epoch 185/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1397 - accuracy: 0.6975\n",
      "Epoch 186/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1396 - accuracy: 0.6979\n",
      "Epoch 187/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1396 - accuracy: 0.6979\n",
      "Epoch 188/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1396 - accuracy: 0.6978\n",
      "Epoch 189/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1396 - accuracy: 0.6983\n",
      "Epoch 190/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1396 - accuracy: 0.6975\n",
      "Epoch 191/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1396 - accuracy: 0.6981\n",
      "Epoch 192/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1395 - accuracy: 0.6982\n",
      "Epoch 193/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1394 - accuracy: 0.6982\n",
      "Epoch 194/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1395 - accuracy: 0.6985\n",
      "Epoch 195/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1394 - accuracy: 0.6991\n",
      "Epoch 196/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1394 - accuracy: 0.6983\n",
      "Epoch 197/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1393 - accuracy: 0.6992\n",
      "Epoch 198/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1395 - accuracy: 0.6986\n",
      "Epoch 199/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1393 - accuracy: 0.6984\n",
      "Epoch 200/200\n",
      "579091/579091 [==============================] - 21s 36us/sample - loss: 0.1394 - accuracy: 0.6986\n"
     ]
    }
   ],
   "source": [
    "lr =  0.017722015080147924\n",
    "Lambda = 0.001766687183734540564\n",
    "\n",
    "score = train_and_test_loop1(200, lr, Lambda,100, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9951901b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579091 samples\n",
      "Epoch 1/1000\n",
      "579091/579091 [==============================] - 20s 35us/sample - loss: 0.1909 - accuracy: 0.5621\n",
      "Epoch 2/1000\n",
      "579091/579091 [==============================] - 10s 18us/sample - loss: 0.1768 - accuracy: 0.5934\n",
      "Epoch 3/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1733 - accuracy: 0.5999\n",
      "Epoch 4/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1711 - accuracy: 0.6047\n",
      "Epoch 5/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1693 - accuracy: 0.6086s - loss: 0.1693 - accuracy - ETA: 0s - loss: 0.1693 - accura\n",
      "Epoch 6/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1680 - accuracy: 0.6125\n",
      "Epoch 7/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1668 - accuracy: 0.6153\n",
      "Epoch 8/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1658 - accuracy: 0.6181\n",
      "Epoch 9/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1649 - accuracy: 0.6209s - loss: 0.1649 - accuracy: 0.62\n",
      "Epoch 10/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1641 - accuracy: 0.6234\n",
      "Epoch 11/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1632 - accuracy: 0.6255\n",
      "Epoch 12/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1625 - accuracy: 0.6279\n",
      "Epoch 13/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1618 - accuracy: 0.6298\n",
      "Epoch 14/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1612 - accuracy: 0.6319\n",
      "Epoch 15/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1605 - accuracy: 0.6335\n",
      "Epoch 16/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1600 - accuracy: 0.6354s - loss: 0\n",
      "Epoch 17/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1594 - accuracy: 0.6374\n",
      "Epoch 18/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1589 - accuracy: 0.6388\n",
      "Epoch 19/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1584 - accuracy: 0.6403\n",
      "Epoch 20/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1578 - accuracy: 0.6419\n",
      "Epoch 21/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1575 - accuracy: 0.6433\n",
      "Epoch 22/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1570 - accuracy: 0.6451\n",
      "Epoch 23/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1566 - accuracy: 0.6457\n",
      "Epoch 24/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1562 - accuracy: 0.6476\n",
      "Epoch 25/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1557 - accuracy: 0.6487\n",
      "Epoch 26/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1554 - accuracy: 0.6499\n",
      "Epoch 27/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1551 - accuracy: 0.6502\n",
      "Epoch 28/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1547 - accuracy: 0.6523\n",
      "Epoch 29/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1544 - accuracy: 0.6531\n",
      "Epoch 30/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1540 - accuracy: 0.6538\n",
      "Epoch 31/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1538 - accuracy: 0.6549\n",
      "Epoch 32/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1535 - accuracy: 0.6557\n",
      "Epoch 33/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1531 - accuracy: 0.6567\n",
      "Epoch 34/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1528 - accuracy: 0.6579\n",
      "Epoch 35/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1526 - accuracy: 0.6586\n",
      "Epoch 36/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1523 - accuracy: 0.6603\n",
      "Epoch 37/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1520 - accuracy: 0.6608s\n",
      "Epoch 38/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1517 - accuracy: 0.6615\n",
      "Epoch 39/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1515 - accuracy: 0.6621\n",
      "Epoch 40/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1512 - accuracy: 0.6631\n",
      "Epoch 41/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1509 - accuracy: 0.6640\n",
      "Epoch 42/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1508 - accuracy: 0.6647\n",
      "Epoch 43/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1505 - accuracy: 0.6649s - loss: 0.1505 \n",
      "Epoch 44/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1503 - accuracy: 0.6662\n",
      "Epoch 45/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1501 - accuracy: 0.6660\n",
      "Epoch 46/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1498 - accuracy: 0.6679\n",
      "Epoch 47/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1496 - accuracy: 0.6678\n",
      "Epoch 48/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1494 - accuracy: 0.6686\n",
      "Epoch 49/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1493 - accuracy: 0.6692\n",
      "Epoch 50/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1490 - accuracy: 0.6698\n",
      "Epoch 51/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1489 - accuracy: 0.6707\n",
      "Epoch 52/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1487 - accuracy: 0.6706\n",
      "Epoch 53/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1484 - accuracy: 0.6717\n",
      "Epoch 54/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1484 - accuracy: 0.6720\n",
      "Epoch 55/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1482 - accuracy: 0.6728\n",
      "Epoch 56/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1480 - accuracy: 0.6732\n",
      "Epoch 57/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1478 - accuracy: 0.6740\n",
      "Epoch 58/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1476 - accuracy: 0.6741\n",
      "Epoch 59/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1475 - accuracy: 0.6748\n",
      "Epoch 60/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1473 - accuracy: 0.6754\n",
      "Epoch 61/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1472 - accuracy: 0.6757\n",
      "Epoch 62/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1470 - accuracy: 0.6761\n",
      "Epoch 63/1000\n",
      "579091/579091 [==============================] - 11s 20us/sample - loss: 0.1469 - accuracy: 0.6767\n",
      "Epoch 64/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1466 - accuracy: 0.6774\n",
      "Epoch 65/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1466 - accuracy: 0.6773\n",
      "Epoch 66/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1465 - accuracy: 0.6780\n",
      "Epoch 67/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1462 - accuracy: 0.6786\n",
      "Epoch 68/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1461 - accuracy: 0.6787\n",
      "Epoch 69/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1460 - accuracy: 0.6797\n",
      "Epoch 70/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1459 - accuracy: 0.6798\n",
      "Epoch 71/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1458 - accuracy: 0.6802\n",
      "Epoch 72/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1456 - accuracy: 0.6808\n",
      "Epoch 73/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1455 - accuracy: 0.6809\n",
      "Epoch 74/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1454 - accuracy: 0.6811s - loss: 0\n",
      "Epoch 75/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1453 - accuracy: 0.6816\n",
      "Epoch 76/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1452 - accuracy: 0.6821\n",
      "Epoch 77/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1450 - accuracy: 0.6827\n",
      "Epoch 78/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1449 - accuracy: 0.6825s - los\n",
      "Epoch 79/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1448 - accuracy: 0.6833\n",
      "Epoch 80/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1447 - accuracy: 0.6835\n",
      "Epoch 81/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1446 - accuracy: 0.6840\n",
      "Epoch 82/1000\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.68 - 8s 14us/sample - loss: 0.1445 - accuracy: 0.6836\n",
      "Epoch 83/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1444 - accuracy: 0.6847\n",
      "Epoch 84/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1443 - accuracy: 0.6850\n",
      "Epoch 85/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1443 - accuracy: 0.6853\n",
      "Epoch 86/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1441 - accuracy: 0.6857\n",
      "Epoch 87/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1439 - accuracy: 0.6862\n",
      "Epoch 88/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1438 - accuracy: 0.6860\n",
      "Epoch 89/1000\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.68 - 8s 14us/sample - loss: 0.1437 - accuracy: 0.6863\n",
      "Epoch 90/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1436 - accuracy: 0.6864\n",
      "Epoch 91/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1436 - accuracy: 0.6869\n",
      "Epoch 92/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1435 - accuracy: 0.6873\n",
      "Epoch 93/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1435 - accuracy: 0.6873\n",
      "Epoch 94/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1433 - accuracy: 0.6881\n",
      "Epoch 95/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1431 - accuracy: 0.6884\n",
      "Epoch 96/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1430 - accuracy: 0.6888\n",
      "Epoch 97/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1431 - accuracy: 0.6882\n",
      "Epoch 98/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1431 - accuracy: 0.6882\n",
      "Epoch 99/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1429 - accuracy: 0.6890\n",
      "Epoch 100/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1429 - accuracy: 0.6892\n",
      "Epoch 101/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1428 - accuracy: 0.6895\n",
      "Epoch 102/1000\n",
      "579091/579091 [==============================] - 10s 16us/sample - loss: 0.1426 - accuracy: 0.6896\n",
      "Epoch 103/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1426 - accuracy: 0.6900\n",
      "Epoch 104/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1424 - accuracy: 0.6902\n",
      "Epoch 105/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1424 - accuracy: 0.6904\n",
      "Epoch 106/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1423 - accuracy: 0.6907\n",
      "Epoch 107/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1422 - accuracy: 0.6916\n",
      "Epoch 108/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1422 - accuracy: 0.6914\n",
      "Epoch 109/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1422 - accuracy: 0.6912s -\n",
      "Epoch 110/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1420 - accuracy: 0.6922\n",
      "Epoch 111/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1421 - accuracy: 0.6920\n",
      "Epoch 112/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1420 - accuracy: 0.6923\n",
      "Epoch 113/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1419 - accuracy: 0.6923\n",
      "Epoch 114/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1418 - accuracy: 0.6930\n",
      "Epoch 115/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1416 - accuracy: 0.6931\n",
      "Epoch 116/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1417 - accuracy: 0.6926\n",
      "Epoch 117/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1416 - accuracy: 0.6935\n",
      "Epoch 118/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1416 - accuracy: 0.6932\n",
      "Epoch 119/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1415 - accuracy: 0.6934\n",
      "Epoch 120/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1414 - accuracy: 0.6941\n",
      "Epoch 121/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1414 - accuracy: 0.6938\n",
      "Epoch 122/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1412 - accuracy: 0.6946\n",
      "Epoch 123/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1412 - accuracy: 0.6943\n",
      "Epoch 124/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1412 - accuracy: 0.6943\n",
      "Epoch 125/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1411 - accuracy: 0.6945\n",
      "Epoch 126/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1410 - accuracy: 0.6953s - loss: 0.1410 - ac\n",
      "Epoch 127/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1410 - accuracy: 0.6948\n",
      "Epoch 128/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1408 - accuracy: 0.6959\n",
      "Epoch 129/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1408 - accuracy: 0.6958\n",
      "Epoch 130/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1409 - accuracy: 0.6953\n",
      "Epoch 131/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1408 - accuracy: 0.6962\n",
      "Epoch 132/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1406 - accuracy: 0.6964\n",
      "Epoch 133/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1407 - accuracy: 0.6963\n",
      "Epoch 134/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1406 - accuracy: 0.6964s - loss: 0.1405 - \n",
      "Epoch 135/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1404 - accuracy: 0.6969\n",
      "Epoch 136/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1405 - accuracy: 0.6968\n",
      "Epoch 137/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1403 - accuracy: 0.6974\n",
      "Epoch 138/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1405 - accuracy: 0.6965\n",
      "Epoch 139/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1403 - accuracy: 0.6972\n",
      "Epoch 140/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1403 - accuracy: 0.6973\n",
      "Epoch 141/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1401 - accuracy: 0.6979\n",
      "Epoch 142/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1402 - accuracy: 0.6974\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1402 - accuracy: 0.6976\n",
      "Epoch 144/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1400 - accuracy: 0.6979\n",
      "Epoch 145/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1401 - accuracy: 0.6977\n",
      "Epoch 146/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1399 - accuracy: 0.6985\n",
      "Epoch 147/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1400 - accuracy: 0.6982\n",
      "Epoch 148/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1400 - accuracy: 0.6984\n",
      "Epoch 149/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1398 - accuracy: 0.6986\n",
      "Epoch 150/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1397 - accuracy: 0.6989\n",
      "Epoch 151/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1397 - accuracy: 0.6996\n",
      "Epoch 152/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1398 - accuracy: 0.6986s - loss:\n",
      "Epoch 153/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1396 - accuracy: 0.6993\n",
      "Epoch 154/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1396 - accuracy: 0.6991\n",
      "Epoch 155/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1395 - accuracy: 0.6991\n",
      "Epoch 156/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1395 - accuracy: 0.7003\n",
      "Epoch 157/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1395 - accuracy: 0.6999\n",
      "Epoch 158/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1395 - accuracy: 0.6994\n",
      "Epoch 159/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1394 - accuracy: 0.6999\n",
      "Epoch 160/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1394 - accuracy: 0.7001\n",
      "Epoch 161/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1393 - accuracy: 0.7003\n",
      "Epoch 162/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1393 - accuracy: 0.7004\n",
      "Epoch 163/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1392 - accuracy: 0.7004\n",
      "Epoch 164/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1391 - accuracy: 0.7006\n",
      "Epoch 165/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1391 - accuracy: 0.7010\n",
      "Epoch 166/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1391 - accuracy: 0.7009\n",
      "Epoch 167/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1390 - accuracy: 0.7012\n",
      "Epoch 168/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1390 - accuracy: 0.7014s -\n",
      "Epoch 169/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1390 - accuracy: 0.7013\n",
      "Epoch 170/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1389 - accuracy: 0.7015\n",
      "Epoch 171/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1390 - accuracy: 0.7017\n",
      "Epoch 172/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1388 - accuracy: 0.7017\n",
      "Epoch 173/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1389 - accuracy: 0.7016\n",
      "Epoch 174/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1387 - accuracy: 0.7022\n",
      "Epoch 175/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1386 - accuracy: 0.7025\n",
      "Epoch 176/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1387 - accuracy: 0.7022\n",
      "Epoch 177/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1387 - accuracy: 0.7027\n",
      "Epoch 178/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1386 - accuracy: 0.7028\n",
      "Epoch 179/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1385 - accuracy: 0.7027\n",
      "Epoch 180/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1386 - accuracy: 0.7029\n",
      "Epoch 181/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1385 - accuracy: 0.7031\n",
      "Epoch 182/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1385 - accuracy: 0.7027\n",
      "Epoch 183/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1385 - accuracy: 0.7031\n",
      "Epoch 184/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1383 - accuracy: 0.7030\n",
      "Epoch 185/1000\n",
      "579091/579091 [==============================] - 10s 16us/sample - loss: 0.1384 - accuracy: 0.7030\n",
      "Epoch 186/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1384 - accuracy: 0.7033\n",
      "Epoch 187/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1382 - accuracy: 0.7039\n",
      "Epoch 188/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1383 - accuracy: 0.7037\n",
      "Epoch 189/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1382 - accuracy: 0.7037\n",
      "Epoch 190/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1382 - accuracy: 0.7042\n",
      "Epoch 191/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1382 - accuracy: 0.7034\n",
      "Epoch 192/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1383 - accuracy: 0.7035\n",
      "Epoch 193/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1381 - accuracy: 0.7039\n",
      "Epoch 194/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1380 - accuracy: 0.7039\n",
      "Epoch 195/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1380 - accuracy: 0.7040\n",
      "Epoch 196/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1379 - accuracy: 0.7042\n",
      "Epoch 197/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1380 - accuracy: 0.7042\n",
      "Epoch 198/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1380 - accuracy: 0.7045\n",
      "Epoch 199/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1379 - accuracy: 0.7049\n",
      "Epoch 200/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1379 - accuracy: 0.7047\n",
      "Epoch 201/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1379 - accuracy: 0.7050\n",
      "Epoch 202/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1378 - accuracy: 0.7049\n",
      "Epoch 203/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1377 - accuracy: 0.7051\n",
      "Epoch 204/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1377 - accuracy: 0.7052\n",
      "Epoch 205/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1378 - accuracy: 0.7056\n",
      "Epoch 206/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1377 - accuracy: 0.7053\n",
      "Epoch 207/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1376 - accuracy: 0.7055\n",
      "Epoch 208/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1376 - accuracy: 0.7055\n",
      "Epoch 209/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1376 - accuracy: 0.7058\n",
      "Epoch 210/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1375 - accuracy: 0.7060\n",
      "Epoch 211/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1375 - accuracy: 0.7059\n",
      "Epoch 212/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1375 - accuracy: 0.7057\n",
      "Epoch 213/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1374 - accuracy: 0.7062\n",
      "Epoch 214/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1373 - accuracy: 0.7068\n",
      "Epoch 215/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1374 - accuracy: 0.7067\n",
      "Epoch 216/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1374 - accuracy: 0.7063\n",
      "Epoch 217/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1374 - accuracy: 0.7059\n",
      "Epoch 218/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1374 - accuracy: 0.7059\n",
      "Epoch 219/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1373 - accuracy: 0.7064\n",
      "Epoch 220/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1373 - accuracy: 0.7069\n",
      "Epoch 221/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1372 - accuracy: 0.7065\n",
      "Epoch 222/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1373 - accuracy: 0.7066\n",
      "Epoch 223/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1372 - accuracy: 0.7069\n",
      "Epoch 224/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1372 - accuracy: 0.7066\n",
      "Epoch 225/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1371 - accuracy: 0.7067\n",
      "Epoch 226/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1370 - accuracy: 0.7075\n",
      "Epoch 227/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1371 - accuracy: 0.7074\n",
      "Epoch 228/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1370 - accuracy: 0.7073\n",
      "Epoch 229/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1370 - accuracy: 0.7074\n",
      "Epoch 230/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1369 - accuracy: 0.7076\n",
      "Epoch 231/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1369 - accuracy: 0.7077\n",
      "Epoch 232/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1369 - accuracy: 0.7079\n",
      "Epoch 233/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1369 - accuracy: 0.7076\n",
      "Epoch 234/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1368 - accuracy: 0.7080\n",
      "Epoch 235/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1369 - accuracy: 0.7077\n",
      "Epoch 236/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1368 - accuracy: 0.7082\n",
      "Epoch 237/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1368 - accuracy: 0.7084\n",
      "Epoch 238/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1367 - accuracy: 0.7084 0s - loss: 0.1\n",
      "Epoch 239/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1368 - accuracy: 0.7081s - loss: 0.136\n",
      "Epoch 240/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1368 - accuracy: 0.7077\n",
      "Epoch 241/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1368 - accuracy: 0.7082\n",
      "Epoch 242/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1367 - accuracy: 0.7086\n",
      "Epoch 243/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1367 - accuracy: 0.7089\n",
      "Epoch 244/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1366 - accuracy: 0.7091\n",
      "Epoch 245/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1366 - accuracy: 0.7085\n",
      "Epoch 246/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1367 - accuracy: 0.7084\n",
      "Epoch 247/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1366 - accuracy: 0.7088\n",
      "Epoch 248/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1365 - accuracy: 0.7089\n",
      "Epoch 249/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1365 - accuracy: 0.7092\n",
      "Epoch 250/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1366 - accuracy: 0.7087\n",
      "Epoch 251/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1364 - accuracy: 0.7093\n",
      "Epoch 252/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1364 - accuracy: 0.7095\n",
      "Epoch 253/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1364 - accuracy: 0.7091\n",
      "Epoch 254/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1364 - accuracy: 0.7091\n",
      "Epoch 255/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1364 - accuracy: 0.7095\n",
      "Epoch 256/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1363 - accuracy: 0.7096\n",
      "Epoch 257/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1364 - accuracy: 0.7094\n",
      "Epoch 258/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1363 - accuracy: 0.7095\n",
      "Epoch 259/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1363 - accuracy: 0.7098\n",
      "Epoch 260/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1362 - accuracy: 0.7097\n",
      "Epoch 261/1000\n",
      "579091/579091 [==============================] - 10s 16us/sample - loss: 0.1361 - accuracy: 0.7103\n",
      "Epoch 262/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1361 - accuracy: 0.7100\n",
      "Epoch 263/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1360 - accuracy: 0.7104\n",
      "Epoch 264/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1360 - accuracy: 0.7107\n",
      "Epoch 265/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1361 - accuracy: 0.7100\n",
      "Epoch 266/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1361 - accuracy: 0.7101\n",
      "Epoch 267/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1361 - accuracy: 0.7099\n",
      "Epoch 268/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1361 - accuracy: 0.7101\n",
      "Epoch 269/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1361 - accuracy: 0.7099\n",
      "Epoch 270/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1360 - accuracy: 0.7105\n",
      "Epoch 271/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1359 - accuracy: 0.7109\n",
      "Epoch 272/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1361 - accuracy: 0.7101\n",
      "Epoch 273/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1358 - accuracy: 0.7108\n",
      "Epoch 274/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1360 - accuracy: 0.7105\n",
      "Epoch 275/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1360 - accuracy: 0.7104\n",
      "Epoch 276/1000\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.71 - 9s 15us/sample - loss: 0.1358 - accuracy: 0.7114\n",
      "Epoch 277/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1358 - accuracy: 0.7111\n",
      "Epoch 278/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1359 - accuracy: 0.7111\n",
      "Epoch 279/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1359 - accuracy: 0.7114\n",
      "Epoch 280/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1358 - accuracy: 0.7111\n",
      "Epoch 281/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1357 - accuracy: 0.7115\n",
      "Epoch 282/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1358 - accuracy: 0.7110\n",
      "Epoch 283/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1357 - accuracy: 0.7114\n",
      "Epoch 284/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1358 - accuracy: 0.7111\n",
      "Epoch 285/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1357 - accuracy: 0.7116\n",
      "Epoch 286/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1356 - accuracy: 0.7113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1356 - accuracy: 0.7114s - loss: 0\n",
      "Epoch 288/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1355 - accuracy: 0.7118\n",
      "Epoch 289/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1357 - accuracy: 0.7113\n",
      "Epoch 290/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1355 - accuracy: 0.7120\n",
      "Epoch 291/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1356 - accuracy: 0.7122\n",
      "Epoch 292/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1355 - accuracy: 0.7119\n",
      "Epoch 293/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1355 - accuracy: 0.7120\n",
      "Epoch 294/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1355 - accuracy: 0.7122\n",
      "Epoch 295/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1354 - accuracy: 0.7124\n",
      "Epoch 296/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1355 - accuracy: 0.7120\n",
      "Epoch 297/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1354 - accuracy: 0.7126\n",
      "Epoch 298/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1355 - accuracy: 0.7119\n",
      "Epoch 299/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1354 - accuracy: 0.7118\n",
      "Epoch 300/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1354 - accuracy: 0.7127\n",
      "Epoch 301/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1354 - accuracy: 0.7122\n",
      "Epoch 302/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1353 - accuracy: 0.7124\n",
      "Epoch 303/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1354 - accuracy: 0.7124\n",
      "Epoch 304/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1353 - accuracy: 0.7123\n",
      "Epoch 305/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7128\n",
      "Epoch 306/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7130\n",
      "Epoch 307/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7129\n",
      "Epoch 308/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7130\n",
      "Epoch 309/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1351 - accuracy: 0.7135\n",
      "Epoch 310/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7125\n",
      "Epoch 311/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7129\n",
      "Epoch 312/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1352 - accuracy: 0.7127\n",
      "Epoch 313/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7128\n",
      "Epoch 314/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1353 - accuracy: 0.7125\n",
      "Epoch 315/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7130\n",
      "Epoch 316/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1352 - accuracy: 0.7130\n",
      "Epoch 317/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1351 - accuracy: 0.7132s - loss: 0.1351 - accuracy\n",
      "Epoch 318/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1351 - accuracy: 0.7129\n",
      "Epoch 319/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1350 - accuracy: 0.7135\n",
      "Epoch 320/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1351 - accuracy: 0.7131\n",
      "Epoch 321/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1350 - accuracy: 0.7137\n",
      "Epoch 322/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1349 - accuracy: 0.7139\n",
      "Epoch 323/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1350 - accuracy: 0.7133\n",
      "Epoch 324/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1350 - accuracy: 0.7139\n",
      "Epoch 325/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1348 - accuracy: 0.7140\n",
      "Epoch 326/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1349 - accuracy: 0.7141\n",
      "Epoch 327/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1350 - accuracy: 0.7135\n",
      "Epoch 328/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1349 - accuracy: 0.7141\n",
      "Epoch 329/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1349 - accuracy: 0.7139\n",
      "Epoch 330/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1349 - accuracy: 0.7139\n",
      "Epoch 331/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1349 - accuracy: 0.7138\n",
      "Epoch 332/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1348 - accuracy: 0.7146\n",
      "Epoch 333/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1347 - accuracy: 0.7145\n",
      "Epoch 334/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1348 - accuracy: 0.7147\n",
      "Epoch 335/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1348 - accuracy: 0.7143\n",
      "Epoch 336/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1347 - accuracy: 0.7146\n",
      "Epoch 337/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1347 - accuracy: 0.7145\n",
      "Epoch 338/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1349 - accuracy: 0.7136\n",
      "Epoch 339/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1347 - accuracy: 0.7143\n",
      "Epoch 340/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1347 - accuracy: 0.7145s - loss:\n",
      "Epoch 341/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1346 - accuracy: 0.7148\n",
      "Epoch 342/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1347 - accuracy: 0.7146\n",
      "Epoch 343/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1347 - accuracy: 0.7146\n",
      "Epoch 344/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1346 - accuracy: 0.7148\n",
      "Epoch 345/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1346 - accuracy: 0.7145\n",
      "Epoch 346/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1348 - accuracy: 0.7141\n",
      "Epoch 347/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1347 - accuracy: 0.7147\n",
      "Epoch 348/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1345 - accuracy: 0.7150\n",
      "Epoch 349/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1346 - accuracy: 0.7147\n",
      "Epoch 350/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1345 - accuracy: 0.7154\n",
      "Epoch 351/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1345 - accuracy: 0.7147\n",
      "Epoch 352/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1345 - accuracy: 0.7151\n",
      "Epoch 353/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1345 - accuracy: 0.7152\n",
      "Epoch 354/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1345 - accuracy: 0.7155\n",
      "Epoch 355/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1346 - accuracy: 0.7144\n",
      "Epoch 356/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1344 - accuracy: 0.7155\n",
      "Epoch 357/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1344 - accuracy: 0.7153\n",
      "Epoch 358/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1344 - accuracy: 0.7154\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1343 - accuracy: 0.7158\n",
      "Epoch 360/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1343 - accuracy: 0.7159\n",
      "Epoch 361/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1344 - accuracy: 0.7154\n",
      "Epoch 362/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1343 - accuracy: 0.7156\n",
      "Epoch 363/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1343 - accuracy: 0.7153\n",
      "Epoch 364/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1343 - accuracy: 0.7156\n",
      "Epoch 365/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1343 - accuracy: 0.7155\n",
      "Epoch 366/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1342 - accuracy: 0.7158\n",
      "Epoch 367/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1342 - accuracy: 0.7161\n",
      "Epoch 368/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1344 - accuracy: 0.7155\n",
      "Epoch 369/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1342 - accuracy: 0.7159\n",
      "Epoch 370/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1343 - accuracy: 0.7157s - loss: 0.134 - ETA: 0s - loss:\n",
      "Epoch 371/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1343 - accuracy: 0.7156\n",
      "Epoch 372/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1342 - accuracy: 0.7159\n",
      "Epoch 373/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1343 - accuracy: 0.7157\n",
      "Epoch 374/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1343 - accuracy: 0.7160\n",
      "Epoch 375/1000\n",
      "579091/579091 [==============================] - 11s 18us/sample - loss: 0.1342 - accuracy: 0.7158\n",
      "Epoch 376/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1341 - accuracy: 0.7161\n",
      "Epoch 377/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1341 - accuracy: 0.7165\n",
      "Epoch 378/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1341 - accuracy: 0.7164\n",
      "Epoch 379/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1341 - accuracy: 0.7165\n",
      "Epoch 380/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1341 - accuracy: 0.7167\n",
      "Epoch 381/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1341 - accuracy: 0.7160\n",
      "Epoch 382/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1340 - accuracy: 0.7166\n",
      "Epoch 383/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1340 - accuracy: 0.7166\n",
      "Epoch 384/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1340 - accuracy: 0.7164\n",
      "Epoch 385/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1341 - accuracy: 0.7164\n",
      "Epoch 386/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1340 - accuracy: 0.7165\n",
      "Epoch 387/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1340 - accuracy: 0.7166\n",
      "Epoch 388/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1339 - accuracy: 0.7169\n",
      "Epoch 389/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1340 - accuracy: 0.7165\n",
      "Epoch 390/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1341 - accuracy: 0.7164\n",
      "Epoch 391/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1339 - accuracy: 0.7168\n",
      "Epoch 392/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1340 - accuracy: 0.7165\n",
      "Epoch 393/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1339 - accuracy: 0.7166\n",
      "Epoch 394/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1338 - accuracy: 0.7172\n",
      "Epoch 395/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1338 - accuracy: 0.7172\n",
      "Epoch 396/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1339 - accuracy: 0.7172\n",
      "Epoch 397/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1339 - accuracy: 0.7171\n",
      "Epoch 398/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1339 - accuracy: 0.7170\n",
      "Epoch 399/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1338 - accuracy: 0.7171\n",
      "Epoch 400/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1338 - accuracy: 0.7170\n",
      "Epoch 401/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1337 - accuracy: 0.7174\n",
      "Epoch 402/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1338 - accuracy: 0.7174\n",
      "Epoch 403/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1338 - accuracy: 0.7167\n",
      "Epoch 404/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1337 - accuracy: 0.7177\n",
      "Epoch 405/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1337 - accuracy: 0.7174\n",
      "Epoch 406/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1337 - accuracy: 0.7174\n",
      "Epoch 407/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1338 - accuracy: 0.7176\n",
      "Epoch 408/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1338 - accuracy: 0.7173\n",
      "Epoch 409/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7178\n",
      "Epoch 410/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7173s - loss: 0.133 - ETA: 1s -\n",
      "Epoch 411/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1337 - accuracy: 0.7175\n",
      "Epoch 412/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7180\n",
      "Epoch 413/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1337 - accuracy: 0.7175\n",
      "Epoch 414/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7176\n",
      "Epoch 415/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7178\n",
      "Epoch 416/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7183\n",
      "Epoch 417/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7176\n",
      "Epoch 418/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1337 - accuracy: 0.7177\n",
      "Epoch 419/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7178\n",
      "Epoch 420/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7177\n",
      "Epoch 421/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7179\n",
      "Epoch 422/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7179\n",
      "Epoch 423/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7182\n",
      "Epoch 424/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7180\n",
      "Epoch 425/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1334 - accuracy: 0.7185\n",
      "Epoch 426/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7182\n",
      "Epoch 427/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1334 - accuracy: 0.7184\n",
      "Epoch 428/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7186\n",
      "Epoch 429/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1334 - accuracy: 0.7188\n",
      "Epoch 430/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7180\n",
      "Epoch 431/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7184\n",
      "Epoch 432/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1336 - accuracy: 0.7183\n",
      "Epoch 433/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1334 - accuracy: 0.7185\n",
      "Epoch 434/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7183\n",
      "Epoch 435/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1334 - accuracy: 0.7184\n",
      "Epoch 436/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1334 - accuracy: 0.7187s - loss: 0.1334 - ac\n",
      "Epoch 437/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1335 - accuracy: 0.7186\n",
      "Epoch 438/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1334 - accuracy: 0.7186\n",
      "Epoch 439/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1333 - accuracy: 0.7189s - loss: 0.1332 - accura\n",
      "Epoch 440/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1333 - accuracy: 0.7187\n",
      "Epoch 441/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7190\n",
      "Epoch 442/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1334 - accuracy: 0.7185\n",
      "Epoch 443/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7184\n",
      "Epoch 444/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1333 - accuracy: 0.7191\n",
      "Epoch 445/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1333 - accuracy: 0.7188\n",
      "Epoch 446/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1333 - accuracy: 0.7188\n",
      "Epoch 447/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7188\n",
      "Epoch 448/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1333 - accuracy: 0.7187\n",
      "Epoch 449/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1331 - accuracy: 0.7197s - loss: 0.1331 - accuracy: \n",
      "Epoch 450/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7190\n",
      "Epoch 451/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1333 - accuracy: 0.7185\n",
      "Epoch 452/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1331 - accuracy: 0.7195\n",
      "Epoch 453/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1331 - accuracy: 0.7193\n",
      "Epoch 454/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1331 - accuracy: 0.7192\n",
      "Epoch 455/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7190\n",
      "Epoch 456/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7192\n",
      "Epoch 457/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7188\n",
      "Epoch 458/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7195\n",
      "Epoch 459/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7192\n",
      "Epoch 460/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7193\n",
      "Epoch 461/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7196\n",
      "Epoch 462/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7197\n",
      "Epoch 463/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1331 - accuracy: 0.7192\n",
      "Epoch 464/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7197\n",
      "Epoch 465/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1332 - accuracy: 0.7193\n",
      "Epoch 466/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1331 - accuracy: 0.7194\n",
      "Epoch 467/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7197\n",
      "Epoch 468/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7200s - loss:\n",
      "Epoch 469/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1331 - accuracy: 0.7186s - loss: 0.1332 - accuracy\n",
      "Epoch 470/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7202\n",
      "Epoch 471/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7201\n",
      "Epoch 472/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7199\n",
      "Epoch 473/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7201\n",
      "Epoch 474/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7199\n",
      "Epoch 475/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7196\n",
      "Epoch 476/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7197\n",
      "Epoch 477/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7198\n",
      "Epoch 478/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7200\n",
      "Epoch 479/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1328 - accuracy: 0.7204\n",
      "Epoch 480/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7200\n",
      "Epoch 481/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7197\n",
      "Epoch 482/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7201\n",
      "Epoch 483/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7201s\n",
      "Epoch 484/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1328 - accuracy: 0.7205\n",
      "Epoch 485/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1328 - accuracy: 0.7205\n",
      "Epoch 486/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7197\n",
      "Epoch 487/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1328 - accuracy: 0.7197\n",
      "Epoch 488/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7201s - loss:\n",
      "Epoch 489/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1328 - accuracy: 0.7206\n",
      "Epoch 490/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1328 - accuracy: 0.7205s - loss: 0.1327 - accuracy: \n",
      "Epoch 491/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1330 - accuracy: 0.7197\n",
      "Epoch 492/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7204\n",
      "Epoch 493/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1328 - accuracy: 0.7202\n",
      "Epoch 494/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7206\n",
      "Epoch 495/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1328 - accuracy: 0.7205s - loss: 0.1328 - accura\n",
      "Epoch 496/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7202\n",
      "Epoch 497/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1329 - accuracy: 0.7201\n",
      "Epoch 498/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7207\n",
      "Epoch 499/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7205\n",
      "Epoch 500/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7203\n",
      "Epoch 501/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7205\n",
      "Epoch 502/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7210\n",
      "Epoch 503/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7209\n",
      "Epoch 504/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7208\n",
      "Epoch 505/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7210\n",
      "Epoch 506/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7201\n",
      "Epoch 507/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7208\n",
      "Epoch 508/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7208\n",
      "Epoch 509/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7204\n",
      "Epoch 510/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7214\n",
      "Epoch 511/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1327 - accuracy: 0.7210\n",
      "Epoch 512/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7210\n",
      "Epoch 513/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7212\n",
      "Epoch 514/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7216\n",
      "Epoch 515/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7213\n",
      "Epoch 516/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7212\n",
      "Epoch 517/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7210\n",
      "Epoch 518/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7209\n",
      "Epoch 519/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7208\n",
      "Epoch 520/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7209\n",
      "Epoch 521/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1326 - accuracy: 0.7211\n",
      "Epoch 522/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7212\n",
      "Epoch 523/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7211\n",
      "Epoch 524/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7213\n",
      "Epoch 525/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7208\n",
      "Epoch 526/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7212\n",
      "Epoch 527/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7213\n",
      "Epoch 528/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7215\n",
      "Epoch 529/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7212\n",
      "Epoch 530/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7215\n",
      "Epoch 531/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7215\n",
      "Epoch 532/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7217\n",
      "Epoch 533/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7210\n",
      "Epoch 534/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7216\n",
      "Epoch 535/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7218\n",
      "Epoch 536/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7220\n",
      "Epoch 537/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7218\n",
      "Epoch 538/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7213\n",
      "Epoch 539/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1325 - accuracy: 0.7210\n",
      "Epoch 540/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7213\n",
      "Epoch 541/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7213\n",
      "Epoch 542/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7217\n",
      "Epoch 543/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7220\n",
      "Epoch 544/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7215\n",
      "Epoch 545/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7217\n",
      "Epoch 546/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7218\n",
      "Epoch 547/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7219\n",
      "Epoch 548/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7220\n",
      "Epoch 549/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1324 - accuracy: 0.7216\n",
      "Epoch 550/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7219\n",
      "Epoch 551/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7221\n",
      "Epoch 552/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7223\n",
      "Epoch 553/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7222\n",
      "Epoch 554/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7222\n",
      "Epoch 555/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7225\n",
      "Epoch 556/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1323 - accuracy: 0.7220\n",
      "Epoch 557/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7220\n",
      "Epoch 558/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7223\n",
      "Epoch 559/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7222\n",
      "Epoch 560/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7221\n",
      "Epoch 561/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7223\n",
      "Epoch 562/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7220\n",
      "Epoch 563/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1320 - accuracy: 0.7227\n",
      "Epoch 564/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7223\n",
      "Epoch 565/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7224\n",
      "Epoch 566/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7220\n",
      "Epoch 567/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7221\n",
      "Epoch 568/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7219\n",
      "Epoch 569/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7224\n",
      "Epoch 570/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7223\n",
      "Epoch 571/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1320 - accuracy: 0.7227\n",
      "Epoch 572/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1320 - accuracy: 0.7229\n",
      "Epoch 573/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7222s - loss:\n",
      "Epoch 574/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7222\n",
      "Epoch 575/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1320 - accuracy: 0.7228\n",
      "Epoch 576/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1322 - accuracy: 0.7218\n",
      "Epoch 577/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1321 - accuracy: 0.7223\n",
      "Epoch 578/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1320 - accuracy: 0.7227\n",
      "Epoch 579/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1320 - accuracy: 0.7229\n",
      "Epoch 580/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1320 - accuracy: 0.7230\n",
      "Epoch 581/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1320 - accuracy: 0.7229\n",
      "Epoch 582/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1320 - accuracy: 0.7226\n",
      "Epoch 583/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1320 - accuracy: 0.7227\n",
      "Epoch 584/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1320 - accuracy: 0.7228s - loss: 0.1320 - accuracy: 0.\n",
      "Epoch 585/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1320 - accuracy: 0.7230s - los\n",
      "Epoch 586/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1320 - accuracy: 0.7227\n",
      "Epoch 587/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1320 - accuracy: 0.7225\n",
      "Epoch 588/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1320 - accuracy: 0.7227\n",
      "Epoch 589/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7231\n",
      "Epoch 590/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7231\n",
      "Epoch 591/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1321 - accuracy: 0.7227\n",
      "Epoch 592/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1320 - accuracy: 0.7232\n",
      "Epoch 593/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7231\n",
      "Epoch 594/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1320 - accuracy: 0.7228\n",
      "Epoch 595/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7230\n",
      "Epoch 596/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7231\n",
      "Epoch 597/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7233s - loss: 0.1319 - accuracy: 0.72\n",
      "Epoch 598/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7232\n",
      "Epoch 599/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7234\n",
      "Epoch 600/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7229\n",
      "Epoch 601/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7233\n",
      "Epoch 602/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7228\n",
      "Epoch 603/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7232\n",
      "Epoch 604/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7232\n",
      "Epoch 605/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7230\n",
      "Epoch 606/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7230\n",
      "Epoch 607/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7228\n",
      "Epoch 608/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7235\n",
      "Epoch 609/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7241\n",
      "Epoch 610/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7229\n",
      "Epoch 611/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1319 - accuracy: 0.7234\n",
      "Epoch 612/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7236\n",
      "Epoch 613/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7234s - loss:\n",
      "Epoch 614/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7234\n",
      "Epoch 615/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7236\n",
      "Epoch 616/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1318 - accuracy: 0.7237s - loss: 0.1318 - \n",
      "Epoch 617/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7237\n",
      "Epoch 618/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7235\n",
      "Epoch 619/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7235\n",
      "Epoch 620/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7234\n",
      "Epoch 621/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7239\n",
      "Epoch 622/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7239\n",
      "Epoch 623/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7237\n",
      "Epoch 624/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7239s - loss: 0.1317 - accuracy: 0.\n",
      "Epoch 625/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7236\n",
      "Epoch 626/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7238\n",
      "Epoch 627/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7239\n",
      "Epoch 628/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7238\n",
      "Epoch 629/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7242\n",
      "Epoch 630/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7247s - loss: 0.1316 \n",
      "Epoch 631/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7238\n",
      "Epoch 632/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7238\n",
      "Epoch 633/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1315 - accuracy: 0.7242\n",
      "Epoch 634/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7235\n",
      "Epoch 635/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7243s - loss: 0.1314 - accura\n",
      "Epoch 636/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1316 - accuracy: 0.7235\n",
      "Epoch 637/1000\n",
      "579091/579091 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.72 - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7239\n",
      "Epoch 638/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1317 - accuracy: 0.7238\n",
      "Epoch 639/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7238\n",
      "Epoch 640/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7242\n",
      "Epoch 641/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7240\n",
      "Epoch 642/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7241\n",
      "Epoch 643/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7239\n",
      "Epoch 644/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7242\n",
      "Epoch 645/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7241\n",
      "Epoch 646/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7241\n",
      "Epoch 647/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7245\n",
      "Epoch 648/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7241\n",
      "Epoch 649/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7250\n",
      "Epoch 650/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7236\n",
      "Epoch 651/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7247\n",
      "Epoch 652/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7240\n",
      "Epoch 653/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7247\n",
      "Epoch 654/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7241\n",
      "Epoch 655/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7244\n",
      "Epoch 656/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7244\n",
      "Epoch 657/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7239\n",
      "Epoch 658/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7241\n",
      "Epoch 659/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7248\n",
      "Epoch 660/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7241\n",
      "Epoch 661/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7248\n",
      "Epoch 662/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7243\n",
      "Epoch 663/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1316 - accuracy: 0.7240\n",
      "Epoch 664/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7251\n",
      "Epoch 665/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7244\n",
      "Epoch 666/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7245\n",
      "Epoch 667/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7247\n",
      "Epoch 668/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7250\n",
      "Epoch 669/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7246\n",
      "Epoch 670/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1315 - accuracy: 0.7246\n",
      "Epoch 671/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7246\n",
      "Epoch 672/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7251\n",
      "Epoch 673/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7250\n",
      "Epoch 674/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1314 - accuracy: 0.7250\n",
      "Epoch 675/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1313 - accuracy: 0.7250\n",
      "Epoch 676/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7249\n",
      "Epoch 677/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7245\n",
      "Epoch 678/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7246\n",
      "Epoch 679/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7249\n",
      "Epoch 680/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7245\n",
      "Epoch 681/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7254\n",
      "Epoch 682/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7250\n",
      "Epoch 683/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7250\n",
      "Epoch 684/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7249\n",
      "Epoch 685/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7251\n",
      "Epoch 686/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1313 - accuracy: 0.7252\n",
      "Epoch 687/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7248\n",
      "Epoch 688/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1314 - accuracy: 0.7248\n",
      "Epoch 689/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7250\n",
      "Epoch 690/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7252\n",
      "Epoch 691/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7260\n",
      "Epoch 692/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7249\n",
      "Epoch 693/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7255\n",
      "Epoch 694/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7251\n",
      "Epoch 695/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7247\n",
      "Epoch 696/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7254\n",
      "Epoch 697/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7249\n",
      "Epoch 698/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7256\n",
      "Epoch 699/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7252\n",
      "Epoch 700/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7248\n",
      "Epoch 701/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7255\n",
      "Epoch 702/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1313 - accuracy: 0.7252\n",
      "Epoch 703/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1311 - accuracy: 0.7260\n",
      "Epoch 704/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7253\n",
      "Epoch 705/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7256\n",
      "Epoch 706/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7249\n",
      "Epoch 707/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7255\n",
      "Epoch 708/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7256\n",
      "Epoch 709/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7256\n",
      "Epoch 710/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7251\n",
      "Epoch 711/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1310 - accuracy: 0.7258\n",
      "Epoch 712/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1311 - accuracy: 0.7257\n",
      "Epoch 713/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1312 - accuracy: 0.7254\n",
      "Epoch 714/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1312 - accuracy: 0.7253\n",
      "Epoch 715/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1310 - accuracy: 0.7257\n",
      "Epoch 716/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1311 - accuracy: 0.7255\n",
      "Epoch 717/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7258\n",
      "Epoch 718/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7258\n",
      "Epoch 719/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7259\n",
      "Epoch 720/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7255\n",
      "Epoch 721/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7257\n",
      "Epoch 722/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7259\n",
      "Epoch 723/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7257\n",
      "Epoch 724/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7256\n",
      "Epoch 725/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7257\n",
      "Epoch 726/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7256s -\n",
      "Epoch 727/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7255s - loss: 0.1310 - accuracy: 0.\n",
      "Epoch 728/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7257\n",
      "Epoch 729/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7257\n",
      "Epoch 730/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7260\n",
      "Epoch 731/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7259\n",
      "Epoch 732/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7260\n",
      "Epoch 733/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7260\n",
      "Epoch 734/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7258\n",
      "Epoch 735/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7257\n",
      "Epoch 736/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7260\n",
      "Epoch 737/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1312 - accuracy: 0.7255\n",
      "Epoch 738/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7260\n",
      "Epoch 739/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7258\n",
      "Epoch 740/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7261\n",
      "Epoch 741/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7263\n",
      "Epoch 742/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7261\n",
      "Epoch 743/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1311 - accuracy: 0.7256\n",
      "Epoch 744/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7265\n",
      "Epoch 745/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7258\n",
      "Epoch 746/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1310 - accuracy: 0.7259\n",
      "Epoch 747/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7256\n",
      "Epoch 748/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7262\n",
      "Epoch 749/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7262\n",
      "Epoch 750/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7264\n",
      "Epoch 751/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7262\n",
      "Epoch 752/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7263\n",
      "Epoch 753/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7263\n",
      "Epoch 754/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7263\n",
      "Epoch 755/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7263\n",
      "Epoch 756/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7264\n",
      "Epoch 757/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7262\n",
      "Epoch 758/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7261\n",
      "Epoch 759/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7266\n",
      "Epoch 760/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1308 - accuracy: 0.7265\n",
      "Epoch 761/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1307 - accuracy: 0.7266\n",
      "Epoch 762/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1308 - accuracy: 0.7266\n",
      "Epoch 763/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1308 - accuracy: 0.7267\n",
      "Epoch 764/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1309 - accuracy: 0.7265\n",
      "Epoch 765/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1309 - accuracy: 0.7264\n",
      "Epoch 766/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7269\n",
      "Epoch 767/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7264\n",
      "Epoch 768/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7265\n",
      "Epoch 769/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7268\n",
      "Epoch 770/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7255\n",
      "Epoch 771/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7270\n",
      "Epoch 772/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7263\n",
      "Epoch 773/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7261\n",
      "Epoch 774/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7267\n",
      "Epoch 775/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7268\n",
      "Epoch 776/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7272\n",
      "Epoch 777/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1309 - accuracy: 0.7266s - loss: 0.130\n",
      "Epoch 778/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7265\n",
      "Epoch 779/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7268\n",
      "Epoch 780/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7266\n",
      "Epoch 781/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7266\n",
      "Epoch 782/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1306 - accuracy: 0.7276\n",
      "Epoch 783/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7269\n",
      "Epoch 784/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7266\n",
      "Epoch 785/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1306 - accuracy: 0.7274\n",
      "Epoch 786/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7267\n",
      "Epoch 787/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1307 - accuracy: 0.7267\n",
      "Epoch 788/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1307 - accuracy: 0.7271\n",
      "Epoch 789/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1306 - accuracy: 0.7268\n",
      "Epoch 790/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7267\n",
      "Epoch 791/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7271\n",
      "Epoch 792/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1306 - accuracy: 0.7271\n",
      "Epoch 793/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1307 - accuracy: 0.7268\n",
      "Epoch 794/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1308 - accuracy: 0.7267\n",
      "Epoch 795/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7272\n",
      "Epoch 796/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1307 - accuracy: 0.7266\n",
      "Epoch 797/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1307 - accuracy: 0.7270\n",
      "Epoch 798/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1307 - accuracy: 0.7268\n",
      "Epoch 799/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7273\n",
      "Epoch 800/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7272\n",
      "Epoch 801/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1307 - accuracy: 0.7265\n",
      "Epoch 802/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7271\n",
      "Epoch 803/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7271\n",
      "Epoch 804/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1307 - accuracy: 0.7263\n",
      "Epoch 805/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1307 - accuracy: 0.7267\n",
      "Epoch 806/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1307 - accuracy: 0.7271s - loss: 0\n",
      "Epoch 807/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7268\n",
      "Epoch 808/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7272\n",
      "Epoch 809/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7278\n",
      "Epoch 810/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7277s - los\n",
      "Epoch 811/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7274\n",
      "Epoch 812/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7272\n",
      "Epoch 813/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7268\n",
      "Epoch 814/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7276\n",
      "Epoch 815/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7271\n",
      "Epoch 816/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7270\n",
      "Epoch 817/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7278\n",
      "Epoch 818/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7274\n",
      "Epoch 819/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7276\n",
      "Epoch 820/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1305 - accuracy: 0.7275\n",
      "Epoch 821/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1306 - accuracy: 0.7272\n",
      "Epoch 822/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7272\n",
      "Epoch 823/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7272\n",
      "Epoch 824/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7270s - los - ETA: 0s - loss: 0.1305 - accu\n",
      "Epoch 825/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1305 - accuracy: 0.7273\n",
      "Epoch 826/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1305 - accuracy: 0.7272\n",
      "Epoch 827/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7268\n",
      "Epoch 828/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7272\n",
      "Epoch 829/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7273\n",
      "Epoch 830/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7274\n",
      "Epoch 831/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7278\n",
      "Epoch 832/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7272\n",
      "Epoch 833/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7274\n",
      "Epoch 834/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1306 - accuracy: 0.7271\n",
      "Epoch 835/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7278\n",
      "Epoch 836/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7268\n",
      "Epoch 837/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7276\n",
      "Epoch 838/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7275\n",
      "Epoch 839/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7273\n",
      "Epoch 840/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1304 - accuracy: 0.7275s - loss: 0.1304 - ac\n",
      "Epoch 841/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1305 - accuracy: 0.7276\n",
      "Epoch 842/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1304 - accuracy: 0.7276\n",
      "Epoch 843/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7278\n",
      "Epoch 844/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7279\n",
      "Epoch 845/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7279\n",
      "Epoch 846/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7273\n",
      "Epoch 847/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7281\n",
      "Epoch 848/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7281\n",
      "Epoch 849/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7277\n",
      "Epoch 850/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7284\n",
      "Epoch 851/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7274\n",
      "Epoch 852/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7280\n",
      "Epoch 853/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7276\n",
      "Epoch 854/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7277\n",
      "Epoch 855/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7278\n",
      "Epoch 856/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7281\n",
      "Epoch 857/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7280\n",
      "Epoch 858/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 859/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7278\n",
      "Epoch 860/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7276s -\n",
      "Epoch 861/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7281\n",
      "Epoch 862/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7275\n",
      "Epoch 863/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7277\n",
      "Epoch 864/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7280\n",
      "Epoch 865/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7280- ETA: 0s\n",
      "Epoch 866/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7280\n",
      "Epoch 867/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7277\n",
      "Epoch 868/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7280\n",
      "Epoch 869/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1304 - accuracy: 0.7275\n",
      "Epoch 870/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7279\n",
      "Epoch 871/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1305 - accuracy: 0.7274\n",
      "Epoch 872/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7286s - loss: 0.1302 \n",
      "Epoch 873/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1302 - accuracy: 0.7280\n",
      "Epoch 874/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1304 - accuracy: 0.7278\n",
      "Epoch 875/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7280\n",
      "Epoch 876/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1303 - accuracy: 0.7279\n",
      "Epoch 877/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1303 - accuracy: 0.7277\n",
      "Epoch 878/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1302 - accuracy: 0.7287\n",
      "Epoch 879/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1303 - accuracy: 0.7285\n",
      "Epoch 880/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1304 - accuracy: 0.7275\n",
      "Epoch 881/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1301 - accuracy: 0.7288\n",
      "Epoch 882/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7284\n",
      "Epoch 883/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1302 - accuracy: 0.7284s - l\n",
      "Epoch 884/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1302 - accuracy: 0.7285\n",
      "Epoch 885/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1304 - accuracy: 0.7282\n",
      "Epoch 886/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1303 - accuracy: 0.7280\n",
      "Epoch 887/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7287s\n",
      "Epoch 888/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1304 - accuracy: 0.7280\n",
      "Epoch 889/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7283\n",
      "Epoch 890/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7279\n",
      "Epoch 891/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7284\n",
      "Epoch 892/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7285\n",
      "Epoch 893/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7281s - loss: 0.1302 - \n",
      "Epoch 894/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7280\n",
      "Epoch 895/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7281\n",
      "Epoch 896/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7276\n",
      "Epoch 897/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7284\n",
      "Epoch 898/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7285\n",
      "Epoch 899/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1302 - accuracy: 0.7283\n",
      "Epoch 900/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7282\n",
      "Epoch 901/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7283\n",
      "Epoch 902/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1302 - accuracy: 0.7287\n",
      "Epoch 903/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1303 - accuracy: 0.7279\n",
      "Epoch 904/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7289\n",
      "Epoch 905/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1301 - accuracy: 0.7287\n",
      "Epoch 906/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7282\n",
      "Epoch 907/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7282\n",
      "Epoch 908/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7282s - loss: 0.1303 \n",
      "Epoch 909/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1301 - accuracy: 0.7289\n",
      "Epoch 910/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7292\n",
      "Epoch 911/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7278\n",
      "Epoch 912/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7283\n",
      "Epoch 913/1000\n",
      "579091/579091 [==============================] - 10s 16us/sample - loss: 0.1301 - accuracy: 0.7289\n",
      "Epoch 914/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1301 - accuracy: 0.7287\n",
      "Epoch 915/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7280\n",
      "Epoch 916/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1300 - accuracy: 0.7289\n",
      "Epoch 917/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7284\n",
      "Epoch 918/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1302 - accuracy: 0.7286\n",
      "Epoch 919/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1300 - accuracy: 0.7287\n",
      "Epoch 920/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7281\n",
      "Epoch 921/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7287\n",
      "Epoch 922/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7289\n",
      "Epoch 923/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7288\n",
      "Epoch 924/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7284\n",
      "Epoch 925/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7285\n",
      "Epoch 926/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7287\n",
      "Epoch 927/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7285\n",
      "Epoch 928/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7292\n",
      "Epoch 929/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7284\n",
      "Epoch 930/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1302 - accuracy: 0.7283\n",
      "Epoch 931/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1300 - accuracy: 0.7289\n",
      "Epoch 932/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7282\n",
      "Epoch 933/1000\n",
      "579091/579091 [==============================] - 8s 15us/sample - loss: 0.1300 - accuracy: 0.7290\n",
      "Epoch 934/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7291\n",
      "Epoch 935/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7289\n",
      "Epoch 936/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7291\n",
      "Epoch 937/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1301 - accuracy: 0.7289\n",
      "Epoch 938/1000\n",
      "579091/579091 [==============================] - 10s 16us/sample - loss: 0.1300 - accuracy: 0.7285\n",
      "Epoch 939/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1300 - accuracy: 0.7291\n",
      "Epoch 940/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7293\n",
      "Epoch 941/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7285\n",
      "Epoch 942/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1300 - accuracy: 0.7292\n",
      "Epoch 943/1000\n",
      "579091/579091 [==============================] - 10s 17us/sample - loss: 0.1299 - accuracy: 0.7293\n",
      "Epoch 944/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1299 - accuracy: 0.7292\n",
      "Epoch 945/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1300 - accuracy: 0.7289\n",
      "Epoch 946/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1300 - accuracy: 0.7288\n",
      "Epoch 947/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1299 - accuracy: 0.7292\n",
      "Epoch 948/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7290s - loss: 0.1299 - accu\n",
      "Epoch 949/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7293\n",
      "Epoch 950/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7290\n",
      "Epoch 951/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1300 - accuracy: 0.7287\n",
      "Epoch 952/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7292\n",
      "Epoch 953/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7288\n",
      "Epoch 954/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7293\n",
      "Epoch 955/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7290\n",
      "Epoch 956/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7288\n",
      "Epoch 957/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1300 - accuracy: 0.7284\n",
      "Epoch 958/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7289\n",
      "Epoch 959/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7291\n",
      "Epoch 960/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7292\n",
      "Epoch 961/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1300 - accuracy: 0.7288\n",
      "Epoch 962/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1301 - accuracy: 0.7289\n",
      "Epoch 963/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7290\n",
      "Epoch 964/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7291\n",
      "Epoch 965/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7295\n",
      "Epoch 966/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7295\n",
      "Epoch 967/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7295\n",
      "Epoch 968/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7291\n",
      "Epoch 969/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7289\n",
      "Epoch 970/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7287\n",
      "Epoch 971/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7292\n",
      "Epoch 972/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7291\n",
      "Epoch 973/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1298 - accuracy: 0.7295\n",
      "Epoch 974/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1298 - accuracy: 0.7297\n",
      "Epoch 975/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1298 - accuracy: 0.7298\n",
      "Epoch 976/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1298 - accuracy: 0.7303\n",
      "Epoch 977/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1300 - accuracy: 0.7287\n",
      "Epoch 978/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1299 - accuracy: 0.7295\n",
      "Epoch 979/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1298 - accuracy: 0.7292\n",
      "Epoch 980/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1297 - accuracy: 0.7298\n",
      "Epoch 981/1000\n",
      "579091/579091 [==============================] - 9s 15us/sample - loss: 0.1298 - accuracy: 0.7296s - l\n",
      "Epoch 982/1000\n",
      "579091/579091 [==============================] - 9s 16us/sample - loss: 0.1298 - accuracy: 0.7295\n",
      "Epoch 983/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7295\n",
      "Epoch 984/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7295\n",
      "Epoch 985/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1299 - accuracy: 0.7290\n",
      "Epoch 986/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7293\n",
      "Epoch 987/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7293\n",
      "Epoch 988/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7295\n",
      "Epoch 989/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1300 - accuracy: 0.7289\n",
      "Epoch 990/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7296\n",
      "Epoch 991/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7297\n",
      "Epoch 992/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1299 - accuracy: 0.7290\n",
      "Epoch 993/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7293\n",
      "Epoch 994/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1297 - accuracy: 0.7299\n",
      "Epoch 995/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1299 - accuracy: 0.7296\n",
      "Epoch 996/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1297 - accuracy: 0.7298\n",
      "Epoch 997/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1297 - accuracy: 0.7299\n",
      "Epoch 998/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1298 - accuracy: 0.7293\n",
      "Epoch 999/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1297 - accuracy: 0.7298\n",
      "Epoch 1000/1000\n",
      "579091/579091 [==============================] - 8s 14us/sample - loss: 0.1297 - accuracy: 0.7297\n"
     ]
    }
   ],
   "source": [
    "lr =  0.017722015080147924\n",
    "Lambda = 0.001766687183734540564\n",
    "iterations = 1000\n",
    "learning_rate = lr\n",
    "hidden_nodes = 256\n",
    "output_nodes = 10\n",
    "batch_size = 250\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape = (300,),kernel_initializer='he_normal',activation=None))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(3,activation='sigmoid', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "\n",
    "sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_tr,y_tr_cat, epochs=iterations, batch_size= batch_size, verbose= 1)\n",
    "score = model.evaluate(x_te, y_te_cat, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4454e",
   "metadata": {},
   "source": [
    "### Finally with a 1000 iterations and a reduced batch size, we could stretch the fit to a 73% percent accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b71e91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17086894100450517, 0.6303269]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0943d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_text):\n",
    "        word_data = []\n",
    "        sentence = np.zeros(300)\n",
    "        count = 0\n",
    "        for w in tokenizer(input_text):\n",
    "            try:\n",
    "                sentence += embeddings_index[w]\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "                continue\n",
    "        return np.array(sentence / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cabab0a",
   "metadata": {},
   "source": [
    "a function to derive word embeddings of the input text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b1f0d313",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "text:             urlLink    Tomorrow's the day! I'll post my predictions in the morning...         ,\n",
      "\n",
      "predicted age class = 20s,\n",
      "\n",
      "actual age class = 20s\n",
      "\n",
      "\n",
      "text:         From  the Washington Post:   Nader's Advice To Kerry By William Raspberry      Ralph Nader, according to many who say they used to admire him, has become the self-centered star whose press clippings have gone to his head, the dog in the manger, the skunk at the Democratic garden party.     After all, the man whose name comes to mind at the mention of the phrase 'consumer advocate' is also the man who almost certainly helped elect President Bush -- by siphoning away a few thousand Florida votes that otherwise would have gone to Al Gore.     And now he's running for president again!     Well, the advice here is that the Democrats -- very much including presumptive nominee John Kerry -- would do well to pause in their brick-throwing long enough to listen. Because what Nader is offering, he genuinely believes, is a road map to a Kerry victory.     'A part of the problem,' Nader said in an interview last week, 'is that the Democrats have become too cautious -- too indentured to the same money the Republicans are dialing for. Kerry's consultants and handlers are telling him to tone it down, and he has. For example, he's now saying, 'I'm not a redistributionist, I'm a centrist,' and that speaks volumes. Because the issue isn't redistributing wealth in the old-fashioned sense but stopping the redistribution that's already going on through corporate welfare.'     In fact, ending corporate welfare is one of 10 elements of what Nader is certain would be a winning campaign. 'Democrats would like it, but so would lots of conservatives, liberals and progressives who don't like the way wealth is being redistributed in this country.' Here are some other ideas on Nader's list:     * Support a living wage. Kerry should propose a living wage -- and act as though he means it. Huge numbers of Americans (10 million  households) earn less than $10,000 a year. Those workers would be substantially better off if the minimum wage had simply been indexed for inflation -- 'like congressional salaries' -- over the past 35 years.    * Go after corporate crime. 'This would attract a lot of conservatives to his cause -- certainly as many as there are Reagan Democrats. I'm talking about people whose 401(k)s have been destroyed by what Enron and the others have done through corporate greed.'    * Repeal the Bush tax cuts for the wealthy. The prospective yield turns out to be 'almost exactly what the American Society of Civil Engineers said last year it would take to restore America's deteriorating infrastructure' -- roads and bridges, schools, libraries, water and sewer systems, public buildings. 'Everybody could get behind this, from labor unions to the Rotary, from workers to the corporate suppliers. And the best part is that it would create thousands of good-paying jobs that can't be outsourced to China.'    * Protect the poor. Low-income Americans have no legal protection for many of their ordinary transactions -- either because the appropriate legislation hasn't been enacted or because of 'a congealed lawlessness that goes unprosecuted.' Nader's list includes check-cashing businesses for people who don't have access to bank accounts, tax-refund loans at usurious rates, rent-to-own schemes, dumping of tainted meat and shoddy merchandise in inner-city outlets, bank red-lining, and all manner of predatory lending. 'Democrats should flock to this issue, and the Republican blur machine couldn't do a thing about it. You know how they blur issues: passing an inadequate prescription bill and saying that takes care of the elderly, or passing No Child Left Behind and saying that takes care of education.'     Nader says Kerry should demand reform of a tax code that taxes work more than it taxes wealth; promote reduced reliance on fossil and nuclear energy; and support a reversal of policies that 'make it almost impossible to form a union in the private sector anymore.'     As for the war in Iraq: Kerry needs to set a date for withdrawal of American troops  and   companies. 'The way to separate mainstream Iraqis from the insurgents is to make clear that there will be no American occupation -- stop building those 14 military bases -- and no puppet government. Bring in peacekeepers from neutral countries and from Egypt and elsewhere in the Arab world, until Iraqi forces take hold with internationally supervised elections.'     'If Kerry takes these positions,' Nader concludes, 'the only thing he'll have to worry about is how big will be his landslide.'     Maybe. At the very least, it would provide an answer to those who've been looking for some reason to support Kerry besides the fact that he isn't Bush.         ,\n",
      "\n",
      "predicted age class = 30s,\n",
      "\n",
      "actual age class = 30s\n",
      "\n",
      "\n",
      "text:         What's up crazy motherfuckers, this is my first post, so it'll probably suck. Neways, today was ok. Better than last week..that was probably one of the worst weeks I've ever had. I just kept on steppin' into shitpile after shitpile after shitpile. So today, not a damn thing happened, so it was a good day. Ashley, my girlfriend, her tounge started swelling up and it wasn't good. We don't know if she was allergic to some food or if her tounge piercing is infected, but it's bad. I wish i could fucking do something, but she's out in California and I'm fucking stuck in Tennessee. We met when Sissy (Destiny, our really good friend) introduced us and we just fell in love. We are both horny as motherfuckers so we can't wait till she comes to visit out here...we're gonna fuck like rabbits...kinky rabbits...with handcuffs...and strawberries.... can't wait....*stares off*...*drools*...oh...sorry *wipes off drool* anyways, well I think that's it for now. tty fuckers later!   Nick    &nbsp;     ,\n",
      "\n",
      "predicted age class = 10s,\n",
      "\n",
      "actual age class = 10s\n",
      "\n",
      "\n",
      "text:        Here Katie.  If you are bored check out this  urlLink  Fark photoshop contest of Condy Rice .         ,\n",
      "\n",
      "predicted age class = 20s,\n",
      "\n",
      "actual age class = 20s\n",
      "\n",
      "\n",
      "text:         Nobody can tell you how to be happy. I think that fact has been established. Know then, that if you are unhappy, it is from your own doing. No outside force exists that is pinned against you, hoping for your failure, making you miserable. And if you are the cause of your own unhappiness, then you must be in control of your&nbsp;own&nbsp;happiness. There cannot exist unhappy without happy, otherwise there would be no balance. We would either be chronically happy or eternally miserable and not even know it. You must change your perspective. There cannot be happy without sad, so if you are sad, know that happy is just around the corner. But most importantly, you must come to this conclusion on your own. We all know these things, but we must  realize  them. We must understand the implications of being sad and being happy. Never accept what someone is telling you simply because it is in a book or a blog. Most blogs are full of shit. I am not so arrogant to insinuate that this blog is not full of shit as well. That is a conclusion you must draw yourself.,\n",
      "\n",
      "predicted age class = 10s,\n",
      "\n",
      "actual age class = 20s\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    idx = np.random.randint(1,x.shape[0])\n",
    "    inp_array = x[idx]\n",
    "    inp_array = np.expand_dims(inp_array,axis=0)\n",
    "    pred = model.predict(inp_array)\n",
    "    decoded = np.where(pred[0]<max(pred[0]),0,1)\n",
    "    pred_class = le.classes_[np.argmax(decoded)]\n",
    "    actual = data['age'][idx]\n",
    "    print('\\n\\ntext: '+data['text'][idx]+',\\n\\npredicted age class = '+pred_class+',\\n\\nactual age class = '+actual)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088d075",
   "metadata": {},
   "source": [
    "### 4 out of 5 blog texts got classified correctly on the basis of author's age bracket at 73% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fca4b0",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d54c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb2e02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66b65d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Vishak\\Great Learning\\Natural Language Processing\\NLP Project\\GL Bot.json\") as file:\n",
    "    data = json.load(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69bd94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = []\n",
    "train_labls = []\n",
    "\n",
    "labls = []\n",
    "responses = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        train_sents.append(pattern)\n",
    "        train_labls.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['tag'] not in labls:\n",
    "        labls.append(intent['tag'])\n",
    "num_classes = len(labls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0efc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_labls)\n",
    "train_labls = encoder.transform(train_labls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "946f57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lim = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=word_lim, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(train_sents)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(train_sents)\n",
    "pad_seq = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f6c7e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 16)            16000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 16,714\n",
      "Trainable params: 16,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(word_lim, embedding_dim, input_length=max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "77e5a199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141 samples\n",
      "Epoch 1/2000\n",
      "141/141 [==============================] - ETA: 29s - loss: 2.2973 - accuracy: 0.093 - 9s 62ms/sample - loss: 2.2986 - accuracy: 0.1277\n",
      "Epoch 2/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2891 - accuracy: 0.25 - 0s 163us/sample - loss: 2.2902 - accuracy: 0.2128\n",
      "Epoch 3/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2826 - accuracy: 0.15 - 0s 177us/sample - loss: 2.2836 - accuracy: 0.2057\n",
      "Epoch 4/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2782 - accuracy: 0.31 - 0s 177us/sample - loss: 2.2761 - accuracy: 0.2057\n",
      "Epoch 5/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2735 - accuracy: 0.25 - 0s 163us/sample - loss: 2.2689 - accuracy: 0.1631\n",
      "Epoch 6/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2405 - accuracy: 0.28 - 0s 163us/sample - loss: 2.2615 - accuracy: 0.1702\n",
      "Epoch 7/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2243 - accuracy: 0.25 - 0s 163us/sample - loss: 2.2533 - accuracy: 0.1702\n",
      "Epoch 8/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2786 - accuracy: 0.15 - 0s 163us/sample - loss: 2.2445 - accuracy: 0.2482\n",
      "Epoch 9/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2510 - accuracy: 0.18 - 0s 142us/sample - loss: 2.2359 - accuracy: 0.3121\n",
      "Epoch 10/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2496 - accuracy: 0.40 - 0s 149us/sample - loss: 2.2271 - accuracy: 0.2837\n",
      "Epoch 11/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2163 - accuracy: 0.21 - 0s 149us/sample - loss: 2.2180 - accuracy: 0.2624\n",
      "Epoch 12/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2088 - accuracy: 0.31 - 0s 142us/sample - loss: 2.2072 - accuracy: 0.2270\n",
      "Epoch 13/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2477 - accuracy: 0.25 - 0s 148us/sample - loss: 2.1976 - accuracy: 0.2057\n",
      "Epoch 14/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1129 - accuracy: 0.28 - 0s 156us/sample - loss: 2.1882 - accuracy: 0.2057\n",
      "Epoch 15/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2024 - accuracy: 0.21 - 0s 163us/sample - loss: 2.1785 - accuracy: 0.2057\n",
      "Epoch 16/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2282 - accuracy: 0.21 - 0s 156us/sample - loss: 2.1696 - accuracy: 0.2057\n",
      "Epoch 17/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1636 - accuracy: 0.28 - 0s 142us/sample - loss: 2.1622 - accuracy: 0.2057\n",
      "Epoch 18/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2833 - accuracy: 0.09 - 0s 163us/sample - loss: 2.1544 - accuracy: 0.2057\n",
      "Epoch 19/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1925 - accuracy: 0.09 - 0s 156us/sample - loss: 2.1482 - accuracy: 0.2057\n",
      "Epoch 20/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0936 - accuracy: 0.25 - 0s 149us/sample - loss: 2.1437 - accuracy: 0.2057\n",
      "Epoch 21/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1893 - accuracy: 0.21 - 0s 156us/sample - loss: 2.1376 - accuracy: 0.2057\n",
      "Epoch 22/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2169 - accuracy: 0.21 - 0s 142us/sample - loss: 2.1329 - accuracy: 0.2057\n",
      "Epoch 23/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0798 - accuracy: 0.34 - 0s 156us/sample - loss: 2.1283 - accuracy: 0.2057\n",
      "Epoch 24/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1837 - accuracy: 0.12 - 0s 149us/sample - loss: 2.1242 - accuracy: 0.2057\n",
      "Epoch 25/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0729 - accuracy: 0.25 - 0s 149us/sample - loss: 2.1201 - accuracy: 0.2057\n",
      "Epoch 26/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0199 - accuracy: 0.31 - 0s 156us/sample - loss: 2.1164 - accuracy: 0.2057\n",
      "Epoch 27/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0632 - accuracy: 0.18 - 0s 149us/sample - loss: 2.1123 - accuracy: 0.2057\n",
      "Epoch 28/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1319 - accuracy: 0.18 - 0s 142us/sample - loss: 2.1073 - accuracy: 0.2057\n",
      "Epoch 29/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9250 - accuracy: 0.31 - 0s 149us/sample - loss: 2.1035 - accuracy: 0.2057\n",
      "Epoch 30/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0228 - accuracy: 0.28 - 0s 156us/sample - loss: 2.0992 - accuracy: 0.2057\n",
      "Epoch 31/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0077 - accuracy: 0.21 - 0s 142us/sample - loss: 2.0950 - accuracy: 0.2057\n",
      "Epoch 32/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0006 - accuracy: 0.31 - 0s 149us/sample - loss: 2.0905 - accuracy: 0.2057\n",
      "Epoch 33/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1286 - accuracy: 0.09 - 0s 149us/sample - loss: 2.0863 - accuracy: 0.2057\n",
      "Epoch 34/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0967 - accuracy: 0.12 - 0s 156us/sample - loss: 2.0815 - accuracy: 0.2057\n",
      "Epoch 35/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2066 - accuracy: 0.21 - 0s 149us/sample - loss: 2.0766 - accuracy: 0.2057\n",
      "Epoch 36/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1416 - accuracy: 0.25 - 0s 149us/sample - loss: 2.0712 - accuracy: 0.2057\n",
      "Epoch 37/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1116 - accuracy: 0.18 - 0s 163us/sample - loss: 2.0662 - accuracy: 0.2057\n",
      "Epoch 38/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1516 - accuracy: 0.15 - 0s 170us/sample - loss: 2.0600 - accuracy: 0.2057\n",
      "Epoch 39/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0833 - accuracy: 0.21 - 0s 156us/sample - loss: 2.0546 - accuracy: 0.2057\n",
      "Epoch 40/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1069 - accuracy: 0.12 - 0s 149us/sample - loss: 2.0483 - accuracy: 0.2057\n",
      "Epoch 41/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9157 - accuracy: 0.31 - 0s 149us/sample - loss: 2.0419 - accuracy: 0.2057\n",
      "Epoch 42/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1282 - accuracy: 0.18 - 0s 142us/sample - loss: 2.0354 - accuracy: 0.2057\n",
      "Epoch 43/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9874 - accuracy: 0.21 - 0s 156us/sample - loss: 2.0284 - accuracy: 0.2057\n",
      "Epoch 44/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0311 - accuracy: 0.18 - 0s 149us/sample - loss: 2.0207 - accuracy: 0.2057\n",
      "Epoch 45/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0466 - accuracy: 0.12 - 0s 163us/sample - loss: 2.0129 - accuracy: 0.2057\n",
      "Epoch 46/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1552 - accuracy: 0.09 - 0s 156us/sample - loss: 2.0047 - accuracy: 0.2057\n",
      "Epoch 47/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9496 - accuracy: 0.18 - 0s 170us/sample - loss: 1.9963 - accuracy: 0.2057\n",
      "Epoch 48/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9960 - accuracy: 0.18 - 0s 149us/sample - loss: 1.9871 - accuracy: 0.2057\n",
      "Epoch 49/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0015 - accuracy: 0.25 - 0s 149us/sample - loss: 1.9771 - accuracy: 0.2057\n",
      "Epoch 50/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0887 - accuracy: 0.09 - 0s 170us/sample - loss: 1.9666 - accuracy: 0.2057\n",
      "Epoch 51/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0223 - accuracy: 0.15 - 0s 156us/sample - loss: 1.9572 - accuracy: 0.2057\n",
      "Epoch 52/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9162 - accuracy: 0.21 - 0s 156us/sample - loss: 1.9449 - accuracy: 0.2057\n",
      "Epoch 53/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8928 - accuracy: 0.25 - 0s 142us/sample - loss: 1.9328 - accuracy: 0.2128\n",
      "Epoch 54/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0719 - accuracy: 0.15 - 0s 149us/sample - loss: 1.9185 - accuracy: 0.2128\n",
      "Epoch 55/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9388 - accuracy: 0.21 - 0s 149us/sample - loss: 1.9033 - accuracy: 0.2199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8392 - accuracy: 0.31 - 0s 156us/sample - loss: 1.8894 - accuracy: 0.2411\n",
      "Epoch 57/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6972 - accuracy: 0.28 - 0s 151us/sample - loss: 1.8747 - accuracy: 0.2411\n",
      "Epoch 58/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0438 - accuracy: 0.15 - 0s 163us/sample - loss: 1.8590 - accuracy: 0.2553\n",
      "Epoch 59/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9583 - accuracy: 0.15 - 0s 156us/sample - loss: 1.8434 - accuracy: 0.2624\n",
      "Epoch 60/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8208 - accuracy: 0.25 - 0s 156us/sample - loss: 1.8277 - accuracy: 0.2695\n",
      "Epoch 61/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9086 - accuracy: 0.18 - 0s 135us/sample - loss: 1.8118 - accuracy: 0.2695\n",
      "Epoch 62/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6765 - accuracy: 0.31 - 0s 142us/sample - loss: 1.7949 - accuracy: 0.2979\n",
      "Epoch 63/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8321 - accuracy: 0.31 - 0s 149us/sample - loss: 1.7774 - accuracy: 0.3121\n",
      "Epoch 64/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8738 - accuracy: 0.28 - 0s 142us/sample - loss: 1.7587 - accuracy: 0.3121\n",
      "Epoch 65/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7212 - accuracy: 0.31 - 0s 142us/sample - loss: 1.7401 - accuracy: 0.2908\n",
      "Epoch 66/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8291 - accuracy: 0.25 - 0s 149us/sample - loss: 1.7214 - accuracy: 0.3050\n",
      "Epoch 67/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7818 - accuracy: 0.21 - 0s 156us/sample - loss: 1.7025 - accuracy: 0.3262\n",
      "Epoch 68/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5413 - accuracy: 0.37 - 0s 149us/sample - loss: 1.6835 - accuracy: 0.3262\n",
      "Epoch 69/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6110 - accuracy: 0.37 - 0s 135us/sample - loss: 1.6644 - accuracy: 0.3262\n",
      "Epoch 70/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5719 - accuracy: 0.34 - 0s 177us/sample - loss: 1.6457 - accuracy: 0.3333\n",
      "Epoch 71/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5278 - accuracy: 0.37 - 0s 149us/sample - loss: 1.6266 - accuracy: 0.3830\n",
      "Epoch 72/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4812 - accuracy: 0.53 - 0s 156us/sample - loss: 1.6080 - accuracy: 0.4043\n",
      "Epoch 73/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5306 - accuracy: 0.34 - 0s 163us/sample - loss: 1.5895 - accuracy: 0.4113\n",
      "Epoch 74/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7945 - accuracy: 0.21 - 0s 149us/sample - loss: 1.5700 - accuracy: 0.4113\n",
      "Epoch 75/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5753 - accuracy: 0.37 - 0s 142us/sample - loss: 1.5511 - accuracy: 0.4184\n",
      "Epoch 76/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5890 - accuracy: 0.40 - 0s 156us/sample - loss: 1.5323 - accuracy: 0.4184\n",
      "Epoch 77/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6376 - accuracy: 0.43 - 0s 142us/sample - loss: 1.5146 - accuracy: 0.4255\n",
      "Epoch 78/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3969 - accuracy: 0.34 - 0s 142us/sample - loss: 1.4951 - accuracy: 0.4397\n",
      "Epoch 79/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4700 - accuracy: 0.50 - 0s 142us/sample - loss: 1.4755 - accuracy: 0.4681\n",
      "Epoch 80/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4087 - accuracy: 0.53 - 0s 142us/sample - loss: 1.4581 - accuracy: 0.5674\n",
      "Epoch 81/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3361 - accuracy: 0.75 - 0s 149us/sample - loss: 1.4396 - accuracy: 0.6099\n",
      "Epoch 82/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5679 - accuracy: 0.50 - 0s 149us/sample - loss: 1.4207 - accuracy: 0.5674\n",
      "Epoch 83/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3957 - accuracy: 0.62 - 0s 156us/sample - loss: 1.4019 - accuracy: 0.6028\n",
      "Epoch 84/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3219 - accuracy: 0.71 - 0s 149us/sample - loss: 1.3837 - accuracy: 0.6383\n",
      "Epoch 85/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3833 - accuracy: 0.62 - 0s 142us/sample - loss: 1.3643 - accuracy: 0.6454\n",
      "Epoch 86/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1454 - accuracy: 0.71 - 0s 156us/sample - loss: 1.3468 - accuracy: 0.6454\n",
      "Epoch 87/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2768 - accuracy: 0.68 - 0s 156us/sample - loss: 1.3285 - accuracy: 0.6596\n",
      "Epoch 88/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2788 - accuracy: 0.65 - 0s 149us/sample - loss: 1.3085 - accuracy: 0.6809\n",
      "Epoch 89/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3106 - accuracy: 0.59 - 0s 149us/sample - loss: 1.2928 - accuracy: 0.6950\n",
      "Epoch 90/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0965 - accuracy: 0.81 - 0s 156us/sample - loss: 1.2742 - accuracy: 0.7021\n",
      "Epoch 91/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2483 - accuracy: 0.75 - 0s 135us/sample - loss: 1.2552 - accuracy: 0.7021\n",
      "Epoch 92/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2263 - accuracy: 0.65 - 0s 149us/sample - loss: 1.2395 - accuracy: 0.6950\n",
      "Epoch 93/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2987 - accuracy: 0.62 - 0s 156us/sample - loss: 1.2218 - accuracy: 0.7021\n",
      "Epoch 94/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1991 - accuracy: 0.78 - 0s 156us/sample - loss: 1.2033 - accuracy: 0.7305\n",
      "Epoch 95/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2613 - accuracy: 0.71 - 0s 163us/sample - loss: 1.1855 - accuracy: 0.7376\n",
      "Epoch 96/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3396 - accuracy: 0.65 - 0s 156us/sample - loss: 1.1689 - accuracy: 0.7305\n",
      "Epoch 97/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2943 - accuracy: 0.71 - 0s 142us/sample - loss: 1.1515 - accuracy: 0.7305\n",
      "Epoch 98/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1599 - accuracy: 0.81 - 0s 149us/sample - loss: 1.1349 - accuracy: 0.7376\n",
      "Epoch 99/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1321 - accuracy: 0.68 - 0s 156us/sample - loss: 1.1183 - accuracy: 0.7376\n",
      "Epoch 100/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0852 - accuracy: 0.71 - 0s 142us/sample - loss: 1.1031 - accuracy: 0.7376\n",
      "Epoch 101/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.9864 - accuracy: 0.78 - 0s 142us/sample - loss: 1.0863 - accuracy: 0.7376\n",
      "Epoch 102/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.9723 - accuracy: 0.75 - 0s 142us/sample - loss: 1.0703 - accuracy: 0.7447\n",
      "Epoch 103/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1236 - accuracy: 0.65 - 0s 149us/sample - loss: 1.0560 - accuracy: 0.7376\n",
      "Epoch 104/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0362 - accuracy: 0.75 - 0s 149us/sample - loss: 1.0400 - accuracy: 0.7376\n",
      "Epoch 105/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.9342 - accuracy: 0.75 - 0s 149us/sample - loss: 1.0246 - accuracy: 0.7376\n",
      "Epoch 106/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1565 - accuracy: 0.59 - 0s 149us/sample - loss: 1.0082 - accuracy: 0.7376\n",
      "Epoch 107/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0990 - accuracy: 0.75 - 0s 149us/sample - loss: 0.9943 - accuracy: 0.7376\n",
      "Epoch 108/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0610 - accuracy: 0.68 - 0s 142us/sample - loss: 0.9788 - accuracy: 0.7376\n",
      "Epoch 109/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.8324 - accuracy: 0.87 - 0s 149us/sample - loss: 0.9646 - accuracy: 0.7376\n",
      "Epoch 110/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.9709 - accuracy: 0.75 - 0s 149us/sample - loss: 0.9504 - accuracy: 0.7447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.9709 - accuracy: 0.71 - 0s 149us/sample - loss: 0.9352 - accuracy: 0.7518\n",
      "Epoch 112/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.9414 - accuracy: 0.81 - 0s 156us/sample - loss: 0.9203 - accuracy: 0.7589\n",
      "Epoch 113/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.81 - 0s 149us/sample - loss: 0.9078 - accuracy: 0.7589\n",
      "Epoch 114/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.8424 - accuracy: 0.87 - 0s 142us/sample - loss: 0.8925 - accuracy: 0.7730\n",
      "Epoch 115/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0463 - accuracy: 0.71 - 0s 135us/sample - loss: 0.8779 - accuracy: 0.7801\n",
      "Epoch 116/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7589 - accuracy: 0.75 - 0s 142us/sample - loss: 0.8632 - accuracy: 0.7801\n",
      "Epoch 117/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7406 - accuracy: 0.84 - 0s 135us/sample - loss: 0.8475 - accuracy: 0.7730\n",
      "Epoch 118/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.84 - 0s 135us/sample - loss: 0.8355 - accuracy: 0.7660\n",
      "Epoch 119/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.87 - 0s 149us/sample - loss: 0.8211 - accuracy: 0.7660\n",
      "Epoch 120/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.8687 - accuracy: 0.65 - 0s 156us/sample - loss: 0.8075 - accuracy: 0.7660\n",
      "Epoch 121/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.71 - 0s 135us/sample - loss: 0.7950 - accuracy: 0.7730\n",
      "Epoch 122/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.8366 - accuracy: 0.71 - 0s 142us/sample - loss: 0.7822 - accuracy: 0.7660\n",
      "Epoch 123/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.8628 - accuracy: 0.62 - 0s 135us/sample - loss: 0.7694 - accuracy: 0.7872\n",
      "Epoch 124/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.81 - 0s 149us/sample - loss: 0.7572 - accuracy: 0.7872\n",
      "Epoch 125/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.8712 - accuracy: 0.62 - 0s 142us/sample - loss: 0.7426 - accuracy: 0.7801\n",
      "Epoch 126/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.81 - 0s 156us/sample - loss: 0.7326 - accuracy: 0.7872\n",
      "Epoch 127/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.81 - 0s 156us/sample - loss: 0.7195 - accuracy: 0.7943\n",
      "Epoch 128/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7252 - accuracy: 0.78 - 0s 142us/sample - loss: 0.7072 - accuracy: 0.8014\n",
      "Epoch 129/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.81 - 0s 135us/sample - loss: 0.6956 - accuracy: 0.8014\n",
      "Epoch 130/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.84 - 0s 156us/sample - loss: 0.6833 - accuracy: 0.8227\n",
      "Epoch 131/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7682 - accuracy: 0.75 - 0s 149us/sample - loss: 0.6740 - accuracy: 0.8227\n",
      "Epoch 132/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.75 - 0s 149us/sample - loss: 0.6600 - accuracy: 0.8298\n",
      "Epoch 133/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.81 - 0s 149us/sample - loss: 0.6482 - accuracy: 0.8298\n",
      "Epoch 134/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.81 - 0s 149us/sample - loss: 0.6388 - accuracy: 0.8227\n",
      "Epoch 135/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.87 - 0s 149us/sample - loss: 0.6265 - accuracy: 0.8369\n",
      "Epoch 136/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.81 - 0s 149us/sample - loss: 0.6177 - accuracy: 0.8440\n",
      "Epoch 137/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6810 - accuracy: 0.81 - 0s 149us/sample - loss: 0.6062 - accuracy: 0.8440\n",
      "Epoch 138/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.84 - 0s 156us/sample - loss: 0.5941 - accuracy: 0.8582\n",
      "Epoch 139/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5609 - accuracy: 0.87 - 0s 142us/sample - loss: 0.5841 - accuracy: 0.8865\n",
      "Epoch 140/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6366 - accuracy: 0.84 - 0s 135us/sample - loss: 0.5745 - accuracy: 0.8582\n",
      "Epoch 141/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.90 - 0s 149us/sample - loss: 0.5626 - accuracy: 0.8582\n",
      "Epoch 142/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6054 - accuracy: 0.78 - 0s 149us/sample - loss: 0.5535 - accuracy: 0.8440\n",
      "Epoch 143/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.90 - 0s 142us/sample - loss: 0.5442 - accuracy: 0.8511\n",
      "Epoch 144/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5129 - accuracy: 0.84 - 0s 149us/sample - loss: 0.5335 - accuracy: 0.8440\n",
      "Epoch 145/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.81 - 0s 149us/sample - loss: 0.5242 - accuracy: 0.8582\n",
      "Epoch 146/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.90 - 0s 142us/sample - loss: 0.5143 - accuracy: 0.8794\n",
      "Epoch 147/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.93 - 0s 149us/sample - loss: 0.5048 - accuracy: 0.9078\n",
      "Epoch 148/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5096 - accuracy: 0.90 - 0s 142us/sample - loss: 0.4954 - accuracy: 0.9007\n",
      "Epoch 149/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.87 - 0s 156us/sample - loss: 0.4873 - accuracy: 0.9078\n",
      "Epoch 150/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.87 - 0s 142us/sample - loss: 0.4775 - accuracy: 0.9007\n",
      "Epoch 151/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.93 - 0s 142us/sample - loss: 0.4697 - accuracy: 0.9007\n",
      "Epoch 152/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.96 - 0s 163us/sample - loss: 0.4595 - accuracy: 0.9220\n",
      "Epoch 153/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.93 - 0s 149us/sample - loss: 0.4495 - accuracy: 0.9149\n",
      "Epoch 154/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.93 - 0s 142us/sample - loss: 0.4408 - accuracy: 0.9149\n",
      "Epoch 155/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 1.00 - 0s 149us/sample - loss: 0.4314 - accuracy: 0.9220\n",
      "Epoch 156/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.90 - 0s 135us/sample - loss: 0.4239 - accuracy: 0.9291\n",
      "Epoch 157/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.93 - 0s 163us/sample - loss: 0.4147 - accuracy: 0.9433\n",
      "Epoch 158/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.96 - 0s 156us/sample - loss: 0.4063 - accuracy: 0.9504\n",
      "Epoch 159/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3696 - accuracy: 0.93 - 0s 142us/sample - loss: 0.3979 - accuracy: 0.9433\n",
      "Epoch 160/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.87 - 0s 149us/sample - loss: 0.3924 - accuracy: 0.9574\n",
      "Epoch 161/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.93 - 0s 156us/sample - loss: 0.3826 - accuracy: 0.9574\n",
      "Epoch 162/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 1.00 - 0s 156us/sample - loss: 0.3739 - accuracy: 0.9574\n",
      "Epoch 163/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.96 - 0s 149us/sample - loss: 0.3682 - accuracy: 0.9504\n",
      "Epoch 164/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.96 - 0s 156us/sample - loss: 0.3594 - accuracy: 0.9574\n",
      "Epoch 165/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.93 - 0s 142us/sample - loss: 0.3522 - accuracy: 0.9574\n",
      "Epoch 166/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4078 - accuracy: 0.90 - 0s 149us/sample - loss: 0.3435 - accuracy: 0.9574\n",
      "Epoch 167/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3128 - accuracy: 0.96 - 0s 142us/sample - loss: 0.3376 - accuracy: 0.9574\n",
      "Epoch 168/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 1.00 - 0s 149us/sample - loss: 0.3287 - accuracy: 0.9574\n",
      "Epoch 169/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 1.00 - 0s 149us/sample - loss: 0.3218 - accuracy: 0.9574\n",
      "Epoch 170/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 1.00 - 0s 142us/sample - loss: 0.3151 - accuracy: 0.9574\n",
      "Epoch 171/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.96 - 0s 156us/sample - loss: 0.3080 - accuracy: 0.9574\n",
      "Epoch 172/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.96 - 0s 142us/sample - loss: 0.3014 - accuracy: 0.9574\n",
      "Epoch 173/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.96 - 0s 135us/sample - loss: 0.2946 - accuracy: 0.9574\n",
      "Epoch 174/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.96 - 0s 149us/sample - loss: 0.2887 - accuracy: 0.9574\n",
      "Epoch 175/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.96 - 0s 156us/sample - loss: 0.2827 - accuracy: 0.9574\n",
      "Epoch 176/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.96 - 0s 142us/sample - loss: 0.2765 - accuracy: 0.9574\n",
      "Epoch 177/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 1.00 - 0s 149us/sample - loss: 0.2718 - accuracy: 0.9574\n",
      "Epoch 178/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.87 - 0s 142us/sample - loss: 0.2653 - accuracy: 0.9574\n",
      "Epoch 179/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 1.00 - 0s 156us/sample - loss: 0.2595 - accuracy: 0.9787\n",
      "Epoch 180/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.96 - 0s 142us/sample - loss: 0.2539 - accuracy: 0.9787\n",
      "Epoch 181/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 1.00 - 0s 142us/sample - loss: 0.2483 - accuracy: 0.9787\n",
      "Epoch 182/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 1.00 - 0s 142us/sample - loss: 0.2438 - accuracy: 0.9645\n",
      "Epoch 183/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 1.00 - 0s 142us/sample - loss: 0.2392 - accuracy: 0.9716\n",
      "Epoch 184/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.93 - 0s 149us/sample - loss: 0.2337 - accuracy: 0.9787\n",
      "Epoch 185/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.93 - 0s 149us/sample - loss: 0.2296 - accuracy: 0.9787\n",
      "Epoch 186/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.96 - 0s 149us/sample - loss: 0.2241 - accuracy: 0.9787\n",
      "Epoch 187/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.96 - 0s 149us/sample - loss: 0.2192 - accuracy: 0.9787\n",
      "Epoch 188/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 1.00 - 0s 149us/sample - loss: 0.2144 - accuracy: 0.9787\n",
      "Epoch 189/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 1.00 - 0s 142us/sample - loss: 0.2102 - accuracy: 0.9787\n",
      "Epoch 190/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 1.00 - 0s 156us/sample - loss: 0.2059 - accuracy: 0.9787\n",
      "Epoch 191/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.96 - 0s 149us/sample - loss: 0.2015 - accuracy: 0.9787\n",
      "Epoch 192/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.96 - 0s 156us/sample - loss: 0.1974 - accuracy: 0.9787\n",
      "Epoch 193/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1934 - accuracy: 0.9858\n",
      "Epoch 194/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1899 - accuracy: 0.9858\n",
      "Epoch 195/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.96 - 0s 142us/sample - loss: 0.1857 - accuracy: 0.9929\n",
      "Epoch 196/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1824 - accuracy: 0.9929\n",
      "Epoch 197/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1787 - accuracy: 0.9929\n",
      "Epoch 198/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 0.96 - 0s 149us/sample - loss: 0.1761 - accuracy: 0.9858\n",
      "Epoch 199/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1257 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1714 - accuracy: 0.9929\n",
      "Epoch 200/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1679 - accuracy: 0.9929\n",
      "Epoch 201/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1647 - accuracy: 0.9929\n",
      "Epoch 202/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.96 - 0s 149us/sample - loss: 0.1619 - accuracy: 0.9929\n",
      "Epoch 203/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 1.00 - 0s 156us/sample - loss: 0.1582 - accuracy: 0.9929\n",
      "Epoch 204/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1547 - accuracy: 0.9929\n",
      "Epoch 205/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1520 - accuracy: 0.9929\n",
      "Epoch 206/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1495 - accuracy: 0.9929\n",
      "Epoch 207/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1459 - accuracy: 0.9929\n",
      "Epoch 208/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1428 - accuracy: 0.9929\n",
      "Epoch 209/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 1.00 - 0s 156us/sample - loss: 0.1400 - accuracy: 0.9929\n",
      "Epoch 210/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1373 - accuracy: 0.9929\n",
      "Epoch 211/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1348 - accuracy: 0.9929\n",
      "Epoch 212/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1321 - accuracy: 0.9929\n",
      "Epoch 213/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1298 - accuracy: 0.9929\n",
      "Epoch 214/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 1.00 - 0s 156us/sample - loss: 0.1275 - accuracy: 0.9929\n",
      "Epoch 215/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1250 - accuracy: 0.9929\n",
      "Epoch 216/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 1.00 - 0s 149us/sample - loss: 0.1224 - accuracy: 0.9929\n",
      "Epoch 217/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1200 - accuracy: 0.9929\n",
      "Epoch 218/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1180 - accuracy: 1.0000\n",
      "Epoch 219/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1160 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 1.00 - 0s 156us/sample - loss: 0.1133 - accuracy: 1.0000\n",
      "Epoch 221/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 1.00 - 0s 156us/sample - loss: 0.1110 - accuracy: 1.0000\n",
      "Epoch 222/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1089 - accuracy: 1.0000\n",
      "Epoch 223/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1066 - accuracy: 1.0000\n",
      "Epoch 224/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1047 - accuracy: 1.0000\n",
      "Epoch 225/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1027 - accuracy: 1.0000\n",
      "Epoch 226/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 1.00 - 0s 142us/sample - loss: 0.1008 - accuracy: 1.0000\n",
      "Epoch 227/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0987 - accuracy: 1.0000\n",
      "Epoch 228/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0970 - accuracy: 1.0000\n",
      "Epoch 229/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0953 - accuracy: 1.0000\n",
      "Epoch 230/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0934 - accuracy: 1.0000\n",
      "Epoch 231/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0918 - accuracy: 1.0000\n",
      "Epoch 232/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0900 - accuracy: 1.0000\n",
      "Epoch 233/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0885 - accuracy: 1.0000\n",
      "Epoch 234/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0868 - accuracy: 1.0000\n",
      "Epoch 235/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0851 - accuracy: 1.0000\n",
      "Epoch 236/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0836 - accuracy: 1.0000\n",
      "Epoch 237/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0820 - accuracy: 1.0000\n",
      "Epoch 238/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0806 - accuracy: 1.0000\n",
      "Epoch 239/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0793 - accuracy: 1.0000\n",
      "Epoch 240/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0779 - accuracy: 1.0000\n",
      "Epoch 241/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0767 - accuracy: 1.0000\n",
      "Epoch 242/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0754 - accuracy: 1.0000\n",
      "Epoch 243/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0737 - accuracy: 1.0000\n",
      "Epoch 244/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0728 - accuracy: 1.0000\n",
      "Epoch 245/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0711 - accuracy: 1.0000\n",
      "Epoch 246/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0700 - accuracy: 1.0000\n",
      "Epoch 247/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0688 - accuracy: 1.0000\n",
      "Epoch 248/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0675 - accuracy: 1.0000\n",
      "Epoch 249/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0665 - accuracy: 1.0000\n",
      "Epoch 250/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0652 - accuracy: 1.0000\n",
      "Epoch 251/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0642 - accuracy: 1.0000\n",
      "Epoch 252/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0633 - accuracy: 1.0000\n",
      "Epoch 253/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0620 - accuracy: 1.0000\n",
      "Epoch 254/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0608 - accuracy: 1.0000\n",
      "Epoch 255/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 256/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0589 - accuracy: 1.0000\n",
      "Epoch 257/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0579 - accuracy: 1.0000\n",
      "Epoch 258/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0570 - accuracy: 1.0000\n",
      "Epoch 259/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0559 - accuracy: 1.0000\n",
      "Epoch 260/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0553 - accuracy: 1.0000\n",
      "Epoch 261/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0541 - accuracy: 1.0000\n",
      "Epoch 262/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0531 - accuracy: 1.0000\n",
      "Epoch 263/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0523 - accuracy: 1.0000\n",
      "Epoch 264/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0514 - accuracy: 1.0000\n",
      "Epoch 265/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0506 - accuracy: 1.0000\n",
      "Epoch 266/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0498 - accuracy: 1.0000\n",
      "Epoch 267/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0490 - accuracy: 1.0000\n",
      "Epoch 268/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 269/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 270/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 199us/sample - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 271/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0460 - accuracy: 1.0000\n",
      "Epoch 272/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 273/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 274/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 275/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0434 - accuracy: 1.0000\n",
      "Epoch 276/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 277/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0421 - accuracy: 1.0000\n",
      "Epoch 278/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0415 - accuracy: 1.0000\n",
      "Epoch 279/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0408 - accuracy: 1.0000\n",
      "Epoch 280/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 281/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0396 - accuracy: 1.0000\n",
      "Epoch 282/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0390 - accuracy: 1.0000\n",
      "Epoch 283/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0385 - accuracy: 1.0000\n",
      "Epoch 284/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 285/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 286/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0368 - accuracy: 1.0000\n",
      "Epoch 287/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 288/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 289/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 290/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 291/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 292/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 293/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 294/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 295/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 296/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 297/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 298/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 299/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 300/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 301/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 302/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 303/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 304/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 305/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 306/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 307/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 308/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 309/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 310/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 311/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 312/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 313/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 314/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 315/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 316/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 317/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 318/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 319/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 320/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 321/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 322/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 323/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 324/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 325/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 326/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 1.00 - 0s 170us/sample - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 327/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 328/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0212 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 330/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 331/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 332/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 333/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 334/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 335/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 336/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 337/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 338/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 339/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 340/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 341/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 342/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 343/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 344/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 345/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 346/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 347/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 348/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 349/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 350/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 351/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 352/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 353/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 354/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 355/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 356/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 357/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 358/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 359/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 360/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 361/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 362/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 363/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 364/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 365/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 366/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 367/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 368/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 369/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 370/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 371/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 372/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 373/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 374/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 375/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 376/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 377/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 378/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 379/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 380/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 381/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 382/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 383/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 384/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 385/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 386/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 387/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 388/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 389/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 390/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 391/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 392/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 393/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 394/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 395/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 396/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 397/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 398/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 399/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 400/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 401/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 402/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 403/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 404/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 405/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 406/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 407/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 408/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 409/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 410/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 411/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 412/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 413/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 414/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 415/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 416/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 417/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 418/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 419/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 420/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 421/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 422/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 423/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 424/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 425/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 426/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 427/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 428/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 429/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 430/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 431/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 432/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 433/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 434/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 435/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 436/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 437/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0074 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 439/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 440/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 441/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 442/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 443/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 444/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 445/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 446/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 447/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 448/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 449/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 450/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 451/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 452/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 453/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 454/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 455/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 456/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 457/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 458/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 459/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 460/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - 0s 160us/sample - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 461/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 462/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 463/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 464/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 465/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 466/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 467/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 468/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 469/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 470/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 471/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 472/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 473/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 474/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 475/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 476/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 477/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 478/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 479/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 480/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 481/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 482/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 483/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 484/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 485/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 486/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 487/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 488/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 489/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 490/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 491/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 492/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 493/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 494/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 184us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 495/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 496/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 497/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 498/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 499/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 500/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 501/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 502/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 503/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 504/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 505/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 506/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 507/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 508/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 509/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 510/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 511/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 512/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 513/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 514/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 515/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 516/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 517/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 518/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 519/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 520/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 521/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 522/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 523/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 524/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 525/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 526/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 527/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 528/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 529/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 530/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 531/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 532/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 533/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 534/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 535/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 536/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 537/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 538/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 539/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 540/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 541/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 542/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 543/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 544/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 545/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 546/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0034 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 548/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 549/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 550/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 551/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 552/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 553/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 554/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 555/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 556/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 557/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 558/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 559/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 560/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 561/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 562/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 563/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 564/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 565/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 566/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 567/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 568/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 569/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 170us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 570/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 571/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 572/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 573/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 574/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 575/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 576/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 577/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 578/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 579/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 580/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 581/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 582/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 583/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 584/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 585/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 586/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 587/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 588/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 589/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 590/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 591/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 592/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 593/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 594/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 595/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 596/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 597/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 598/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 599/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 170us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 600/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 601/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 602/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 603/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 604/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 605/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 606/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 607/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 608/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 609/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 610/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 611/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 612/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 613/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 614/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 615/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 616/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 617/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 618/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 619/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 620/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 621/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 622/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 623/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 624/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 625/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 626/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 627/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 628/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 629/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 630/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 631/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 632/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 633/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 634/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 635/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 636/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 637/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 638/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 639/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 640/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 641/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 642/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 643/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 644/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 645/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 646/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 647/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 648/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 649/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 650/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 651/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 652/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 653/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 654/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 655/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0019 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 657/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 658/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 659/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 660/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 661/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 662/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 663/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 664/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 665/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 666/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 667/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 668/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 669/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 670/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 671/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 672/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 673/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 674/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 675/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 676/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 677/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 678/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 679/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 680/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 199us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 681/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 682/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 683/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 684/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 685/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 686/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 687/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 688/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 689/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 690/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 691/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 692/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 693/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 694/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.6647e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 695/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.8439e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 696/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 697/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 698/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 699/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 700/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 701/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 702/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 703/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 704/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 705/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 706/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 707/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 708/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 709/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 710/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 711/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 712/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.0357e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 713/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 714/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 715/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 716/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 717/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 718/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 719/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 720/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 721/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 722/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 723/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 724/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 725/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 726/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 727/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 728/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3816e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 729/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 730/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 731/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 732/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 733/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 734/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 735/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 736/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 737/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2537e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 738/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3997e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 739/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 740/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2971e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 741/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 742/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 743/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 744/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 745/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 746/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 747/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2770e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 748/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 749/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 750/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 751/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 752/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 753/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 754/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.7243e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 755/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 756/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 757/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 758/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 759/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 760/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 761/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.7723e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 762/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 763/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 764/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 765/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 766/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 767/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5738e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 768/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 769/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 770/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 771/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 772/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 206us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 773/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 774/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2352e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 775/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.4533e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 776/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.1428e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 777/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.5353e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 778/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3090e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 779/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.9201e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 780/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 781/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.5562e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 782/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 149us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 783/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.9424e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 784/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 156us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 785/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.9990e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 786/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 787/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8829e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 9.9683e-04 - accuracy: 1.0000\n",
      "Epoch 788/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.9757e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.9242e-04 - accuracy: 1.0000\n",
      "Epoch 789/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4711e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 9.8765e-04 - accuracy: 1.0000\n",
      "Epoch 790/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.7550e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.8362e-04 - accuracy: 1.0000\n",
      "Epoch 791/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 149us/sample - loss: 9.7885e-04 - accuracy: 1.0000\n",
      "Epoch 792/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2119e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 9.7415e-04 - accuracy: 1.0000\n",
      "Epoch 793/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2452e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 9.6965e-04 - accuracy: 1.0000\n",
      "Epoch 794/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.8964e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 9.6578e-04 - accuracy: 1.0000\n",
      "Epoch 795/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.7630e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 9.6139e-04 - accuracy: 1.0000\n",
      "Epoch 796/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.8746e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.5711e-04 - accuracy: 1.0000\n",
      "Epoch 797/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.7040e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 9.5298e-04 - accuracy: 1.0000\n",
      "Epoch 798/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.4752e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.4926e-04 - accuracy: 1.0000\n",
      "Epoch 799/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.8101e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.4540e-04 - accuracy: 1.0000\n",
      "Epoch 800/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 149us/sample - loss: 9.4101e-04 - accuracy: 1.0000\n",
      "Epoch 801/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 163us/sample - loss: 9.3665e-04 - accuracy: 1.0000\n",
      "Epoch 802/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2908e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 9.3240e-04 - accuracy: 1.0000\n",
      "Epoch 803/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 149us/sample - loss: 9.2884e-04 - accuracy: 1.0000\n",
      "Epoch 804/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.6984e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 9.2489e-04 - accuracy: 1.0000\n",
      "Epoch 805/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.3331e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 9.2071e-04 - accuracy: 1.0000\n",
      "Epoch 806/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4069e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 9.1658e-04 - accuracy: 1.0000\n",
      "Epoch 807/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8956e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 9.1251e-04 - accuracy: 1.0000\n",
      "Epoch 808/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 142us/sample - loss: 9.0824e-04 - accuracy: 1.0000\n",
      "Epoch 809/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3372e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 9.0485e-04 - accuracy: 1.0000\n",
      "Epoch 810/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.2447e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 9.0058e-04 - accuracy: 1.0000\n",
      "Epoch 811/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5538e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 8.9743e-04 - accuracy: 1.0000\n",
      "Epoch 812/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.4847e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 8.9331e-04 - accuracy: 1.0000\n",
      "Epoch 813/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 156us/sample - loss: 8.8964e-04 - accuracy: 1.0000\n",
      "Epoch 814/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7707e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 8.8549e-04 - accuracy: 1.0000\n",
      "Epoch 815/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.8828e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 8.8224e-04 - accuracy: 1.0000\n",
      "Epoch 816/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 142us/sample - loss: 8.7778e-04 - accuracy: 1.0000\n",
      "Epoch 817/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2200e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 8.7423e-04 - accuracy: 1.0000\n",
      "Epoch 818/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 156us/sample - loss: 8.7043e-04 - accuracy: 1.0000\n",
      "Epoch 819/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 135us/sample - loss: 8.6710e-04 - accuracy: 1.0000\n",
      "Epoch 820/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.6203e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 8.6284e-04 - accuracy: 1.0000\n",
      "Epoch 821/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.0814e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 8.5941e-04 - accuracy: 1.0000\n",
      "Epoch 822/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 149us/sample - loss: 8.5586e-04 - accuracy: 1.0000\n",
      "Epoch 823/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 142us/sample - loss: 8.5179e-04 - accuracy: 1.0000\n",
      "Epoch 824/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 142us/sample - loss: 8.4865e-04 - accuracy: 1.0000\n",
      "Epoch 825/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8558e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 8.4466e-04 - accuracy: 1.0000\n",
      "Epoch 826/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.5302e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 8.4133e-04 - accuracy: 1.0000\n",
      "Epoch 827/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7398e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 8.3746e-04 - accuracy: 1.0000\n",
      "Epoch 828/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2425e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 8.3439e-04 - accuracy: 1.0000\n",
      "Epoch 829/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 149us/sample - loss: 8.3089e-04 - accuracy: 1.0000\n",
      "Epoch 830/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.0257e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 8.2700e-04 - accuracy: 1.0000\n",
      "Epoch 831/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.7787e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 8.2432e-04 - accuracy: 1.0000\n",
      "Epoch 832/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 142us/sample - loss: 8.2127e-04 - accuracy: 1.0000\n",
      "Epoch 833/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 142us/sample - loss: 8.1712e-04 - accuracy: 1.0000\n",
      "Epoch 834/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.9712e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 8.1364e-04 - accuracy: 1.0000\n",
      "Epoch 835/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.3929e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 8.0972e-04 - accuracy: 1.0000\n",
      "Epoch 836/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.7109e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 8.0698e-04 - accuracy: 1.0000\n",
      "Epoch 837/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2645e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 8.0338e-04 - accuracy: 1.0000\n",
      "Epoch 838/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2784e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.9993e-04 - accuracy: 1.0000\n",
      "Epoch 839/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7006e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 7.9590e-04 - accuracy: 1.0000\n",
      "Epoch 840/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5284e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 7.9216e-04 - accuracy: 1.0000\n",
      "Epoch 841/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.6642e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.9057e-04 - accuracy: 1.0000\n",
      "Epoch 842/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.4120e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.8783e-04 - accuracy: 1.0000\n",
      "Epoch 843/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7648e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.8337e-04 - accuracy: 1.0000\n",
      "Epoch 844/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.8072e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 7.7987e-04 - accuracy: 1.0000\n",
      "Epoch 845/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.6845e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.7582e-04 - accuracy: 1.0000\n",
      "Epoch 846/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.4045e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 7.7267e-04 - accuracy: 1.0000\n",
      "Epoch 847/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7318e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 7.6989e-04 - accuracy: 1.0000\n",
      "Epoch 848/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.4987e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.6702e-04 - accuracy: 1.0000\n",
      "Epoch 849/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.3298e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 7.6334e-04 - accuracy: 1.0000\n",
      "Epoch 850/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.0148e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.6025e-04 - accuracy: 1.0000\n",
      "Epoch 851/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.6159e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.5690e-04 - accuracy: 1.0000\n",
      "Epoch 852/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.9346e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 7.5363e-04 - accuracy: 1.0000\n",
      "Epoch 853/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0880e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 7.5039e-04 - accuracy: 1.0000\n",
      "Epoch 854/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.6836e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 7.4783e-04 - accuracy: 1.0000\n",
      "Epoch 855/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5142e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.4476e-04 - accuracy: 1.0000\n",
      "Epoch 856/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1981e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.4104e-04 - accuracy: 1.0000\n",
      "Epoch 857/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8572e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 7.3822e-04 - accuracy: 1.0000\n",
      "Epoch 858/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.6059e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 7.3563e-04 - accuracy: 1.0000\n",
      "Epoch 859/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6077e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.3236e-04 - accuracy: 1.0000\n",
      "Epoch 860/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5055e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 7.2990e-04 - accuracy: 1.0000\n",
      "Epoch 861/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.4388e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 7.2653e-04 - accuracy: 1.0000\n",
      "Epoch 862/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.1054e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.2335e-04 - accuracy: 1.0000\n",
      "Epoch 863/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.4291e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.2032e-04 - accuracy: 1.0000\n",
      "Epoch 864/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2706e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 7.1772e-04 - accuracy: 1.0000\n",
      "Epoch 865/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1806e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 7.1438e-04 - accuracy: 1.0000\n",
      "Epoch 866/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8202e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 7.1067e-04 - accuracy: 1.0000\n",
      "Epoch 867/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4427e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 7.0746e-04 - accuracy: 1.0000\n",
      "Epoch 868/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 149us/sample - loss: 7.0547e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 869/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9392e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 7.0209e-04 - accuracy: 1.0000\n",
      "Epoch 870/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7381e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.9914e-04 - accuracy: 1.0000\n",
      "Epoch 871/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2421e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.9651e-04 - accuracy: 1.0000\n",
      "Epoch 872/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0271e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.9341e-04 - accuracy: 1.0000\n",
      "Epoch 873/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6675e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.9049e-04 - accuracy: 1.0000\n",
      "Epoch 874/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.3647e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.8821e-04 - accuracy: 1.0000\n",
      "Epoch 875/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5599e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.8509e-04 - accuracy: 1.0000\n",
      "Epoch 876/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1072e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.8291e-04 - accuracy: 1.0000\n",
      "Epoch 877/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5681e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.7963e-04 - accuracy: 1.0000\n",
      "Epoch 878/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.3307e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.7692e-04 - accuracy: 1.0000\n",
      "Epoch 879/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0522e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.7375e-04 - accuracy: 1.0000\n",
      "Epoch 880/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5035e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.7125e-04 - accuracy: 1.0000\n",
      "Epoch 881/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.8662e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.6852e-04 - accuracy: 1.0000\n",
      "Epoch 882/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.3575e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.6523e-04 - accuracy: 1.0000\n",
      "Epoch 883/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0775e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 6.6245e-04 - accuracy: 1.0000\n",
      "Epoch 884/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3303e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.5969e-04 - accuracy: 1.0000\n",
      "Epoch 885/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.0049e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 6.5716e-04 - accuracy: 1.0000\n",
      "Epoch 886/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.1604e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 6.5439e-04 - accuracy: 1.0000\n",
      "Epoch 887/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.3206e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.5153e-04 - accuracy: 1.0000\n",
      "Epoch 888/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.0501e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.4902e-04 - accuracy: 1.0000\n",
      "Epoch 889/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9049e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 6.4653e-04 - accuracy: 1.0000\n",
      "Epoch 890/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.2748e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.4394e-04 - accuracy: 1.0000\n",
      "Epoch 891/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0653e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 6.4132e-04 - accuracy: 1.0000\n",
      "Epoch 892/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9217e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.3882e-04 - accuracy: 1.0000\n",
      "Epoch 893/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.1240e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.3673e-04 - accuracy: 1.0000\n",
      "Epoch 894/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.9994e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 6.3431e-04 - accuracy: 1.0000\n",
      "Epoch 895/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5760e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 6.3151e-04 - accuracy: 1.0000\n",
      "Epoch 896/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1727e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 6.2884e-04 - accuracy: 1.0000\n",
      "Epoch 897/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.3339e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.2607e-04 - accuracy: 1.0000\n",
      "Epoch 898/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1870e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 6.2376e-04 - accuracy: 1.0000\n",
      "Epoch 899/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.3443e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.2079e-04 - accuracy: 1.0000\n",
      "Epoch 900/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8566e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.1863e-04 - accuracy: 1.0000\n",
      "Epoch 901/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5985e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 6.1592e-04 - accuracy: 1.0000\n",
      "Epoch 902/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2811e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.1386e-04 - accuracy: 1.0000\n",
      "Epoch 903/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0097e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.1145e-04 - accuracy: 1.0000\n",
      "Epoch 904/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1236e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 6.0852e-04 - accuracy: 1.0000\n",
      "Epoch 905/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.1044e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 6.0598e-04 - accuracy: 1.0000\n",
      "Epoch 906/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7675e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.0385e-04 - accuracy: 1.0000\n",
      "Epoch 907/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4399e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 6.0114e-04 - accuracy: 1.0000\n",
      "Epoch 908/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.7170e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.9858e-04 - accuracy: 1.0000\n",
      "Epoch 909/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7684e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.9604e-04 - accuracy: 1.0000\n",
      "Epoch 910/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4800e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.9378e-04 - accuracy: 1.0000\n",
      "Epoch 911/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.6075e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 5.9134e-04 - accuracy: 1.0000\n",
      "Epoch 912/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8607e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 5.8985e-04 - accuracy: 1.0000\n",
      "Epoch 913/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.3259e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.8694e-04 - accuracy: 1.0000\n",
      "Epoch 914/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3444e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.8481e-04 - accuracy: 1.0000\n",
      "Epoch 915/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8321e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.8221e-04 - accuracy: 1.0000\n",
      "Epoch 916/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0123e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 5.7984e-04 - accuracy: 1.0000\n",
      "Epoch 917/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4484e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.7742e-04 - accuracy: 1.0000\n",
      "Epoch 918/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2417e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.7513e-04 - accuracy: 1.0000\n",
      "Epoch 919/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0165e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.7266e-04 - accuracy: 1.0000\n",
      "Epoch 920/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.0243e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.7027e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4087e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.6853e-04 - accuracy: 1.0000\n",
      "Epoch 922/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0150e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 5.6634e-04 - accuracy: 1.0000\n",
      "Epoch 923/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5608e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.6382e-04 - accuracy: 1.0000\n",
      "Epoch 924/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8214e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.6171e-04 - accuracy: 1.0000\n",
      "Epoch 925/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4878e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.5945e-04 - accuracy: 1.0000\n",
      "Epoch 926/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8327e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.5724e-04 - accuracy: 1.0000\n",
      "Epoch 927/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0598e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.5487e-04 - accuracy: 1.0000\n",
      "Epoch 928/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.9712e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.5279e-04 - accuracy: 1.0000\n",
      "Epoch 929/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.0548e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.5058e-04 - accuracy: 1.0000\n",
      "Epoch 930/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2829e-04 - accuracy: 1.00 - 0s 185us/sample - loss: 5.4823e-04 - accuracy: 1.0000\n",
      "Epoch 931/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1330e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 5.4611e-04 - accuracy: 1.0000\n",
      "Epoch 932/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5461e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.4394e-04 - accuracy: 1.0000\n",
      "Epoch 933/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7328e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.4182e-04 - accuracy: 1.0000\n",
      "Epoch 934/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6808e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.3985e-04 - accuracy: 1.0000\n",
      "Epoch 935/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6269e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.3791e-04 - accuracy: 1.0000\n",
      "Epoch 936/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7375e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.3562e-04 - accuracy: 1.0000\n",
      "Epoch 937/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1030e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 5.3349e-04 - accuracy: 1.0000\n",
      "Epoch 938/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6955e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.3160e-04 - accuracy: 1.0000\n",
      "Epoch 939/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8896e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.2961e-04 - accuracy: 1.0000\n",
      "Epoch 940/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1680e-04 - accuracy: 1.00 - 0s 369us/sample - loss: 5.2739e-04 - accuracy: 1.0000\n",
      "Epoch 941/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1212e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.2569e-04 - accuracy: 1.0000\n",
      "Epoch 942/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.6742e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.2352e-04 - accuracy: 1.0000\n",
      "Epoch 943/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5723e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.2114e-04 - accuracy: 1.0000\n",
      "Epoch 944/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9596e-04 - accuracy: 1.00 - 0s 128us/sample - loss: 5.1909e-04 - accuracy: 1.0000\n",
      "Epoch 945/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7342e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.1762e-04 - accuracy: 1.0000\n",
      "Epoch 946/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1877e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.1521e-04 - accuracy: 1.0000\n",
      "Epoch 947/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5740e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 5.1346e-04 - accuracy: 1.0000\n",
      "Epoch 948/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8748e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 5.1128e-04 - accuracy: 1.0000\n",
      "Epoch 949/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2923e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 5.0936e-04 - accuracy: 1.0000\n",
      "Epoch 950/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2743e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.0717e-04 - accuracy: 1.0000\n",
      "Epoch 951/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4908e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 5.0525e-04 - accuracy: 1.0000\n",
      "Epoch 952/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.5119e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.0395e-04 - accuracy: 1.0000\n",
      "Epoch 953/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.0004e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 5.0138e-04 - accuracy: 1.0000\n",
      "Epoch 954/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9018e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 4.9939e-04 - accuracy: 1.0000\n",
      "Epoch 955/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9980e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.9769e-04 - accuracy: 1.0000\n",
      "Epoch 956/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8281e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.9570e-04 - accuracy: 1.0000\n",
      "Epoch 957/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4951e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.9381e-04 - accuracy: 1.0000\n",
      "Epoch 958/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0768e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.9209e-04 - accuracy: 1.0000\n",
      "Epoch 959/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1899e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.9023e-04 - accuracy: 1.0000\n",
      "Epoch 960/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1446e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.8854e-04 - accuracy: 1.0000\n",
      "Epoch 961/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0442e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.8717e-04 - accuracy: 1.0000\n",
      "Epoch 962/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7657e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 4.8443e-04 - accuracy: 1.0000\n",
      "Epoch 963/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7398e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.8270e-04 - accuracy: 1.0000\n",
      "Epoch 964/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2911e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 4.8090e-04 - accuracy: 1.0000\n",
      "Epoch 965/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0273e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.7911e-04 - accuracy: 1.0000\n",
      "Epoch 966/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2712e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.7721e-04 - accuracy: 1.0000\n",
      "Epoch 967/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1631e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.7535e-04 - accuracy: 1.0000\n",
      "Epoch 968/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6900e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.7404e-04 - accuracy: 1.0000\n",
      "Epoch 969/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6371e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.7216e-04 - accuracy: 1.0000\n",
      "Epoch 970/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2464e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.7062e-04 - accuracy: 1.0000\n",
      "Epoch 971/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.6472e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.6874e-04 - accuracy: 1.0000\n",
      "Epoch 972/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8708e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.6659e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7289e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.6447e-04 - accuracy: 1.0000\n",
      "Epoch 974/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1383e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 4.6286e-04 - accuracy: 1.0000\n",
      "Epoch 975/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7664e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.6116e-04 - accuracy: 1.0000\n",
      "Epoch 976/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.3952e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 4.5964e-04 - accuracy: 1.0000\n",
      "Epoch 977/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.2427e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.5795e-04 - accuracy: 1.0000\n",
      "Epoch 978/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2039e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.5582e-04 - accuracy: 1.0000\n",
      "Epoch 979/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5315e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.5450e-04 - accuracy: 1.0000\n",
      "Epoch 980/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4752e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.5259e-04 - accuracy: 1.0000\n",
      "Epoch 981/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8196e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.5093e-04 - accuracy: 1.0000\n",
      "Epoch 982/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6289e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.4922e-04 - accuracy: 1.0000\n",
      "Epoch 983/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4377e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.4774e-04 - accuracy: 1.0000\n",
      "Epoch 984/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5212e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 4.4577e-04 - accuracy: 1.0000\n",
      "Epoch 985/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9204e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.4423e-04 - accuracy: 1.0000\n",
      "Epoch 986/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2384e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 4.4227e-04 - accuracy: 1.0000\n",
      "Epoch 987/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7387e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.4095e-04 - accuracy: 1.0000\n",
      "Epoch 988/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0968e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.3923e-04 - accuracy: 1.0000\n",
      "Epoch 989/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.3303e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 4.3784e-04 - accuracy: 1.0000\n",
      "Epoch 990/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9516e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.3590e-04 - accuracy: 1.0000\n",
      "Epoch 991/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7137e-04 - accuracy: 1.00 - 0s 213us/sample - loss: 4.3410e-04 - accuracy: 1.0000\n",
      "Epoch 992/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7965e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.3252e-04 - accuracy: 1.0000\n",
      "Epoch 993/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3277e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.3092e-04 - accuracy: 1.0000\n",
      "Epoch 994/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.4572e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 4.2909e-04 - accuracy: 1.0000\n",
      "Epoch 995/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3139e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.2746e-04 - accuracy: 1.0000\n",
      "Epoch 996/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6797e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.2582e-04 - accuracy: 1.0000\n",
      "Epoch 997/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4690e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.2432e-04 - accuracy: 1.0000\n",
      "Epoch 998/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9855e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.2255e-04 - accuracy: 1.0000\n",
      "Epoch 999/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0786e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 4.2111e-04 - accuracy: 1.0000\n",
      "Epoch 1000/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.7416e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.1929e-04 - accuracy: 1.0000\n",
      "Epoch 1001/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3361e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.1772e-04 - accuracy: 1.0000\n",
      "Epoch 1002/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0373e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.1626e-04 - accuracy: 1.0000\n",
      "Epoch 1003/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0558e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.1469e-04 - accuracy: 1.0000\n",
      "Epoch 1004/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4897e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.1324e-04 - accuracy: 1.0000\n",
      "Epoch 1005/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2625e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.1166e-04 - accuracy: 1.0000\n",
      "Epoch 1006/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3722e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 4.0972e-04 - accuracy: 1.0000\n",
      "Epoch 1007/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0617e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.0834e-04 - accuracy: 1.0000\n",
      "Epoch 1008/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6867e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.0697e-04 - accuracy: 1.0000\n",
      "Epoch 1009/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4048e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 4.0521e-04 - accuracy: 1.0000\n",
      "Epoch 1010/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4697e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.0379e-04 - accuracy: 1.0000\n",
      "Epoch 1011/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7089e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 4.0236e-04 - accuracy: 1.0000\n",
      "Epoch 1012/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2668e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 4.0070e-04 - accuracy: 1.0000\n",
      "Epoch 1013/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8813e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.9907e-04 - accuracy: 1.0000\n",
      "Epoch 1014/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6355e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.9763e-04 - accuracy: 1.0000\n",
      "Epoch 1015/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6797e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.9580e-04 - accuracy: 1.0000\n",
      "Epoch 1016/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5546e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.9436e-04 - accuracy: 1.0000\n",
      "Epoch 1017/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8028e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.9288e-04 - accuracy: 1.0000\n",
      "Epoch 1018/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.3136e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.9146e-04 - accuracy: 1.0000\n",
      "Epoch 1019/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1969e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.9003e-04 - accuracy: 1.0000\n",
      "Epoch 1020/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8959e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.8878e-04 - accuracy: 1.0000\n",
      "Epoch 1021/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3119e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.8712e-04 - accuracy: 1.0000\n",
      "Epoch 1022/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5255e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.8564e-04 - accuracy: 1.0000\n",
      "Epoch 1023/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6861e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.8452e-04 - accuracy: 1.0000\n",
      "Epoch 1024/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5983e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.8298e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1025/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9685e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.8150e-04 - accuracy: 1.0000\n",
      "Epoch 1026/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0746e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.8012e-04 - accuracy: 1.0000\n",
      "Epoch 1027/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6439e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.7903e-04 - accuracy: 1.0000\n",
      "Epoch 1028/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0959e-04 - accuracy: 1.00 - 0s 128us/sample - loss: 3.7754e-04 - accuracy: 1.0000\n",
      "Epoch 1029/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3498e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.7588e-04 - accuracy: 1.0000\n",
      "Epoch 1030/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2412e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.7440e-04 - accuracy: 1.0000\n",
      "Epoch 1031/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6701e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.7320e-04 - accuracy: 1.0000\n",
      "Epoch 1032/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6871e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.7181e-04 - accuracy: 1.0000\n",
      "Epoch 1033/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4774e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.7055e-04 - accuracy: 1.0000\n",
      "Epoch 1034/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6112e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.6911e-04 - accuracy: 1.0000\n",
      "Epoch 1035/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0405e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.6782e-04 - accuracy: 1.0000\n",
      "Epoch 1036/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0809e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.6645e-04 - accuracy: 1.0000\n",
      "Epoch 1037/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2504e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.6507e-04 - accuracy: 1.0000\n",
      "Epoch 1038/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8656e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.6379e-04 - accuracy: 1.0000\n",
      "Epoch 1039/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5377e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.6238e-04 - accuracy: 1.0000\n",
      "Epoch 1040/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2027e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.6113e-04 - accuracy: 1.0000\n",
      "Epoch 1041/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6520e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.5959e-04 - accuracy: 1.0000\n",
      "Epoch 1042/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3993e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.5833e-04 - accuracy: 1.0000\n",
      "Epoch 1043/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4837e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.5671e-04 - accuracy: 1.0000\n",
      "Epoch 1044/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4685e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.5558e-04 - accuracy: 1.0000\n",
      "Epoch 1045/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6861e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.5429e-04 - accuracy: 1.0000\n",
      "Epoch 1046/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0683e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.5301e-04 - accuracy: 1.0000\n",
      "Epoch 1047/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5559e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.5162e-04 - accuracy: 1.0000\n",
      "Epoch 1048/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0487e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.5043e-04 - accuracy: 1.0000\n",
      "Epoch 1049/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9897e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.4911e-04 - accuracy: 1.0000\n",
      "Epoch 1050/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3415e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.4774e-04 - accuracy: 1.0000\n",
      "Epoch 1051/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3920e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.4673e-04 - accuracy: 1.0000\n",
      "Epoch 1052/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9000e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.4529e-04 - accuracy: 1.0000\n",
      "Epoch 1053/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5934e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.4419e-04 - accuracy: 1.0000\n",
      "Epoch 1054/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1371e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.4274e-04 - accuracy: 1.0000\n",
      "Epoch 1055/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3249e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.4150e-04 - accuracy: 1.0000\n",
      "Epoch 1056/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1431e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.4012e-04 - accuracy: 1.0000\n",
      "Epoch 1057/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1428e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.3897e-04 - accuracy: 1.0000\n",
      "Epoch 1058/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1591e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.3765e-04 - accuracy: 1.0000\n",
      "Epoch 1059/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3761e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.3659e-04 - accuracy: 1.0000\n",
      "Epoch 1060/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7680e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.3533e-04 - accuracy: 1.0000\n",
      "Epoch 1061/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3578e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.3406e-04 - accuracy: 1.0000\n",
      "Epoch 1062/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4563e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.3281e-04 - accuracy: 1.0000\n",
      "Epoch 1063/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9467e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.3173e-04 - accuracy: 1.0000\n",
      "Epoch 1064/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8939e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.3065e-04 - accuracy: 1.0000\n",
      "Epoch 1065/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8834e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.2932e-04 - accuracy: 1.0000\n",
      "Epoch 1066/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0079e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.2806e-04 - accuracy: 1.0000\n",
      "Epoch 1067/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4615e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.2687e-04 - accuracy: 1.0000\n",
      "Epoch 1068/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9343e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.2565e-04 - accuracy: 1.0000\n",
      "Epoch 1069/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9087e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.2450e-04 - accuracy: 1.0000\n",
      "Epoch 1070/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.7487e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.2354e-04 - accuracy: 1.0000\n",
      "Epoch 1071/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6285e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.2252e-04 - accuracy: 1.0000\n",
      "Epoch 1072/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3337e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.2113e-04 - accuracy: 1.0000\n",
      "Epoch 1073/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7654e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.2006e-04 - accuracy: 1.0000\n",
      "Epoch 1074/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6526e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.1882e-04 - accuracy: 1.0000\n",
      "Epoch 1075/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2219e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.1760e-04 - accuracy: 1.0000\n",
      "Epoch 1076/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0052e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.1645e-04 - accuracy: 1.0000\n",
      "Epoch 1077/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0796e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.1537e-04 - accuracy: 1.0000\n",
      "Epoch 1078/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2247e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.1407e-04 - accuracy: 1.0000\n",
      "Epoch 1079/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0741e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.1307e-04 - accuracy: 1.0000\n",
      "Epoch 1080/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0341e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.1197e-04 - accuracy: 1.0000\n",
      "Epoch 1081/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4134e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.1089e-04 - accuracy: 1.0000\n",
      "Epoch 1082/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9187e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.0985e-04 - accuracy: 1.0000\n",
      "Epoch 1083/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6310e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.0853e-04 - accuracy: 1.0000\n",
      "Epoch 1084/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7526e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.0746e-04 - accuracy: 1.0000\n",
      "Epoch 1085/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2713e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 3.0639e-04 - accuracy: 1.0000\n",
      "Epoch 1086/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4410e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.0553e-04 - accuracy: 1.0000\n",
      "Epoch 1087/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.7906e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.0441e-04 - accuracy: 1.0000\n",
      "Epoch 1088/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8823e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.0322e-04 - accuracy: 1.0000\n",
      "Epoch 1089/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5672e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.0196e-04 - accuracy: 1.0000\n",
      "Epoch 1090/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2619e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 3.0078e-04 - accuracy: 1.0000\n",
      "Epoch 1091/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4157e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.9983e-04 - accuracy: 1.0000\n",
      "Epoch 1092/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7778e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.9877e-04 - accuracy: 1.0000\n",
      "Epoch 1093/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3281e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.9778e-04 - accuracy: 1.0000\n",
      "Epoch 1094/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2872e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.9644e-04 - accuracy: 1.0000\n",
      "Epoch 1095/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4571e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.9525e-04 - accuracy: 1.0000\n",
      "Epoch 1096/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3563e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.9439e-04 - accuracy: 1.0000\n",
      "Epoch 1097/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9988e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.9326e-04 - accuracy: 1.0000\n",
      "Epoch 1098/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9855e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.9209e-04 - accuracy: 1.0000\n",
      "Epoch 1099/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9634e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 2.9112e-04 - accuracy: 1.0000\n",
      "Epoch 1100/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2304e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.9003e-04 - accuracy: 1.0000\n",
      "Epoch 1101/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6272e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8894e-04 - accuracy: 1.0000\n",
      "Epoch 1102/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0969e-04 - accuracy: 1.00 - 0s 184us/sample - loss: 2.8796e-04 - accuracy: 1.0000\n",
      "Epoch 1103/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1629e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.8690e-04 - accuracy: 1.0000\n",
      "Epoch 1104/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0115e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.8585e-04 - accuracy: 1.0000\n",
      "Epoch 1105/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0879e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.8478e-04 - accuracy: 1.0000\n",
      "Epoch 1106/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2641e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.8369e-04 - accuracy: 1.0000\n",
      "Epoch 1107/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5366e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.8265e-04 - accuracy: 1.0000\n",
      "Epoch 1108/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6350e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.8171e-04 - accuracy: 1.0000\n",
      "Epoch 1109/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3833e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.8060e-04 - accuracy: 1.0000\n",
      "Epoch 1110/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7032e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.7979e-04 - accuracy: 1.0000\n",
      "Epoch 1111/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4927e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.7881e-04 - accuracy: 1.0000\n",
      "Epoch 1112/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1835e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.7791e-04 - accuracy: 1.0000\n",
      "Epoch 1113/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9129e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.7674e-04 - accuracy: 1.0000\n",
      "Epoch 1114/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4568e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.7581e-04 - accuracy: 1.0000\n",
      "Epoch 1115/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4628e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.7486e-04 - accuracy: 1.0000\n",
      "Epoch 1116/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2738e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.7400e-04 - accuracy: 1.0000\n",
      "Epoch 1117/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7400e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.7297e-04 - accuracy: 1.0000\n",
      "Epoch 1118/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7704e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.7198e-04 - accuracy: 1.0000\n",
      "Epoch 1119/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8598e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.7098e-04 - accuracy: 1.0000\n",
      "Epoch 1120/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0529e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.7019e-04 - accuracy: 1.0000\n",
      "Epoch 1121/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5828e-04 - accuracy: 1.00 - 0s 199us/sample - loss: 2.6919e-04 - accuracy: 1.0000\n",
      "Epoch 1122/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5956e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.6838e-04 - accuracy: 1.0000\n",
      "Epoch 1123/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4392e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.6723e-04 - accuracy: 1.0000\n",
      "Epoch 1124/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5862e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.6660e-04 - accuracy: 1.0000\n",
      "Epoch 1125/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5539e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.6573e-04 - accuracy: 1.0000\n",
      "Epoch 1126/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4806e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.6434e-04 - accuracy: 1.0000\n",
      "Epoch 1127/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 3.1535e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.6351e-04 - accuracy: 1.0000\n",
      "Epoch 1128/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4451e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.6251e-04 - accuracy: 1.0000\n",
      "Epoch 1129/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2825e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.6165e-04 - accuracy: 1.0000\n",
      "Epoch 1130/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1180e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.6062e-04 - accuracy: 1.0000\n",
      "Epoch 1131/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6102e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.5973e-04 - accuracy: 1.0000\n",
      "Epoch 1132/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6601e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.5874e-04 - accuracy: 1.0000\n",
      "Epoch 1133/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5141e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.5792e-04 - accuracy: 1.0000\n",
      "Epoch 1134/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0963e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.5705e-04 - accuracy: 1.0000\n",
      "Epoch 1135/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0778e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.5625e-04 - accuracy: 1.0000\n",
      "Epoch 1136/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0434e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.5532e-04 - accuracy: 1.0000\n",
      "Epoch 1137/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8224e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.5427e-04 - accuracy: 1.0000\n",
      "Epoch 1138/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8015e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.5347e-04 - accuracy: 1.0000\n",
      "Epoch 1139/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9346e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 2.5251e-04 - accuracy: 1.0000\n",
      "Epoch 1140/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3771e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.5150e-04 - accuracy: 1.0000\n",
      "Epoch 1141/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6096e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.5066e-04 - accuracy: 1.0000\n",
      "Epoch 1142/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0100e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.4991e-04 - accuracy: 1.0000\n",
      "Epoch 1143/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1815e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.4917e-04 - accuracy: 1.0000\n",
      "Epoch 1144/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2725e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.4812e-04 - accuracy: 1.0000\n",
      "Epoch 1145/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6656e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.4717e-04 - accuracy: 1.0000\n",
      "Epoch 1146/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2051e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.4620e-04 - accuracy: 1.0000\n",
      "Epoch 1147/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2433e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.4555e-04 - accuracy: 1.0000\n",
      "Epoch 1148/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7335e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.4450e-04 - accuracy: 1.0000\n",
      "Epoch 1149/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0672e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.4356e-04 - accuracy: 1.0000\n",
      "Epoch 1150/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9844e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.4281e-04 - accuracy: 1.0000\n",
      "Epoch 1151/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9977e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.4186e-04 - accuracy: 1.0000\n",
      "Epoch 1152/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4132e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.4100e-04 - accuracy: 1.0000\n",
      "Epoch 1153/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3934e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.4010e-04 - accuracy: 1.0000\n",
      "Epoch 1154/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7168e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.3930e-04 - accuracy: 1.0000\n",
      "Epoch 1155/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7865e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.3845e-04 - accuracy: 1.0000\n",
      "Epoch 1156/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7267e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.3764e-04 - accuracy: 1.0000\n",
      "Epoch 1157/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9269e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.3681e-04 - accuracy: 1.0000\n",
      "Epoch 1158/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7256e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.3598e-04 - accuracy: 1.0000\n",
      "Epoch 1159/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5747e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.3516e-04 - accuracy: 1.0000\n",
      "Epoch 1160/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3132e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.3423e-04 - accuracy: 1.0000\n",
      "Epoch 1161/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4230e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.3342e-04 - accuracy: 1.0000\n",
      "Epoch 1162/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4445e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.3265e-04 - accuracy: 1.0000\n",
      "Epoch 1163/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8696e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.3184e-04 - accuracy: 1.0000\n",
      "Epoch 1164/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8869e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.3103e-04 - accuracy: 1.0000\n",
      "Epoch 1165/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5886e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.3009e-04 - accuracy: 1.0000\n",
      "Epoch 1166/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1580e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.2935e-04 - accuracy: 1.0000\n",
      "Epoch 1167/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5183e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.2868e-04 - accuracy: 1.0000\n",
      "Epoch 1168/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2541e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2790e-04 - accuracy: 1.0000\n",
      "Epoch 1169/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2666e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.2698e-04 - accuracy: 1.0000\n",
      "Epoch 1170/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3934e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.2638e-04 - accuracy: 1.0000\n",
      "Epoch 1171/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5797e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.2552e-04 - accuracy: 1.0000\n",
      "Epoch 1172/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4131e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.2469e-04 - accuracy: 1.0000\n",
      "Epoch 1173/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7510e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2389e-04 - accuracy: 1.0000\n",
      "Epoch 1174/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9046e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.2310e-04 - accuracy: 1.0000\n",
      "Epoch 1175/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1228e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2236e-04 - accuracy: 1.0000\n",
      "Epoch 1176/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8132e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2183e-04 - accuracy: 1.0000\n",
      "Epoch 1177/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6460e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2090e-04 - accuracy: 1.0000\n",
      "Epoch 1178/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0238e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2010e-04 - accuracy: 1.0000\n",
      "Epoch 1179/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3784e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.1936e-04 - accuracy: 1.0000\n",
      "Epoch 1180/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9681e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.1850e-04 - accuracy: 1.0000\n",
      "Epoch 1181/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3223e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.1783e-04 - accuracy: 1.0000\n",
      "Epoch 1182/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5604e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.1715e-04 - accuracy: 1.0000\n",
      "Epoch 1183/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9821e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 2.1656e-04 - accuracy: 1.0000\n",
      "Epoch 1184/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7133e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.1565e-04 - accuracy: 1.0000\n",
      "Epoch 1185/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3693e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.1487e-04 - accuracy: 1.0000\n",
      "Epoch 1186/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1145e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.1415e-04 - accuracy: 1.0000\n",
      "Epoch 1187/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9854e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.1362e-04 - accuracy: 1.0000\n",
      "Epoch 1188/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0704e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.1271e-04 - accuracy: 1.0000\n",
      "Epoch 1189/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4319e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.1192e-04 - accuracy: 1.0000\n",
      "Epoch 1190/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2267e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.1118e-04 - accuracy: 1.0000\n",
      "Epoch 1191/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2952e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.1041e-04 - accuracy: 1.0000\n",
      "Epoch 1192/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9450e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.0971e-04 - accuracy: 1.0000\n",
      "Epoch 1193/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5136e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.0893e-04 - accuracy: 1.0000\n",
      "Epoch 1194/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9019e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.0837e-04 - accuracy: 1.0000\n",
      "Epoch 1195/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2459e-04 - accuracy: 1.00 - 0s 145us/sample - loss: 2.0765e-04 - accuracy: 1.0000\n",
      "Epoch 1196/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0983e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.0692e-04 - accuracy: 1.0000\n",
      "Epoch 1197/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3473e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.0611e-04 - accuracy: 1.0000\n",
      "Epoch 1198/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2957e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.0538e-04 - accuracy: 1.0000\n",
      "Epoch 1199/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9942e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.0471e-04 - accuracy: 1.0000\n",
      "Epoch 1200/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0345e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.0383e-04 - accuracy: 1.0000\n",
      "Epoch 1201/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6969e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.0325e-04 - accuracy: 1.0000\n",
      "Epoch 1202/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7428e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 2.0258e-04 - accuracy: 1.0000\n",
      "Epoch 1203/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6422e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.0191e-04 - accuracy: 1.0000\n",
      "Epoch 1204/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3858e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.0130e-04 - accuracy: 1.0000\n",
      "Epoch 1205/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1575e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.0057e-04 - accuracy: 1.0000\n",
      "Epoch 1206/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4425e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.9987e-04 - accuracy: 1.0000\n",
      "Epoch 1207/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9558e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 1.9911e-04 - accuracy: 1.0000\n",
      "Epoch 1208/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7859e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9848e-04 - accuracy: 1.0000\n",
      "Epoch 1209/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5195e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 1.9780e-04 - accuracy: 1.0000\n",
      "Epoch 1210/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2494e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.9711e-04 - accuracy: 1.0000\n",
      "Epoch 1211/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8586e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9653e-04 - accuracy: 1.0000\n",
      "Epoch 1212/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6442e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.9578e-04 - accuracy: 1.0000\n",
      "Epoch 1213/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6807e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9519e-04 - accuracy: 1.0000\n",
      "Epoch 1214/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3368e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9450e-04 - accuracy: 1.0000\n",
      "Epoch 1215/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3282e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.9395e-04 - accuracy: 1.0000\n",
      "Epoch 1216/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6443e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9316e-04 - accuracy: 1.0000\n",
      "Epoch 1217/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8091e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.9254e-04 - accuracy: 1.0000\n",
      "Epoch 1218/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8335e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.9195e-04 - accuracy: 1.0000\n",
      "Epoch 1219/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2305e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.9130e-04 - accuracy: 1.0000\n",
      "Epoch 1220/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1889e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9066e-04 - accuracy: 1.0000\n",
      "Epoch 1221/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8132e-04 - accuracy: 1.00 - 0s 135us/sample - loss: 1.8992e-04 - accuracy: 1.0000\n",
      "Epoch 1222/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7633e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.8923e-04 - accuracy: 1.0000\n",
      "Epoch 1223/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5835e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8872e-04 - accuracy: 1.0000\n",
      "Epoch 1224/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8133e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.8799e-04 - accuracy: 1.0000\n",
      "Epoch 1225/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0376e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.8738e-04 - accuracy: 1.0000\n",
      "Epoch 1226/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7960e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8679e-04 - accuracy: 1.0000\n",
      "Epoch 1227/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6214e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.8613e-04 - accuracy: 1.0000\n",
      "Epoch 1228/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3028e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.8545e-04 - accuracy: 1.0000\n",
      "Epoch 1229/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 2.0397e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8484e-04 - accuracy: 1.0000\n",
      "Epoch 1230/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9709e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8424e-04 - accuracy: 1.0000\n",
      "Epoch 1231/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1662e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.8361e-04 - accuracy: 1.0000\n",
      "Epoch 1232/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7537e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8292e-04 - accuracy: 1.0000\n",
      "Epoch 1233/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7436e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.8235e-04 - accuracy: 1.0000\n",
      "Epoch 1234/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5470e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8170e-04 - accuracy: 1.0000\n",
      "Epoch 1235/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9070e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8104e-04 - accuracy: 1.0000\n",
      "Epoch 1236/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6230e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8053e-04 - accuracy: 1.0000\n",
      "Epoch 1237/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6248e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8004e-04 - accuracy: 1.0000\n",
      "Epoch 1238/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3771e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7932e-04 - accuracy: 1.0000\n",
      "Epoch 1239/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9994e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.7852e-04 - accuracy: 1.0000\n",
      "Epoch 1240/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9922e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7814e-04 - accuracy: 1.0000\n",
      "Epoch 1241/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9173e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7739e-04 - accuracy: 1.0000\n",
      "Epoch 1242/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5896e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7673e-04 - accuracy: 1.0000\n",
      "Epoch 1243/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4305e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7607e-04 - accuracy: 1.0000\n",
      "Epoch 1244/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3389e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7548e-04 - accuracy: 1.0000\n",
      "Epoch 1245/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3369e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.7486e-04 - accuracy: 1.0000\n",
      "Epoch 1246/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5533e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7433e-04 - accuracy: 1.0000\n",
      "Epoch 1247/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8872e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7378e-04 - accuracy: 1.0000\n",
      "Epoch 1248/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3340e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.7314e-04 - accuracy: 1.0000\n",
      "Epoch 1249/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1561e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.7249e-04 - accuracy: 1.0000\n",
      "Epoch 1250/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.0072e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.7196e-04 - accuracy: 1.0000\n",
      "Epoch 1251/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7133e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7153e-04 - accuracy: 1.0000\n",
      "Epoch 1252/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8998e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.7079e-04 - accuracy: 1.0000\n",
      "Epoch 1253/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2757e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7019e-04 - accuracy: 1.0000\n",
      "Epoch 1254/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2177e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6966e-04 - accuracy: 1.0000\n",
      "Epoch 1255/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7041e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6908e-04 - accuracy: 1.0000\n",
      "Epoch 1256/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5263e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6843e-04 - accuracy: 1.0000\n",
      "Epoch 1257/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2163e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6791e-04 - accuracy: 1.0000\n",
      "Epoch 1258/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0922e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6739e-04 - accuracy: 1.0000\n",
      "Epoch 1259/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3399e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.6678e-04 - accuracy: 1.0000\n",
      "Epoch 1260/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3012e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6628e-04 - accuracy: 1.0000\n",
      "Epoch 1261/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0148e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6563e-04 - accuracy: 1.0000\n",
      "Epoch 1262/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6517e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6523e-04 - accuracy: 1.0000\n",
      "Epoch 1263/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9139e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6469e-04 - accuracy: 1.0000\n",
      "Epoch 1264/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3415e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6404e-04 - accuracy: 1.0000\n",
      "Epoch 1265/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5702e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.6345e-04 - accuracy: 1.0000\n",
      "Epoch 1266/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7765e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6283e-04 - accuracy: 1.0000\n",
      "Epoch 1267/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7972e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6227e-04 - accuracy: 1.0000\n",
      "Epoch 1268/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6509e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6178e-04 - accuracy: 1.0000\n",
      "Epoch 1269/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1108e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6116e-04 - accuracy: 1.0000\n",
      "Epoch 1270/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0645e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6057e-04 - accuracy: 1.0000\n",
      "Epoch 1271/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1737e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6003e-04 - accuracy: 1.0000\n",
      "Epoch 1272/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0643e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.5954e-04 - accuracy: 1.0000\n",
      "Epoch 1273/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6897e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5907e-04 - accuracy: 1.0000\n",
      "Epoch 1274/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4405e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.5846e-04 - accuracy: 1.0000\n",
      "Epoch 1275/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7847e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5790e-04 - accuracy: 1.0000\n",
      "Epoch 1276/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4851e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5740e-04 - accuracy: 1.0000\n",
      "Epoch 1277/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2819e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5687e-04 - accuracy: 1.0000\n",
      "Epoch 1278/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5554e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.5626e-04 - accuracy: 1.0000\n",
      "Epoch 1279/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6259e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.5580e-04 - accuracy: 1.0000\n",
      "Epoch 1280/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7257e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.5527e-04 - accuracy: 1.0000\n",
      "Epoch 1281/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5022e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5475e-04 - accuracy: 1.0000\n",
      "Epoch 1282/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2037e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5431e-04 - accuracy: 1.0000\n",
      "Epoch 1283/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3229e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.5377e-04 - accuracy: 1.0000\n",
      "Epoch 1284/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5509e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.5320e-04 - accuracy: 1.0000\n",
      "Epoch 1285/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3270e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5275e-04 - accuracy: 1.0000\n",
      "Epoch 1286/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0256e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5227e-04 - accuracy: 1.0000\n",
      "Epoch 1287/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8763e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.5161e-04 - accuracy: 1.0000\n",
      "Epoch 1288/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5998e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.5111e-04 - accuracy: 1.0000\n",
      "Epoch 1289/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2423e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5054e-04 - accuracy: 1.0000\n",
      "Epoch 1290/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1898e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.5008e-04 - accuracy: 1.0000\n",
      "Epoch 1291/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5312e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4958e-04 - accuracy: 1.0000\n",
      "Epoch 1292/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8726e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4907e-04 - accuracy: 1.0000\n",
      "Epoch 1293/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3071e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4860e-04 - accuracy: 1.0000\n",
      "Epoch 1294/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8252e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4813e-04 - accuracy: 1.0000\n",
      "Epoch 1295/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0205e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.4765e-04 - accuracy: 1.0000\n",
      "Epoch 1296/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9078e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4715e-04 - accuracy: 1.0000\n",
      "Epoch 1297/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2868e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4671e-04 - accuracy: 1.0000\n",
      "Epoch 1298/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4820e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4622e-04 - accuracy: 1.0000\n",
      "Epoch 1299/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7695e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4586e-04 - accuracy: 1.0000\n",
      "Epoch 1300/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2448e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4523e-04 - accuracy: 1.0000\n",
      "Epoch 1301/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.5464e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4482e-04 - accuracy: 1.0000\n",
      "Epoch 1302/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3098e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4427e-04 - accuracy: 1.0000\n",
      "Epoch 1303/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3184e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4383e-04 - accuracy: 1.0000\n",
      "Epoch 1304/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2278e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4335e-04 - accuracy: 1.0000\n",
      "Epoch 1305/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.1568e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4285e-04 - accuracy: 1.0000\n",
      "Epoch 1306/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0729e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4227e-04 - accuracy: 1.0000\n",
      "Epoch 1307/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.7410e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.4181e-04 - accuracy: 1.0000\n",
      "Epoch 1308/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1651e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4136e-04 - accuracy: 1.0000\n",
      "Epoch 1309/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4888e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4090e-04 - accuracy: 1.0000\n",
      "Epoch 1310/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1701e-04 - accuracy: 1.00 - 0s 160us/sample - loss: 1.4040e-04 - accuracy: 1.0000\n",
      "Epoch 1311/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.4185e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3990e-04 - accuracy: 1.0000\n",
      "Epoch 1312/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1472e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3946e-04 - accuracy: 1.0000\n",
      "Epoch 1313/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4032e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3906e-04 - accuracy: 1.0000\n",
      "Epoch 1314/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3181e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3857e-04 - accuracy: 1.0000\n",
      "Epoch 1315/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3248e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3815e-04 - accuracy: 1.0000\n",
      "Epoch 1316/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7622e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3768e-04 - accuracy: 1.0000\n",
      "Epoch 1317/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1479e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3720e-04 - accuracy: 1.0000\n",
      "Epoch 1318/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.9257e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3670e-04 - accuracy: 1.0000\n",
      "Epoch 1319/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.0185e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.3632e-04 - accuracy: 1.0000\n",
      "Epoch 1320/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6340e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3589e-04 - accuracy: 1.0000\n",
      "Epoch 1321/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1615e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3541e-04 - accuracy: 1.0000\n",
      "Epoch 1322/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8065e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3503e-04 - accuracy: 1.0000\n",
      "Epoch 1323/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3684e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3456e-04 - accuracy: 1.0000\n",
      "Epoch 1324/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5758e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3405e-04 - accuracy: 1.0000\n",
      "Epoch 1325/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6207e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3366e-04 - accuracy: 1.0000\n",
      "Epoch 1326/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5467e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3324e-04 - accuracy: 1.0000\n",
      "Epoch 1327/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0898e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3270e-04 - accuracy: 1.0000\n",
      "Epoch 1328/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1953e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.3229e-04 - accuracy: 1.0000\n",
      "Epoch 1329/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.4016e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3184e-04 - accuracy: 1.0000\n",
      "Epoch 1330/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2022e-04 - accuracy: 1.00 - 0s 184us/sample - loss: 1.3138e-04 - accuracy: 1.0000\n",
      "Epoch 1331/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 1.1927e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3094e-04 - accuracy: 1.0000\n",
      "Epoch 1332/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2631e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3054e-04 - accuracy: 1.0000\n",
      "Epoch 1333/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9373e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.3006e-04 - accuracy: 1.0000\n",
      "Epoch 1334/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1546e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2954e-04 - accuracy: 1.0000\n",
      "Epoch 1335/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1493e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.2912e-04 - accuracy: 1.0000\n",
      "Epoch 1336/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8719e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2873e-04 - accuracy: 1.0000\n",
      "Epoch 1337/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0604e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2827e-04 - accuracy: 1.0000\n",
      "Epoch 1338/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3020e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2787e-04 - accuracy: 1.0000\n",
      "Epoch 1339/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6501e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2748e-04 - accuracy: 1.0000\n",
      "Epoch 1340/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3175e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2708e-04 - accuracy: 1.0000\n",
      "Epoch 1341/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4866e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.2664e-04 - accuracy: 1.0000\n",
      "Epoch 1342/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2980e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2630e-04 - accuracy: 1.0000\n",
      "Epoch 1343/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5446e-04 - accuracy: 1.00 - 0s 199us/sample - loss: 1.2587e-04 - accuracy: 1.0000\n",
      "Epoch 1344/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3612e-04 - accuracy: 1.00 - 0s 191us/sample - loss: 1.2544e-04 - accuracy: 1.0000\n",
      "Epoch 1345/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2140e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2498e-04 - accuracy: 1.0000\n",
      "Epoch 1346/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5135e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2464e-04 - accuracy: 1.0000\n",
      "Epoch 1347/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1129e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2421e-04 - accuracy: 1.0000\n",
      "Epoch 1348/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1533e-04 - accuracy: 1.00 - 0s 177us/sample - loss: 1.2379e-04 - accuracy: 1.0000\n",
      "Epoch 1349/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4735e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2336e-04 - accuracy: 1.0000\n",
      "Epoch 1350/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.9531e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2294e-04 - accuracy: 1.0000\n",
      "Epoch 1351/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1879e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2256e-04 - accuracy: 1.0000\n",
      "Epoch 1352/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6858e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2217e-04 - accuracy: 1.0000\n",
      "Epoch 1353/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2734e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.2175e-04 - accuracy: 1.0000\n",
      "Epoch 1354/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9193e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2142e-04 - accuracy: 1.0000\n",
      "Epoch 1355/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2982e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2097e-04 - accuracy: 1.0000\n",
      "Epoch 1356/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.8809e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.2053e-04 - accuracy: 1.0000\n",
      "Epoch 1357/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4770e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2011e-04 - accuracy: 1.0000\n",
      "Epoch 1358/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0969e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1971e-04 - accuracy: 1.0000\n",
      "Epoch 1359/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.5279e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1933e-04 - accuracy: 1.0000\n",
      "Epoch 1360/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0579e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.1895e-04 - accuracy: 1.0000\n",
      "Epoch 1361/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3281e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1860e-04 - accuracy: 1.0000\n",
      "Epoch 1362/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0423e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1812e-04 - accuracy: 1.0000\n",
      "Epoch 1363/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2774e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.1779e-04 - accuracy: 1.0000\n",
      "Epoch 1364/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2507e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1738e-04 - accuracy: 1.0000\n",
      "Epoch 1365/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2103e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1695e-04 - accuracy: 1.0000\n",
      "Epoch 1366/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3466e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.1668e-04 - accuracy: 1.0000\n",
      "Epoch 1367/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.4564e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.1625e-04 - accuracy: 1.0000\n",
      "Epoch 1368/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5782e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.1587e-04 - accuracy: 1.0000\n",
      "Epoch 1369/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0311e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1557e-04 - accuracy: 1.0000\n",
      "Epoch 1370/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0831e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1511e-04 - accuracy: 1.0000\n",
      "Epoch 1371/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2441e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1474e-04 - accuracy: 1.0000\n",
      "Epoch 1372/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3564e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.1431e-04 - accuracy: 1.0000\n",
      "Epoch 1373/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1847e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1393e-04 - accuracy: 1.0000\n",
      "Epoch 1374/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1422e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1359e-04 - accuracy: 1.0000\n",
      "Epoch 1375/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3073e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1328e-04 - accuracy: 1.0000\n",
      "Epoch 1376/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.4170e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.1291e-04 - accuracy: 1.0000\n",
      "Epoch 1377/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0570e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1249e-04 - accuracy: 1.0000\n",
      "Epoch 1378/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.9738e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1211e-04 - accuracy: 1.0000\n",
      "Epoch 1379/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2605e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1170e-04 - accuracy: 1.0000\n",
      "Epoch 1380/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1578e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1135e-04 - accuracy: 1.0000\n",
      "Epoch 1381/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5560e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1093e-04 - accuracy: 1.0000\n",
      "Epoch 1382/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3732e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1059e-04 - accuracy: 1.0000\n",
      "Epoch 1383/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4396e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.1021e-04 - accuracy: 1.0000\n",
      "Epoch 1384/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3182e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0985e-04 - accuracy: 1.0000\n",
      "Epoch 1385/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.6059e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0953e-04 - accuracy: 1.0000\n",
      "Epoch 1386/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3784e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0915e-04 - accuracy: 1.0000\n",
      "Epoch 1387/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.4671e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0876e-04 - accuracy: 1.0000\n",
      "Epoch 1388/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7606e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0843e-04 - accuracy: 1.0000\n",
      "Epoch 1389/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0900e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0813e-04 - accuracy: 1.0000\n",
      "Epoch 1390/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1082e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.0783e-04 - accuracy: 1.0000\n",
      "Epoch 1391/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5621e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0749e-04 - accuracy: 1.0000\n",
      "Epoch 1392/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3023e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.0706e-04 - accuracy: 1.0000\n",
      "Epoch 1393/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3457e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0671e-04 - accuracy: 1.0000\n",
      "Epoch 1394/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0766e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0638e-04 - accuracy: 1.0000\n",
      "Epoch 1395/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2939e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.0606e-04 - accuracy: 1.0000\n",
      "Epoch 1396/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1841e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 1.0576e-04 - accuracy: 1.0000\n",
      "Epoch 1397/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.9941e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0533e-04 - accuracy: 1.0000\n",
      "Epoch 1398/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4770e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 1.0508e-04 - accuracy: 1.0000\n",
      "Epoch 1399/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2494e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0471e-04 - accuracy: 1.0000\n",
      "Epoch 1400/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1724e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0432e-04 - accuracy: 1.0000\n",
      "Epoch 1401/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5023e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0408e-04 - accuracy: 1.0000\n",
      "Epoch 1402/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.7200e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0364e-04 - accuracy: 1.0000\n",
      "Epoch 1403/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.9584e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0336e-04 - accuracy: 1.0000\n",
      "Epoch 1404/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0511e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0299e-04 - accuracy: 1.0000\n",
      "Epoch 1405/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0886e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0264e-04 - accuracy: 1.0000\n",
      "Epoch 1406/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0560e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0238e-04 - accuracy: 1.0000\n",
      "Epoch 1407/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.9660e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.0204e-04 - accuracy: 1.0000\n",
      "Epoch 1408/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.0528e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0168e-04 - accuracy: 1.0000\n",
      "Epoch 1409/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1047e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0140e-04 - accuracy: 1.0000\n",
      "Epoch 1410/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0097e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 1.0105e-04 - accuracy: 1.0000\n",
      "Epoch 1411/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0523e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0074e-04 - accuracy: 1.0000\n",
      "Epoch 1412/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0894e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0037e-04 - accuracy: 1.0000\n",
      "Epoch 1413/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8197e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0004e-04 - accuracy: 1.0000\n",
      "Epoch 1414/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0817e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.9707e-05 - accuracy: 1.0000\n",
      "Epoch 1415/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.0611e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 9.9369e-05 - accuracy: 1.0000\n",
      "Epoch 1416/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1464e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.9047e-05 - accuracy: 1.0000\n",
      "Epoch 1417/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2078e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.8747e-05 - accuracy: 1.0000\n",
      "Epoch 1418/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0667e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.8401e-05 - accuracy: 1.0000\n",
      "Epoch 1419/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0986e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.8120e-05 - accuracy: 1.0000\n",
      "Epoch 1420/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.1830e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 9.7743e-05 - accuracy: 1.0000\n",
      "Epoch 1421/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7791e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 9.7469e-05 - accuracy: 1.0000\n",
      "Epoch 1422/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8692e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.7151e-05 - accuracy: 1.0000\n",
      "Epoch 1423/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1424e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 9.6849e-05 - accuracy: 1.0000\n",
      "Epoch 1424/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2190e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.6516e-05 - accuracy: 1.0000\n",
      "Epoch 1425/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0761e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.6208e-05 - accuracy: 1.0000\n",
      "Epoch 1426/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5557e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.5987e-05 - accuracy: 1.0000\n",
      "Epoch 1427/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.9003e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.5638e-05 - accuracy: 1.0000\n",
      "Epoch 1428/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.7314e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.5358e-05 - accuracy: 1.0000\n",
      "Epoch 1429/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0247e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.5013e-05 - accuracy: 1.0000\n",
      "Epoch 1430/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.3186e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.4687e-05 - accuracy: 1.0000\n",
      "Epoch 1431/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3981e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.4451e-05 - accuracy: 1.0000\n",
      "Epoch 1432/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2141e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 9.4140e-05 - accuracy: 1.0000\n",
      "Epoch 1433/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 8.6474e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.3758e-05 - accuracy: 1.0000\n",
      "Epoch 1434/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.3356e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 9.3467e-05 - accuracy: 1.0000\n",
      "Epoch 1435/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2576e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.3179e-05 - accuracy: 1.0000\n",
      "Epoch 1436/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5855e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.2880e-05 - accuracy: 1.0000\n",
      "Epoch 1437/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1423e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.2552e-05 - accuracy: 1.0000\n",
      "Epoch 1438/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.5975e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 9.2276e-05 - accuracy: 1.0000\n",
      "Epoch 1439/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1047e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.1957e-05 - accuracy: 1.0000\n",
      "Epoch 1440/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1316e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 9.1657e-05 - accuracy: 1.0000\n",
      "Epoch 1441/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8865e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 9.1355e-05 - accuracy: 1.0000\n",
      "Epoch 1442/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1262e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 9.1107e-05 - accuracy: 1.0000\n",
      "Epoch 1443/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8662e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 9.0797e-05 - accuracy: 1.0000\n",
      "Epoch 1444/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.7777e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.0520e-05 - accuracy: 1.0000\n",
      "Epoch 1445/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0431e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 9.0261e-05 - accuracy: 1.0000\n",
      "Epoch 1446/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.6707e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.9931e-05 - accuracy: 1.0000\n",
      "Epoch 1447/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.0456e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.9639e-05 - accuracy: 1.0000\n",
      "Epoch 1448/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7865e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.9385e-05 - accuracy: 1.0000\n",
      "Epoch 1449/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2784e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 8.9088e-05 - accuracy: 1.0000\n",
      "Epoch 1450/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.6616e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.8789e-05 - accuracy: 1.0000\n",
      "Epoch 1451/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8586e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.8486e-05 - accuracy: 1.0000\n",
      "Epoch 1452/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2447e-05 - accuracy: 1.00 - 0s 177us/sample - loss: 8.8186e-05 - accuracy: 1.0000\n",
      "Epoch 1453/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.3639e-05 - accuracy: 1.00 - 0s 177us/sample - loss: 8.7947e-05 - accuracy: 1.0000\n",
      "Epoch 1454/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.6697e-05 - accuracy: 1.00 - 0s 184us/sample - loss: 8.7723e-05 - accuracy: 1.0000\n",
      "Epoch 1455/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1706e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 8.7455e-05 - accuracy: 1.0000\n",
      "Epoch 1456/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0111e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.7074e-05 - accuracy: 1.0000\n",
      "Epoch 1457/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3060e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 8.6816e-05 - accuracy: 1.0000\n",
      "Epoch 1458/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0065e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.6516e-05 - accuracy: 1.0000\n",
      "Epoch 1459/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2968e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 8.6298e-05 - accuracy: 1.0000\n",
      "Epoch 1460/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.8898e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.6012e-05 - accuracy: 1.0000\n",
      "Epoch 1461/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0468e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 8.5735e-05 - accuracy: 1.0000\n",
      "Epoch 1462/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0953e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 8.5408e-05 - accuracy: 1.0000\n",
      "Epoch 1463/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2126e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.5147e-05 - accuracy: 1.0000\n",
      "Epoch 1464/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.8235e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.4883e-05 - accuracy: 1.0000\n",
      "Epoch 1465/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7387e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.4661e-05 - accuracy: 1.0000\n",
      "Epoch 1466/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3572e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.4388e-05 - accuracy: 1.0000\n",
      "Epoch 1467/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.6357e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.4055e-05 - accuracy: 1.0000\n",
      "Epoch 1468/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.9481e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.3835e-05 - accuracy: 1.0000\n",
      "Epoch 1469/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.6104e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.3545e-05 - accuracy: 1.0000\n",
      "Epoch 1470/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5978e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.3307e-05 - accuracy: 1.0000\n",
      "Epoch 1471/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1331e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 8.3054e-05 - accuracy: 1.0000\n",
      "Epoch 1472/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.4777e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.2751e-05 - accuracy: 1.0000\n",
      "Epoch 1473/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.0736e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 8.2490e-05 - accuracy: 1.0000\n",
      "Epoch 1474/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.7481e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.2219e-05 - accuracy: 1.0000\n",
      "Epoch 1475/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.6425e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 8.1897e-05 - accuracy: 1.0000\n",
      "Epoch 1476/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7134e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 8.1680e-05 - accuracy: 1.0000\n",
      "Epoch 1477/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1797e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 8.1488e-05 - accuracy: 1.0000\n",
      "Epoch 1478/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8801e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.1214e-05 - accuracy: 1.0000\n",
      "Epoch 1479/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0891e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.0942e-05 - accuracy: 1.0000\n",
      "Epoch 1480/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.9819e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.0692e-05 - accuracy: 1.0000\n",
      "Epoch 1481/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8156e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 8.0391e-05 - accuracy: 1.0000\n",
      "Epoch 1482/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.8634e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.0161e-05 - accuracy: 1.0000\n",
      "Epoch 1483/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7008e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.9897e-05 - accuracy: 1.0000\n",
      "Epoch 1484/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7522e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.9622e-05 - accuracy: 1.0000\n",
      "Epoch 1485/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7119e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.9385e-05 - accuracy: 1.0000\n",
      "Epoch 1486/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.8284e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.9154e-05 - accuracy: 1.0000\n",
      "Epoch 1487/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7783e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.8874e-05 - accuracy: 1.0000\n",
      "Epoch 1488/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5547e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.8612e-05 - accuracy: 1.0000\n",
      "Epoch 1489/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.1784e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.8370e-05 - accuracy: 1.0000\n",
      "Epoch 1490/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.0115e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 7.8153e-05 - accuracy: 1.0000\n",
      "Epoch 1491/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3369e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.7895e-05 - accuracy: 1.0000\n",
      "Epoch 1492/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.6523e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 7.7611e-05 - accuracy: 1.0000\n",
      "Epoch 1493/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.2959e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 7.7391e-05 - accuracy: 1.0000\n",
      "Epoch 1494/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0025e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 7.7136e-05 - accuracy: 1.0000\n",
      "Epoch 1495/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1577e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 7.6887e-05 - accuracy: 1.0000\n",
      "Epoch 1496/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.1725e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.6653e-05 - accuracy: 1.0000\n",
      "Epoch 1497/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5607e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 7.6439e-05 - accuracy: 1.0000\n",
      "Epoch 1498/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5659e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.6184e-05 - accuracy: 1.0000\n",
      "Epoch 1499/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5303e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.5945e-05 - accuracy: 1.0000\n",
      "Epoch 1500/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.4364e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.5726e-05 - accuracy: 1.0000\n",
      "Epoch 1501/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8134e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.5486e-05 - accuracy: 1.0000\n",
      "Epoch 1502/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.3515e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.5257e-05 - accuracy: 1.0000\n",
      "Epoch 1503/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7047e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 7.4962e-05 - accuracy: 1.0000\n",
      "Epoch 1504/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1782e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.4743e-05 - accuracy: 1.0000\n",
      "Epoch 1505/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8489e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.4508e-05 - accuracy: 1.0000\n",
      "Epoch 1506/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4363e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.4279e-05 - accuracy: 1.0000\n",
      "Epoch 1507/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2185e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.4069e-05 - accuracy: 1.0000\n",
      "Epoch 1508/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5727e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.3811e-05 - accuracy: 1.0000\n",
      "Epoch 1509/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.6591e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 7.3581e-05 - accuracy: 1.0000\n",
      "Epoch 1510/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.9333e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.3363e-05 - accuracy: 1.0000\n",
      "Epoch 1511/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.3447e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.3142e-05 - accuracy: 1.0000\n",
      "Epoch 1512/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.3574e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.2898e-05 - accuracy: 1.0000\n",
      "Epoch 1513/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.8015e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 7.2640e-05 - accuracy: 1.0000\n",
      "Epoch 1514/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2648e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.2502e-05 - accuracy: 1.0000\n",
      "Epoch 1515/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.3419e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.2241e-05 - accuracy: 1.0000\n",
      "Epoch 1516/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.5276e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.2000e-05 - accuracy: 1.0000\n",
      "Epoch 1517/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.2681e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.1770e-05 - accuracy: 1.0000\n",
      "Epoch 1518/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1872e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.1522e-05 - accuracy: 1.0000\n",
      "Epoch 1519/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4393e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.1333e-05 - accuracy: 1.0000\n",
      "Epoch 1520/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.0330e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.1127e-05 - accuracy: 1.0000\n",
      "Epoch 1521/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4663e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.0890e-05 - accuracy: 1.0000\n",
      "Epoch 1522/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0388e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.0644e-05 - accuracy: 1.0000\n",
      "Epoch 1523/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.0929e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.0490e-05 - accuracy: 1.0000\n",
      "Epoch 1524/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2767e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.0206e-05 - accuracy: 1.0000\n",
      "Epoch 1525/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0819e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 7.0041e-05 - accuracy: 1.0000\n",
      "Epoch 1526/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7891e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.9780e-05 - accuracy: 1.0000\n",
      "Epoch 1527/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6675e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.9563e-05 - accuracy: 1.0000\n",
      "Epoch 1528/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2758e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.9379e-05 - accuracy: 1.0000\n",
      "Epoch 1529/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8993e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.9133e-05 - accuracy: 1.0000\n",
      "Epoch 1530/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2958e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 6.8935e-05 - accuracy: 1.0000\n",
      "Epoch 1531/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4213e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.8666e-05 - accuracy: 1.0000\n",
      "Epoch 1532/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8649e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.8426e-05 - accuracy: 1.0000\n",
      "Epoch 1533/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1319e-04 - accuracy: 1.00 - 0s 156us/sample - loss: 6.8255e-05 - accuracy: 1.0000\n",
      "Epoch 1534/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8206e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.8014e-05 - accuracy: 1.0000\n",
      "Epoch 1535/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 1.0329e-04 - accuracy: 1.00 - 0s 170us/sample - loss: 6.7835e-05 - accuracy: 1.0000\n",
      "Epoch 1536/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8810e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.7637e-05 - accuracy: 1.0000\n",
      "Epoch 1537/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5389e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.7369e-05 - accuracy: 1.0000\n",
      "Epoch 1538/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8590e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.7214e-05 - accuracy: 1.0000\n",
      "Epoch 1539/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9157e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.6985e-05 - accuracy: 1.0000\n",
      "Epoch 1540/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1910e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.6754e-05 - accuracy: 1.0000\n",
      "Epoch 1541/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7978e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.6549e-05 - accuracy: 1.0000\n",
      "Epoch 1542/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.0459e-05 - accuracy: 1.00 - 0s 177us/sample - loss: 6.6295e-05 - accuracy: 1.0000\n",
      "Epoch 1543/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7802e-05 - accuracy: 1.00 - 0s 184us/sample - loss: 6.6098e-05 - accuracy: 1.0000\n",
      "Epoch 1544/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.8947e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.5896e-05 - accuracy: 1.0000\n",
      "Epoch 1545/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.8218e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.5708e-05 - accuracy: 1.0000\n",
      "Epoch 1546/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1941e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.5504e-05 - accuracy: 1.0000\n",
      "Epoch 1547/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5434e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.5314e-05 - accuracy: 1.0000\n",
      "Epoch 1548/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5727e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.5093e-05 - accuracy: 1.0000\n",
      "Epoch 1549/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8250e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.4918e-05 - accuracy: 1.0000\n",
      "Epoch 1550/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2500e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.4705e-05 - accuracy: 1.0000\n",
      "Epoch 1551/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.3178e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.4501e-05 - accuracy: 1.0000\n",
      "Epoch 1552/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8083e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.4280e-05 - accuracy: 1.0000\n",
      "Epoch 1553/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1334e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.4117e-05 - accuracy: 1.0000\n",
      "Epoch 1554/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.8594e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.3953e-05 - accuracy: 1.0000\n",
      "Epoch 1555/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3852e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.3682e-05 - accuracy: 1.0000\n",
      "Epoch 1556/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.1134e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.3508e-05 - accuracy: 1.0000\n",
      "Epoch 1557/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0456e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.3309e-05 - accuracy: 1.0000\n",
      "Epoch 1558/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2457e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.3083e-05 - accuracy: 1.0000\n",
      "Epoch 1559/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1646e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.2858e-05 - accuracy: 1.0000\n",
      "Epoch 1560/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.7593e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.2673e-05 - accuracy: 1.0000\n",
      "Epoch 1561/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8135e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.2468e-05 - accuracy: 1.0000\n",
      "Epoch 1562/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8446e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.2278e-05 - accuracy: 1.0000\n",
      "Epoch 1563/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1838e-05 - accuracy: 1.00 - 0s 178us/sample - loss: 6.2079e-05 - accuracy: 1.0000\n",
      "Epoch 1564/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7517e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.1889e-05 - accuracy: 1.0000\n",
      "Epoch 1565/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1247e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.1698e-05 - accuracy: 1.0000\n",
      "Epoch 1566/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9735e-05 - accuracy: 1.00 - 0s 191us/sample - loss: 6.1510e-05 - accuracy: 1.0000\n",
      "Epoch 1567/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7859e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.1332e-05 - accuracy: 1.0000\n",
      "Epoch 1568/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9521e-05 - accuracy: 1.00 - 0s 184us/sample - loss: 6.1130e-05 - accuracy: 1.0000\n",
      "Epoch 1569/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0142e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.0941e-05 - accuracy: 1.0000\n",
      "Epoch 1570/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2245e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.0766e-05 - accuracy: 1.0000\n",
      "Epoch 1571/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.2025e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 6.0586e-05 - accuracy: 1.0000\n",
      "Epoch 1572/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1636e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.0361e-05 - accuracy: 1.0000\n",
      "Epoch 1573/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.1959e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.0206e-05 - accuracy: 1.0000\n",
      "Epoch 1574/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7747e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 6.0038e-05 - accuracy: 1.0000\n",
      "Epoch 1575/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5071e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.9808e-05 - accuracy: 1.0000\n",
      "Epoch 1576/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5326e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.9665e-05 - accuracy: 1.0000\n",
      "Epoch 1577/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9363e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.9454e-05 - accuracy: 1.0000\n",
      "Epoch 1578/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.4289e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.9271e-05 - accuracy: 1.0000\n",
      "Epoch 1579/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3237e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.9068e-05 - accuracy: 1.0000\n",
      "Epoch 1580/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.7648e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.8894e-05 - accuracy: 1.0000\n",
      "Epoch 1581/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8767e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.8716e-05 - accuracy: 1.0000\n",
      "Epoch 1582/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3904e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.8501e-05 - accuracy: 1.0000\n",
      "Epoch 1583/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0243e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.8327e-05 - accuracy: 1.0000\n",
      "Epoch 1584/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2306e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.8149e-05 - accuracy: 1.0000\n",
      "Epoch 1585/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.4034e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.7987e-05 - accuracy: 1.0000\n",
      "Epoch 1586/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3557e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.7769e-05 - accuracy: 1.0000\n",
      "Epoch 1587/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2132e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.7624e-05 - accuracy: 1.0000\n",
      "Epoch 1588/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.7158e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.7483e-05 - accuracy: 1.0000\n",
      "Epoch 1589/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1512e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.7263e-05 - accuracy: 1.0000\n",
      "Epoch 1590/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0186e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.7059e-05 - accuracy: 1.0000\n",
      "Epoch 1591/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5304e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.6903e-05 - accuracy: 1.0000\n",
      "Epoch 1592/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5622e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.6724e-05 - accuracy: 1.0000\n",
      "Epoch 1593/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4727e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.6569e-05 - accuracy: 1.0000\n",
      "Epoch 1594/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9542e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.6355e-05 - accuracy: 1.0000\n",
      "Epoch 1595/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8488e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.6196e-05 - accuracy: 1.0000\n",
      "Epoch 1596/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.0471e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.6021e-05 - accuracy: 1.0000\n",
      "Epoch 1597/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.5727e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.5829e-05 - accuracy: 1.0000\n",
      "Epoch 1598/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8816e-05 - accuracy: 1.00 - 0s 177us/sample - loss: 5.5637e-05 - accuracy: 1.0000\n",
      "Epoch 1599/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3379e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.5459e-05 - accuracy: 1.0000\n",
      "Epoch 1600/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.1588e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.5317e-05 - accuracy: 1.0000\n",
      "Epoch 1601/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0597e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.5138e-05 - accuracy: 1.0000\n",
      "Epoch 1602/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2934e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.4950e-05 - accuracy: 1.0000\n",
      "Epoch 1603/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.2372e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.4794e-05 - accuracy: 1.0000\n",
      "Epoch 1604/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5993e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.4623e-05 - accuracy: 1.0000\n",
      "Epoch 1605/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2737e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.4452e-05 - accuracy: 1.0000\n",
      "Epoch 1606/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7393e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.4298e-05 - accuracy: 1.0000\n",
      "Epoch 1607/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.6990e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.4128e-05 - accuracy: 1.0000\n",
      "Epoch 1608/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.8467e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.3994e-05 - accuracy: 1.0000\n",
      "Epoch 1609/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7487e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.3777e-05 - accuracy: 1.0000\n",
      "Epoch 1610/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8383e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.3630e-05 - accuracy: 1.0000\n",
      "Epoch 1611/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1004e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.3441e-05 - accuracy: 1.0000\n",
      "Epoch 1612/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5429e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.3274e-05 - accuracy: 1.0000\n",
      "Epoch 1613/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.0878e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.3124e-05 - accuracy: 1.0000\n",
      "Epoch 1614/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0869e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.2955e-05 - accuracy: 1.0000\n",
      "Epoch 1615/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1257e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.2771e-05 - accuracy: 1.0000\n",
      "Epoch 1616/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.8089e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.2631e-05 - accuracy: 1.0000\n",
      "Epoch 1617/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7855e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.2470e-05 - accuracy: 1.0000\n",
      "Epoch 1618/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.4646e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.2281e-05 - accuracy: 1.0000\n",
      "Epoch 1619/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2596e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.2133e-05 - accuracy: 1.0000\n",
      "Epoch 1620/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.5381e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.1984e-05 - accuracy: 1.0000\n",
      "Epoch 1621/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9156e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.1832e-05 - accuracy: 1.0000\n",
      "Epoch 1622/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9630e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.1643e-05 - accuracy: 1.0000\n",
      "Epoch 1623/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2372e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.1541e-05 - accuracy: 1.0000\n",
      "Epoch 1624/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6759e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.1346e-05 - accuracy: 1.0000\n",
      "Epoch 1625/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2194e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 5.1182e-05 - accuracy: 1.0000\n",
      "Epoch 1626/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.2891e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.1025e-05 - accuracy: 1.0000\n",
      "Epoch 1627/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 8.4018e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.0875e-05 - accuracy: 1.0000\n",
      "Epoch 1628/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8336e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.0709e-05 - accuracy: 1.0000\n",
      "Epoch 1629/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.4905e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.0531e-05 - accuracy: 1.0000\n",
      "Epoch 1630/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.6484e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 5.0355e-05 - accuracy: 1.0000\n",
      "Epoch 1631/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5719e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 5.0209e-05 - accuracy: 1.0000\n",
      "Epoch 1632/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0811e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.0043e-05 - accuracy: 1.0000\n",
      "Epoch 1633/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1572e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.9890e-05 - accuracy: 1.0000\n",
      "Epoch 1634/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.9927e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.9792e-05 - accuracy: 1.0000\n",
      "Epoch 1635/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7536e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.9625e-05 - accuracy: 1.0000\n",
      "Epoch 1636/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8286e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 4.9433e-05 - accuracy: 1.0000\n",
      "Epoch 1637/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 6.6163e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 4.9280e-05 - accuracy: 1.0000\n",
      "Epoch 1638/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.9474e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 4.9148e-05 - accuracy: 1.0000\n",
      "Epoch 1639/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6869e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.8978e-05 - accuracy: 1.0000\n",
      "Epoch 1640/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4018e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.8837e-05 - accuracy: 1.0000\n",
      "Epoch 1641/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4334e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.8694e-05 - accuracy: 1.0000\n",
      "Epoch 1642/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1893e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 4.8562e-05 - accuracy: 1.0000\n",
      "Epoch 1643/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1291e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.8403e-05 - accuracy: 1.0000\n",
      "Epoch 1644/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0491e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.8232e-05 - accuracy: 1.0000\n",
      "Epoch 1645/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.3116e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.8061e-05 - accuracy: 1.0000\n",
      "Epoch 1646/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5421e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 4.7906e-05 - accuracy: 1.0000\n",
      "Epoch 1647/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.2392e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.7762e-05 - accuracy: 1.0000\n",
      "Epoch 1648/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6474e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.7610e-05 - accuracy: 1.0000\n",
      "Epoch 1649/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6086e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.7454e-05 - accuracy: 1.0000\n",
      "Epoch 1650/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 7.0722e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.7336e-05 - accuracy: 1.0000\n",
      "Epoch 1651/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9269e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.7157e-05 - accuracy: 1.0000\n",
      "Epoch 1652/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8280e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.7017e-05 - accuracy: 1.0000\n",
      "Epoch 1653/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0151e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.6845e-05 - accuracy: 1.0000\n",
      "Epoch 1654/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5345e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.6717e-05 - accuracy: 1.0000\n",
      "Epoch 1655/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6356e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.6556e-05 - accuracy: 1.0000\n",
      "Epoch 1656/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9214e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.6423e-05 - accuracy: 1.0000\n",
      "Epoch 1657/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6328e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.6287e-05 - accuracy: 1.0000\n",
      "Epoch 1658/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8712e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.6162e-05 - accuracy: 1.0000\n",
      "Epoch 1659/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7245e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.6016e-05 - accuracy: 1.0000\n",
      "Epoch 1660/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4417e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.5861e-05 - accuracy: 1.0000\n",
      "Epoch 1661/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0403e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.5740e-05 - accuracy: 1.0000\n",
      "Epoch 1662/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1006e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.5605e-05 - accuracy: 1.0000\n",
      "Epoch 1663/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6566e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 4.5470e-05 - accuracy: 1.0000\n",
      "Epoch 1664/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5128e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.5324e-05 - accuracy: 1.0000\n",
      "Epoch 1665/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7818e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.5210e-05 - accuracy: 1.0000\n",
      "Epoch 1666/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.1873e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.5055e-05 - accuracy: 1.0000\n",
      "Epoch 1667/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2257e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.4913e-05 - accuracy: 1.0000\n",
      "Epoch 1668/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4778e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.4764e-05 - accuracy: 1.0000\n",
      "Epoch 1669/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3778e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.4638e-05 - accuracy: 1.0000\n",
      "Epoch 1670/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5516e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.4503e-05 - accuracy: 1.0000\n",
      "Epoch 1671/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3102e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.4373e-05 - accuracy: 1.0000\n",
      "Epoch 1672/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0389e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.4235e-05 - accuracy: 1.0000\n",
      "Epoch 1673/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9445e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.4102e-05 - accuracy: 1.0000\n",
      "Epoch 1674/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8757e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.3947e-05 - accuracy: 1.0000\n",
      "Epoch 1675/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.7005e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 4.3813e-05 - accuracy: 1.0000\n",
      "Epoch 1676/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.4091e-05 - accuracy: 1.00 - 0s 177us/sample - loss: 4.3684e-05 - accuracy: 1.0000\n",
      "Epoch 1677/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5763e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 4.3568e-05 - accuracy: 1.0000\n",
      "Epoch 1678/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6881e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.3406e-05 - accuracy: 1.0000\n",
      "Epoch 1679/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0107e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.3251e-05 - accuracy: 1.0000\n",
      "Epoch 1680/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0677e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.3151e-05 - accuracy: 1.0000\n",
      "Epoch 1681/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6418e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 4.3011e-05 - accuracy: 1.0000\n",
      "Epoch 1682/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3537e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.2879e-05 - accuracy: 1.0000\n",
      "Epoch 1683/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5646e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.2748e-05 - accuracy: 1.0000\n",
      "Epoch 1684/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9790e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.2606e-05 - accuracy: 1.0000\n",
      "Epoch 1685/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6116e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.2456e-05 - accuracy: 1.0000\n",
      "Epoch 1686/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5653e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.2310e-05 - accuracy: 1.0000\n",
      "Epoch 1687/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3986e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 4.2182e-05 - accuracy: 1.0000\n",
      "Epoch 1688/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8623e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.2043e-05 - accuracy: 1.0000\n",
      "Epoch 1689/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5722e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.1934e-05 - accuracy: 1.0000\n",
      "Epoch 1690/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.8303e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.1787e-05 - accuracy: 1.0000\n",
      "Epoch 1691/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1828e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.1676e-05 - accuracy: 1.0000\n",
      "Epoch 1692/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0895e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 4.1532e-05 - accuracy: 1.0000\n",
      "Epoch 1693/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.7654e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 4.1393e-05 - accuracy: 1.0000\n",
      "Epoch 1694/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0882e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.1283e-05 - accuracy: 1.0000\n",
      "Epoch 1695/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3002e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.1153e-05 - accuracy: 1.0000\n",
      "Epoch 1696/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6493e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.0996e-05 - accuracy: 1.0000\n",
      "Epoch 1697/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3497e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.0891e-05 - accuracy: 1.0000\n",
      "Epoch 1698/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2071e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 4.0759e-05 - accuracy: 1.0000\n",
      "Epoch 1699/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4056e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.0618e-05 - accuracy: 1.0000\n",
      "Epoch 1700/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8186e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 4.0519e-05 - accuracy: 1.0000\n",
      "Epoch 1701/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2379e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.0394e-05 - accuracy: 1.0000\n",
      "Epoch 1702/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8446e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.0254e-05 - accuracy: 1.0000\n",
      "Epoch 1703/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.2362e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.0112e-05 - accuracy: 1.0000\n",
      "Epoch 1704/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1233e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.9988e-05 - accuracy: 1.0000\n",
      "Epoch 1705/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.5658e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.9884e-05 - accuracy: 1.0000\n",
      "Epoch 1706/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7306e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.9747e-05 - accuracy: 1.0000\n",
      "Epoch 1707/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7823e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.9611e-05 - accuracy: 1.0000\n",
      "Epoch 1708/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8689e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.9479e-05 - accuracy: 1.0000\n",
      "Epoch 1709/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5882e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.9355e-05 - accuracy: 1.0000\n",
      "Epoch 1710/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4592e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.9238e-05 - accuracy: 1.0000\n",
      "Epoch 1711/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3947e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.9131e-05 - accuracy: 1.0000\n",
      "Epoch 1712/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0855e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.9012e-05 - accuracy: 1.0000\n",
      "Epoch 1713/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0294e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8875e-05 - accuracy: 1.0000\n",
      "Epoch 1714/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0279e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8773e-05 - accuracy: 1.0000\n",
      "Epoch 1715/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9307e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8680e-05 - accuracy: 1.0000\n",
      "Epoch 1716/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3818e-05 - accuracy: 1.00 - 0s 167us/sample - loss: 3.8584e-05 - accuracy: 1.0000\n",
      "Epoch 1717/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2576e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8444e-05 - accuracy: 1.0000\n",
      "Epoch 1718/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0583e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 3.8289e-05 - accuracy: 1.0000\n",
      "Epoch 1719/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1940e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 3.8179e-05 - accuracy: 1.0000\n",
      "Epoch 1720/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6476e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.8070e-05 - accuracy: 1.0000\n",
      "Epoch 1721/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4179e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.7963e-05 - accuracy: 1.0000\n",
      "Epoch 1722/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4547e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.7872e-05 - accuracy: 1.0000\n",
      "Epoch 1723/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4180e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 3.7740e-05 - accuracy: 1.0000\n",
      "Epoch 1724/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1504e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.7616e-05 - accuracy: 1.0000\n",
      "Epoch 1725/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1223e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.7484e-05 - accuracy: 1.0000\n",
      "Epoch 1726/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3356e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 3.7380e-05 - accuracy: 1.0000\n",
      "Epoch 1727/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0730e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.7255e-05 - accuracy: 1.0000\n",
      "Epoch 1728/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1248e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.7136e-05 - accuracy: 1.0000\n",
      "Epoch 1729/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6488e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.7026e-05 - accuracy: 1.0000\n",
      "Epoch 1730/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4065e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.6927e-05 - accuracy: 1.0000\n",
      "Epoch 1731/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9980e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.6801e-05 - accuracy: 1.0000\n",
      "Epoch 1732/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4725e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.6679e-05 - accuracy: 1.0000\n",
      "Epoch 1733/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0268e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.6591e-05 - accuracy: 1.0000\n",
      "Epoch 1734/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3619e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 3.6476e-05 - accuracy: 1.0000\n",
      "Epoch 1735/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7331e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.6361e-05 - accuracy: 1.0000\n",
      "Epoch 1736/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8427e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.6240e-05 - accuracy: 1.0000\n",
      "Epoch 1737/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.4392e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.6167e-05 - accuracy: 1.0000\n",
      "Epoch 1738/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7916e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.6043e-05 - accuracy: 1.0000\n",
      "Epoch 1739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 3.2695e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.5932e-05 - accuracy: 1.0000\n",
      "Epoch 1740/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.2980e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 3.5815e-05 - accuracy: 1.0000\n",
      "Epoch 1741/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8513e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.5710e-05 - accuracy: 1.0000\n",
      "Epoch 1742/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6029e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.5607e-05 - accuracy: 1.0000\n",
      "Epoch 1743/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1289e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 3.5493e-05 - accuracy: 1.0000\n",
      "Epoch 1744/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0301e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.5388e-05 - accuracy: 1.0000\n",
      "Epoch 1745/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2923e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.5281e-05 - accuracy: 1.0000\n",
      "Epoch 1746/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4395e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.5169e-05 - accuracy: 1.0000\n",
      "Epoch 1747/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0191e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.5057e-05 - accuracy: 1.0000\n",
      "Epoch 1748/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2275e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.4940e-05 - accuracy: 1.0000\n",
      "Epoch 1749/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6610e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.4855e-05 - accuracy: 1.0000\n",
      "Epoch 1750/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6497e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.4766e-05 - accuracy: 1.0000\n",
      "Epoch 1751/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3666e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 3.4657e-05 - accuracy: 1.0000\n",
      "Epoch 1752/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6473e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.4559e-05 - accuracy: 1.0000\n",
      "Epoch 1753/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3981e-05 - accuracy: 1.00 - 0s 153us/sample - loss: 3.4434e-05 - accuracy: 1.0000\n",
      "Epoch 1754/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3004e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.4307e-05 - accuracy: 1.0000\n",
      "Epoch 1755/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.9226e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.4237e-05 - accuracy: 1.0000\n",
      "Epoch 1756/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9555e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.4121e-05 - accuracy: 1.0000\n",
      "Epoch 1757/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3612e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.4030e-05 - accuracy: 1.0000\n",
      "Epoch 1758/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9865e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.3915e-05 - accuracy: 1.0000\n",
      "Epoch 1759/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9920e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.3790e-05 - accuracy: 1.0000\n",
      "Epoch 1760/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1122e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.3698e-05 - accuracy: 1.0000\n",
      "Epoch 1761/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4431e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 3.3604e-05 - accuracy: 1.0000\n",
      "Epoch 1762/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6352e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.3506e-05 - accuracy: 1.0000\n",
      "Epoch 1763/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3583e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.3415e-05 - accuracy: 1.0000\n",
      "Epoch 1764/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4386e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.3300e-05 - accuracy: 1.0000\n",
      "Epoch 1765/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1802e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 3.3197e-05 - accuracy: 1.0000\n",
      "Epoch 1766/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4951e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.3097e-05 - accuracy: 1.0000\n",
      "Epoch 1767/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4149e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.3002e-05 - accuracy: 1.0000\n",
      "Epoch 1768/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8760e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.2882e-05 - accuracy: 1.0000\n",
      "Epoch 1769/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.1338e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2816e-05 - accuracy: 1.0000\n",
      "Epoch 1770/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6774e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2699e-05 - accuracy: 1.0000\n",
      "Epoch 1771/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3326e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.2605e-05 - accuracy: 1.0000\n",
      "Epoch 1772/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.5135e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2488e-05 - accuracy: 1.0000\n",
      "Epoch 1773/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0040e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 3.2389e-05 - accuracy: 1.0000\n",
      "Epoch 1774/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4009e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2302e-05 - accuracy: 1.0000\n",
      "Epoch 1775/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2051e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.2205e-05 - accuracy: 1.0000\n",
      "Epoch 1776/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0240e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.2102e-05 - accuracy: 1.0000\n",
      "Epoch 1777/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8473e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2002e-05 - accuracy: 1.0000\n",
      "Epoch 1778/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4986e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.1894e-05 - accuracy: 1.0000\n",
      "Epoch 1779/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3630e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 3.1815e-05 - accuracy: 1.0000\n",
      "Epoch 1780/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7082e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.1704e-05 - accuracy: 1.0000\n",
      "Epoch 1781/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8912e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.1616e-05 - accuracy: 1.0000\n",
      "Epoch 1782/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.3422e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.1540e-05 - accuracy: 1.0000\n",
      "Epoch 1783/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9190e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.1412e-05 - accuracy: 1.0000\n",
      "Epoch 1784/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.3904e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.1362e-05 - accuracy: 1.0000\n",
      "Epoch 1785/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9134e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 3.1251e-05 - accuracy: 1.0000\n",
      "Epoch 1786/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8863e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.1146e-05 - accuracy: 1.0000\n",
      "Epoch 1787/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8391e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.1031e-05 - accuracy: 1.0000\n",
      "Epoch 1788/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9313e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.0945e-05 - accuracy: 1.0000\n",
      "Epoch 1789/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4998e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.0843e-05 - accuracy: 1.0000\n",
      "Epoch 1790/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2336e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.0765e-05 - accuracy: 1.0000\n",
      "Epoch 1791/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6784e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.0656e-05 - accuracy: 1.0000\n",
      "Epoch 1792/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0672e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 3.0573e-05 - accuracy: 1.0000\n",
      "Epoch 1793/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1529e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.0467e-05 - accuracy: 1.0000\n",
      "Epoch 1794/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8426e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.0379e-05 - accuracy: 1.0000\n",
      "Epoch 1795/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1450e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.0306e-05 - accuracy: 1.0000\n",
      "Epoch 1796/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7641e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.0197e-05 - accuracy: 1.0000\n",
      "Epoch 1797/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9890e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 3.0110e-05 - accuracy: 1.0000\n",
      "Epoch 1798/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0818e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.0015e-05 - accuracy: 1.0000\n",
      "Epoch 1799/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0669e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.9919e-05 - accuracy: 1.0000\n",
      "Epoch 1800/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9302e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.9820e-05 - accuracy: 1.0000\n",
      "Epoch 1801/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0127e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.9750e-05 - accuracy: 1.0000\n",
      "Epoch 1802/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6074e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.9663e-05 - accuracy: 1.0000\n",
      "Epoch 1803/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0688e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.9567e-05 - accuracy: 1.0000\n",
      "Epoch 1804/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6849e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.9470e-05 - accuracy: 1.0000\n",
      "Epoch 1805/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4649e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.9386e-05 - accuracy: 1.0000\n",
      "Epoch 1806/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8237e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.9295e-05 - accuracy: 1.0000\n",
      "Epoch 1807/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6017e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.9216e-05 - accuracy: 1.0000\n",
      "Epoch 1808/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0367e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.9120e-05 - accuracy: 1.0000\n",
      "Epoch 1809/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8207e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.9022e-05 - accuracy: 1.0000\n",
      "Epoch 1810/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0087e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8943e-05 - accuracy: 1.0000\n",
      "Epoch 1811/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0099e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8858e-05 - accuracy: 1.0000\n",
      "Epoch 1812/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4708e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8774e-05 - accuracy: 1.0000\n",
      "Epoch 1813/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.1843e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.8676e-05 - accuracy: 1.0000\n",
      "Epoch 1814/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5323e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.8603e-05 - accuracy: 1.0000\n",
      "Epoch 1815/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9896e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8510e-05 - accuracy: 1.0000\n",
      "Epoch 1816/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1045e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.8434e-05 - accuracy: 1.0000\n",
      "Epoch 1817/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8011e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8338e-05 - accuracy: 1.0000\n",
      "Epoch 1818/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0936e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.8254e-05 - accuracy: 1.0000\n",
      "Epoch 1819/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.7906e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8169e-05 - accuracy: 1.0000\n",
      "Epoch 1820/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4899e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8096e-05 - accuracy: 1.0000\n",
      "Epoch 1821/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4102e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.8015e-05 - accuracy: 1.0000\n",
      "Epoch 1822/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0201e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.7917e-05 - accuracy: 1.0000\n",
      "Epoch 1823/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1648e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.7832e-05 - accuracy: 1.0000\n",
      "Epoch 1824/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3215e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.7751e-05 - accuracy: 1.0000\n",
      "Epoch 1825/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8490e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.7695e-05 - accuracy: 1.0000\n",
      "Epoch 1826/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0825e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.7580e-05 - accuracy: 1.0000\n",
      "Epoch 1827/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8319e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.7507e-05 - accuracy: 1.0000\n",
      "Epoch 1828/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8426e-05 - accuracy: 1.00 - 0s 220us/sample - loss: 2.7409e-05 - accuracy: 1.0000\n",
      "Epoch 1829/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8987e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.7331e-05 - accuracy: 1.0000\n",
      "Epoch 1830/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1692e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.7261e-05 - accuracy: 1.0000\n",
      "Epoch 1831/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9878e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.7175e-05 - accuracy: 1.0000\n",
      "Epoch 1832/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6463e-05 - accuracy: 1.00 - 0s 191us/sample - loss: 2.7113e-05 - accuracy: 1.0000\n",
      "Epoch 1833/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9349e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 2.6997e-05 - accuracy: 1.0000\n",
      "Epoch 1834/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6188e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.6925e-05 - accuracy: 1.0000\n",
      "Epoch 1835/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2498e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.6845e-05 - accuracy: 1.0000\n",
      "Epoch 1836/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8385e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.6761e-05 - accuracy: 1.0000\n",
      "Epoch 1837/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.8697e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.6691e-05 - accuracy: 1.0000\n",
      "Epoch 1838/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0675e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.6606e-05 - accuracy: 1.0000\n",
      "Epoch 1839/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1267e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.6504e-05 - accuracy: 1.0000\n",
      "Epoch 1840/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4392e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 2.6427e-05 - accuracy: 1.0000\n",
      "Epoch 1841/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 2.2131e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 2.6341e-05 - accuracy: 1.0000\n",
      "Epoch 1842/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3588e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.6271e-05 - accuracy: 1.0000\n",
      "Epoch 1843/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2274e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.6190e-05 - accuracy: 1.0000\n",
      "Epoch 1844/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6233e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.6111e-05 - accuracy: 1.0000\n",
      "Epoch 1845/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3304e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.6036e-05 - accuracy: 1.0000\n",
      "Epoch 1846/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.7512e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.5968e-05 - accuracy: 1.0000\n",
      "Epoch 1847/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4895e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.5867e-05 - accuracy: 1.0000\n",
      "Epoch 1848/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1118e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.5785e-05 - accuracy: 1.0000\n",
      "Epoch 1849/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9917e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.5717e-05 - accuracy: 1.0000\n",
      "Epoch 1850/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2989e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.5641e-05 - accuracy: 1.0000\n",
      "Epoch 1851/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5415e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.5564e-05 - accuracy: 1.0000\n",
      "Epoch 1852/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0261e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.5477e-05 - accuracy: 1.0000\n",
      "Epoch 1853/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3349e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.5422e-05 - accuracy: 1.0000\n",
      "Epoch 1854/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6983e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.5364e-05 - accuracy: 1.0000\n",
      "Epoch 1855/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7410e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.5265e-05 - accuracy: 1.0000\n",
      "Epoch 1856/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2954e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.5189e-05 - accuracy: 1.0000\n",
      "Epoch 1857/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6426e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.5114e-05 - accuracy: 1.0000\n",
      "Epoch 1858/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3390e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.5046e-05 - accuracy: 1.0000\n",
      "Epoch 1859/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0574e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.4962e-05 - accuracy: 1.0000\n",
      "Epoch 1860/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8464e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 2.4885e-05 - accuracy: 1.0000\n",
      "Epoch 1861/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8671e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.4811e-05 - accuracy: 1.0000\n",
      "Epoch 1862/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5776e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.4730e-05 - accuracy: 1.0000\n",
      "Epoch 1863/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9498e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.4653e-05 - accuracy: 1.0000\n",
      "Epoch 1864/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3785e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.4576e-05 - accuracy: 1.0000\n",
      "Epoch 1865/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.2408e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.4521e-05 - accuracy: 1.0000\n",
      "Epoch 1866/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2847e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.4435e-05 - accuracy: 1.0000\n",
      "Epoch 1867/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1444e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.4364e-05 - accuracy: 1.0000\n",
      "Epoch 1868/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7616e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.4284e-05 - accuracy: 1.0000\n",
      "Epoch 1869/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3353e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.4220e-05 - accuracy: 1.0000\n",
      "Epoch 1870/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0265e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.4133e-05 - accuracy: 1.0000\n",
      "Epoch 1871/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3765e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.4069e-05 - accuracy: 1.0000\n",
      "Epoch 1872/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2198e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.4000e-05 - accuracy: 1.0000\n",
      "Epoch 1873/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0702e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3921e-05 - accuracy: 1.0000\n",
      "Epoch 1874/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1710e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3856e-05 - accuracy: 1.0000\n",
      "Epoch 1875/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1990e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3775e-05 - accuracy: 1.0000\n",
      "Epoch 1876/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1371e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 2.3700e-05 - accuracy: 1.0000\n",
      "Epoch 1877/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9818e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.3619e-05 - accuracy: 1.0000\n",
      "Epoch 1878/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4310e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3567e-05 - accuracy: 1.0000\n",
      "Epoch 1879/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2269e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3485e-05 - accuracy: 1.0000\n",
      "Epoch 1880/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3543e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3415e-05 - accuracy: 1.0000\n",
      "Epoch 1881/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6625e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.3356e-05 - accuracy: 1.0000\n",
      "Epoch 1882/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1140e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3265e-05 - accuracy: 1.0000\n",
      "Epoch 1883/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.6889e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.3209e-05 - accuracy: 1.0000\n",
      "Epoch 1884/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6771e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3133e-05 - accuracy: 1.0000\n",
      "Epoch 1885/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7894e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.3054e-05 - accuracy: 1.0000\n",
      "Epoch 1886/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8052e-05 - accuracy: 1.00 - 0s 160us/sample - loss: 2.2971e-05 - accuracy: 1.0000\n",
      "Epoch 1887/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8646e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.2925e-05 - accuracy: 1.0000\n",
      "Epoch 1888/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2049e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.2845e-05 - accuracy: 1.0000\n",
      "Epoch 1889/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8780e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.2773e-05 - accuracy: 1.0000\n",
      "Epoch 1890/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3497e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.2706e-05 - accuracy: 1.0000\n",
      "Epoch 1891/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3256e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.2633e-05 - accuracy: 1.0000\n",
      "Epoch 1892/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1848e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.2585e-05 - accuracy: 1.0000\n",
      "Epoch 1893/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8661e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.2492e-05 - accuracy: 1.0000\n",
      "Epoch 1894/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0101e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.2430e-05 - accuracy: 1.0000\n",
      "Epoch 1895/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7812e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2364e-05 - accuracy: 1.0000\n",
      "Epoch 1896/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6462e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.2292e-05 - accuracy: 1.0000\n",
      "Epoch 1897/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5985e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.2227e-05 - accuracy: 1.0000\n",
      "Epoch 1898/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0950e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2166e-05 - accuracy: 1.0000\n",
      "Epoch 1899/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5339e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.2100e-05 - accuracy: 1.0000\n",
      "Epoch 1900/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8488e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.2028e-05 - accuracy: 1.0000\n",
      "Epoch 1901/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2221e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.1975e-05 - accuracy: 1.0000\n",
      "Epoch 1902/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8078e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.1899e-05 - accuracy: 1.0000\n",
      "Epoch 1903/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3360e-05 - accuracy: 1.00 - 0s 142us/sample - loss: 2.1838e-05 - accuracy: 1.0000\n",
      "Epoch 1904/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6415e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.1792e-05 - accuracy: 1.0000\n",
      "Epoch 1905/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3126e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.1717e-05 - accuracy: 1.0000\n",
      "Epoch 1906/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1956e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.1640e-05 - accuracy: 1.0000\n",
      "Epoch 1907/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6406e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.1565e-05 - accuracy: 1.0000\n",
      "Epoch 1908/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9092e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.1519e-05 - accuracy: 1.0000\n",
      "Epoch 1909/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.8557e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.1458e-05 - accuracy: 1.0000\n",
      "Epoch 1910/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5264e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.1383e-05 - accuracy: 1.0000\n",
      "Epoch 1911/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6171e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.1318e-05 - accuracy: 1.0000\n",
      "Epoch 1912/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7499e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.1256e-05 - accuracy: 1.0000\n",
      "Epoch 1913/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0529e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.1201e-05 - accuracy: 1.0000\n",
      "Epoch 1914/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3353e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.1135e-05 - accuracy: 1.0000\n",
      "Epoch 1915/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0369e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.1070e-05 - accuracy: 1.0000\n",
      "Epoch 1916/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1884e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.0996e-05 - accuracy: 1.0000\n",
      "Epoch 1917/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5495e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.0944e-05 - accuracy: 1.0000\n",
      "Epoch 1918/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4156e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.0882e-05 - accuracy: 1.0000\n",
      "Epoch 1919/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3833e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.0822e-05 - accuracy: 1.0000\n",
      "Epoch 1920/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1235e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.0746e-05 - accuracy: 1.0000\n",
      "Epoch 1921/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.0542e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.0698e-05 - accuracy: 1.0000\n",
      "Epoch 1922/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6916e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.0633e-05 - accuracy: 1.0000\n",
      "Epoch 1923/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5620e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.0577e-05 - accuracy: 1.0000\n",
      "Epoch 1924/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3327e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.0505e-05 - accuracy: 1.0000\n",
      "Epoch 1925/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2418e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.0434e-05 - accuracy: 1.0000\n",
      "Epoch 1926/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5730e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.0380e-05 - accuracy: 1.0000\n",
      "Epoch 1927/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0552e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.0318e-05 - accuracy: 1.0000\n",
      "Epoch 1928/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9755e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 2.0238e-05 - accuracy: 1.0000\n",
      "Epoch 1929/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.5812e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.0193e-05 - accuracy: 1.0000\n",
      "Epoch 1930/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2120e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.0133e-05 - accuracy: 1.0000\n",
      "Epoch 1931/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4264e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.0076e-05 - accuracy: 1.0000\n",
      "Epoch 1932/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3163e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 2.0008e-05 - accuracy: 1.0000\n",
      "Epoch 1933/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4961e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9958e-05 - accuracy: 1.0000\n",
      "Epoch 1934/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4622e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9895e-05 - accuracy: 1.0000\n",
      "Epoch 1935/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9021e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.9836e-05 - accuracy: 1.0000\n",
      "Epoch 1936/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1757e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.9802e-05 - accuracy: 1.0000\n",
      "Epoch 1937/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4160e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9726e-05 - accuracy: 1.0000\n",
      "Epoch 1938/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4636e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.9667e-05 - accuracy: 1.0000\n",
      "Epoch 1939/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3537e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9605e-05 - accuracy: 1.0000\n",
      "Epoch 1940/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8227e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.9549e-05 - accuracy: 1.0000\n",
      "Epoch 1941/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6838e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9469e-05 - accuracy: 1.0000\n",
      "Epoch 1942/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4307e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.9457e-05 - accuracy: 1.0000\n",
      "Epoch 1943/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 2.7894e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.9382e-05 - accuracy: 1.0000\n",
      "Epoch 1944/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4117e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9318e-05 - accuracy: 1.0000\n",
      "Epoch 1945/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6208e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9246e-05 - accuracy: 1.0000\n",
      "Epoch 1946/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1857e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 1.9194e-05 - accuracy: 1.0000\n",
      "Epoch 1947/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3020e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.9135e-05 - accuracy: 1.0000\n",
      "Epoch 1948/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3716e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9067e-05 - accuracy: 1.0000\n",
      "Epoch 1949/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1513e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9021e-05 - accuracy: 1.0000\n",
      "Epoch 1950/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.2980e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.8965e-05 - accuracy: 1.0000\n",
      "Epoch 1951/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1412e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8895e-05 - accuracy: 1.0000\n",
      "Epoch 1952/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5672e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8834e-05 - accuracy: 1.0000\n",
      "Epoch 1953/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9542e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8783e-05 - accuracy: 1.0000\n",
      "Epoch 1954/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4675e-05 - accuracy: 1.00 - 0s 177us/sample - loss: 1.8731e-05 - accuracy: 1.0000\n",
      "Epoch 1955/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5381e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.8670e-05 - accuracy: 1.0000\n",
      "Epoch 1956/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2446e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8613e-05 - accuracy: 1.0000\n",
      "Epoch 1957/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3234e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8569e-05 - accuracy: 1.0000\n",
      "Epoch 1958/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0425e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8497e-05 - accuracy: 1.0000\n",
      "Epoch 1959/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6979e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8446e-05 - accuracy: 1.0000\n",
      "Epoch 1960/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5929e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8384e-05 - accuracy: 1.0000\n",
      "Epoch 1961/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4364e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.8348e-05 - accuracy: 1.0000\n",
      "Epoch 1962/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9099e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8277e-05 - accuracy: 1.0000\n",
      "Epoch 1963/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0496e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8222e-05 - accuracy: 1.0000\n",
      "Epoch 1964/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6473e-05 - accuracy: 1.00 - 0s 177us/sample - loss: 1.8157e-05 - accuracy: 1.0000\n",
      "Epoch 1965/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4152e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8113e-05 - accuracy: 1.0000\n",
      "Epoch 1966/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4191e-05 - accuracy: 1.00 - 0s 213us/sample - loss: 1.8078e-05 - accuracy: 1.0000\n",
      "Epoch 1967/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5556e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.8013e-05 - accuracy: 1.0000\n",
      "Epoch 1968/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7680e-05 - accuracy: 1.00 - 0s 177us/sample - loss: 1.7949e-05 - accuracy: 1.0000\n",
      "Epoch 1969/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0347e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7888e-05 - accuracy: 1.0000\n",
      "Epoch 1970/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6208e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7836e-05 - accuracy: 1.0000\n",
      "Epoch 1971/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1872e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7780e-05 - accuracy: 1.0000\n",
      "Epoch 1972/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0140e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7719e-05 - accuracy: 1.0000\n",
      "Epoch 1973/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5210e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7682e-05 - accuracy: 1.0000\n",
      "Epoch 1974/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6491e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7630e-05 - accuracy: 1.0000\n",
      "Epoch 1975/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8618e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7571e-05 - accuracy: 1.0000\n",
      "Epoch 1976/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3828e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7528e-05 - accuracy: 1.0000\n",
      "Epoch 1977/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3590e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7473e-05 - accuracy: 1.0000\n",
      "Epoch 1978/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0936e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7429e-05 - accuracy: 1.0000\n",
      "Epoch 1979/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8801e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7375e-05 - accuracy: 1.0000\n",
      "Epoch 1980/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8272e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7311e-05 - accuracy: 1.0000\n",
      "Epoch 1981/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3698e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7265e-05 - accuracy: 1.0000\n",
      "Epoch 1982/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9501e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7219e-05 - accuracy: 1.0000\n",
      "Epoch 1983/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6514e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7161e-05 - accuracy: 1.0000\n",
      "Epoch 1984/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1364e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 1.7116e-05 - accuracy: 1.0000\n",
      "Epoch 1985/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4562e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.7069e-05 - accuracy: 1.0000\n",
      "Epoch 1986/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.6048e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7026e-05 - accuracy: 1.0000\n",
      "Epoch 1987/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2297e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6961e-05 - accuracy: 1.0000\n",
      "Epoch 1988/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7398e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6900e-05 - accuracy: 1.0000\n",
      "Epoch 1989/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8242e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.6869e-05 - accuracy: 1.0000\n",
      "Epoch 1990/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8659e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6807e-05 - accuracy: 1.0000\n",
      "Epoch 1991/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4949e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6750e-05 - accuracy: 1.0000\n",
      "Epoch 1992/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.7516e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 1.6704e-05 - accuracy: 1.0000\n",
      "Epoch 1993/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1207e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.6650e-05 - accuracy: 1.0000\n",
      "Epoch 1994/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.0712e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.6609e-05 - accuracy: 1.0000\n",
      "Epoch 1995/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0788e-05 - accuracy: 1.00 - 0s 170us/sample - loss: 1.6552e-05 - accuracy: 1.0000\n",
      "Epoch 1996/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 9.3616e-06 - accuracy: 1.00 - 0s 177us/sample - loss: 1.6499e-05 - accuracy: 1.0000\n",
      "Epoch 1997/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9095e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6456e-05 - accuracy: 1.0000\n",
      "Epoch 1998/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1146e-05 - accuracy: 1.00 - 0s 149us/sample - loss: 1.6407e-05 - accuracy: 1.0000\n",
      "Epoch 1999/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2107e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6365e-05 - accuracy: 1.0000\n",
      "Epoch 2000/2000\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4886e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6316e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "history = model.fit(pad_seq, np.array(train_labls), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77051573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a035fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n",
      "User: what do you know?\n",
      "ChatBot: Please use respectful words\n",
      "User: who's your father?\n",
      "ChatBot: I am a bot as intelligent and articulate as the human that made me, right out of a computer.\n",
      "User: Play me a song\n",
      "ChatBot: sorry, author did not have enough time to code in the features for that.\n",
      "User: have a sandwich\n",
      "ChatBot: Hello! how can i help you ?\n",
      "User: you're stupid\n",
      "ChatBot: Please use respectful words\n",
      "User: bye\n",
      "ChatBot: Hello! how can i help you ?\n",
      "User: quit\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "                \n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a0619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
